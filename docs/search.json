[
  {
    "objectID": "betabinomial/beta_binomial.html",
    "href": "betabinomial/beta_binomial.html",
    "title": "Beta-binomial model testing",
    "section": "",
    "text": "knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())\n\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n\n\nWarning: package 'ggplot2' was built under R version 4.2.2\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(lme4)\n\nWarning: package 'lme4' was built under R version 4.2.2\n\n\nLoading required package: Matrix\n\nAttaching package: 'Matrix'\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\nlibrary(lmerTest)\n\nWarning: package 'lmerTest' was built under R version 4.2.2\n\n\n\nAttaching package: 'lmerTest'\n\nThe following object is masked from 'package:lme4':\n\n    lmer\n\nThe following object is masked from 'package:stats':\n\n    step\n\nlibrary(spaMM)\n\nRegistered S3 methods overwritten by 'registry':\n  method               from \n  print.registry_field proxy\n  print.registry_entry proxy\nspaMM (Rousset & Ferdy, 2014, version 4.1.0) is loaded.\nType 'help(spaMM)' for a short introduction,\n'news(package='spaMM')' for news,\nand 'citation('spaMM')' for proper citation.\nFurther infos, slides, etc. at https://gitlab.mbb.univ-montp2.fr/francois/spamm-ref."
  },
  {
    "objectID": "code_demos.html",
    "href": "code_demos.html",
    "title": "Code Demos",
    "section": "",
    "text": "This section has code and demos that cover many topics and serves several purposes. The pages here are organised thematically, though it will likely take me some iterating on the quarto website yaml to get there.\nThe goal in many of these examples and demos is NOT clean, efficient coding, but exploring HOW the code works and how to accomplish something. That often means creating LOTS of extra variables, copy-paste, and being extremely verbose."
  },
  {
    "objectID": "code_demos.html#clarify-thinking-and-testing",
    "href": "code_demos.html#clarify-thinking-and-testing",
    "title": "Code Demos",
    "section": "Clarify thinking and testing",
    "text": "Clarify thinking and testing\nClarify what I’m actually trying to do, and what the expected outcomes are. Then figuring out a) how do get those, and b) why I sometimes don’t, which can be just as important. Doing this sort of testing here instead of in-project can be very helpful as using minimal examples forces me to isolate the issue I’m trying to solve from all the particulars of a given dataset or project structure."
  },
  {
    "objectID": "code_demos.html#central-location-for-useful-bits",
    "href": "code_demos.html#central-location-for-useful-bits",
    "title": "Code Demos",
    "section": "Central location for useful bits",
    "text": "Central location for useful bits\nA central point for (relatively) clean, complete things that I want to be able to use across many projects (e.g. 2d autocorrelation, the Johnson distribution, how to use certain packages, fonts, colours and other plotting things etc). Having one central reference point keeps me from having to either reinvent the wheel or remember which project I put the wheel in, and having many slightly different variations. And improvements/extensions can then be accessed across projects."
  },
  {
    "objectID": "code_demos.html#understanding-code-testing-beyond-standard-uses",
    "href": "code_demos.html#understanding-code-testing-beyond-standard-uses",
    "title": "Code Demos",
    "section": "Understanding code, testing beyond standard uses",
    "text": "Understanding code, testing beyond standard uses\nI spend quite a lot of time figuring out how to do things in code, understanding how code works, and double-checking everything is working correctly. There are a lot of good demos and tutorials out there (e.g. stackoverflow, some package vignettes and websites), but I often end up needing to figure out weird edge cases. And I often end up doing something similar later, but needing not the final answer, but some intermediate step along the way."
  },
  {
    "objectID": "code_demos.html#the-process-of-coding",
    "href": "code_demos.html#the-process-of-coding",
    "title": "Code Demos",
    "section": "The process of coding",
    "text": "The process of coding\nI also think there can be value in seeing how I’ve solved a problem and tested the various avenues, both for my own future reference and others. For one, if I do later have a need for one of those side avenues, they’re available. For another, it exposes the actual process of coding a bit more than the usual tutorial that has cleaned everything up start to finish. And it gives a better starting point for additional development potentially much later if I can see what I’ve already tried. Maybe most importantly, there are few tutorials/walkthroughs I’ve followed that don’t end up with some sort of error, especially as soon as I try to modify them for my purposes. Seeing where I’ve hit errors, what caused them, and how I solved it can be incredibly helpful, rather than only seeing what worked."
  },
  {
    "objectID": "data_acquisition/bom_gauges.html",
    "href": "data_acquisition/bom_gauges.html",
    "title": "Bom reference stations",
    "section": "",
    "text": "knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())\n\n\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.2.2\n\nlibrary(sf)\n\nWarning: package 'sf' was built under R version 4.2.2\n\n\nLinking to GEOS 3.9.3, GDAL 3.5.2, PROJ 8.2.1; sf_use_s2() is TRUE\n\n\nTrying to find BOM gauge locations. Found reference stations. It’s a simple link, but have to use httr2 to download because there’s an error with the user_agent if we try to just download.file.\nMostly including this here as an example of changing user_agent.\nhttp://www.bom.gov.au/waterdata/ has a clickable link to what I want, but the data is buried in a frame so can’t scrape.\nThe below is because I found a link to reference stations and wanted to see what they were.\n\nIs there a url for BOM?\nIt’s just a csv, but have to faff about with httr2 and deparsing back to csv because need to pass a user agent or get a 403 error.\n\nbom2 <- httr2::request(\"http://www.bom.gov.au/water/hrs/content/hrs_station_details.csv\") |>\n  httr2::req_user_agent(\"md-werp\") |> \n  httr2::req_perform() |> \n  httr2::resp_body_string() |> \n  readr::read_csv(skip = 11) |> \n  dplyr::select(site = `Station Name`, \n                gauge = `AWRC Station Number`,  \n                owner = `Data Owner Name`, \n                Latitude, Longitude)\n\nRows: 467 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): AWRC Station Number, Station Name, Jurisdiction, Data Owner Name, D...\ndbl (3): Latitude, Longitude, Catchment Area (km2)\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nbasin <- read_sf(file.path('data','mdb_boundary', 'mdb_boundary.shp'))\n\n\nbom2 <- bom2 |>\n    # lat an long come in as chr because there is a line for 'undefined'\n    dplyr::filter(site != 'undefined') |>\n  st_as_sf(coords = c('Longitude', 'Latitude'), crs = 4326) |> \n  st_transform(crs = st_crs(basin))\n\nThey’re not the gauges I’m looking for. Only 457, instead of 6500, and around the edges of the basin.\n\nggplot() + \n  geom_sf(data = basin) +\n  geom_sf(data = bom2)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "This is a placeholder. I am a community ecologist with a focus on aquatic ecology. My background is in theoretical community ecology, though I also do fieldwork in aquatic systems and develop management-focused models. I have a particular interest in scaling, probabalistic modeling, and climate impacts.\nPostdoctoral researcher in the QAEL Lab at Deakin University."
  },
  {
    "objectID": "package/package_creation.html",
    "href": "package/package_creation.html",
    "title": "Creating a package",
    "section": "",
    "text": "I’ve always meant to build packages, but never quite have the time, and often end up with very convoluted projects that are not ideal for shoehorning into a typical package structure, particularly as a first try.\nIn part, I think, that is because my code is often a combination of package-type-things (functions, tests, other software flow) and analyses. It’s unclear what the best approach to this sort of flow is, where we absolutely want functions, but they are very specific to the analyses, of which there are many. Do the analyses go in the package? In two projects, but that’s a hassle? Anyway, that’s a topic for a longer post.\nHere, I have a self-contained, broadly usable bit of code I’m working on to extract information from the Victoria (Australia) waterdata network API. It’s more interesting than a Hello World type package, but also constrained in scope and the analyses can clearly go elsewhere.\nThis doc will be developed as I go, and so like most docs on this site isn’t a tutorial per se, but a sequence of steps, including pitfalls and recoveries (hopefully).\n\n\nFirst, created a repo in git.\nFor the main package development, I’m largely going to follow https://r-pkgs.org/, though I’m hoping I don’t have to read the whole thing (I know I should, but time is time).\nOpened a new Rstudio session (I use renv, but want to adjust some things globally- particularly {devtools}).\ninstall_packages(\"devtools\"), then devtools::dev_sitrep() and install any requested updates (in my case, {roxygen2} was out of date.\n\ndevtools::dev_sitrep()\n\n── R ───────────────────────────────────────────────────────────────────────────\n• version: 4.2.1\n• path: 'C:/Program Files/R/R-4.2.1/'\n\n\n• R is out of date (4.2.1 vs 4.2.2)\n\n\n── Rtools ──────────────────────────────────────────────────────────────────────\n• path: 'C:/rtools42/usr/bin/'\n── devtools ────────────────────────────────────────────────────────────────────\n• version: 2.4.5\n\n\n• devtools or its dependencies out of date:\n  'jsonlite', 'stringr', 'openssl', 'whisker', 'gert'\n  Update them with `devtools::update_packages(\"devtools\")`\n\n\n── dev package ─────────────────────────────────────────────────────────────────\n• package: <unset>\n• path: <unset>\n\n\nR is also out of date (at the time of writing). Fix it with rig, then re-run and update the packages.\n\ndevtools::update_packages('devtools')\n\nCheck the name I used works.\n\navailable::available('vicwater')\n\nWarning: package 'tidytext' was built under R version 4.2.2\n\n\n── vicwater ────────────────────────────────────────────────────────────────────\nName valid: ✔\nAvailable on CRAN: ✔ \nAvailable on Bioconductor: ✔\nAvailable on GitHub:  ✔ \nAbbreviations: http://www.abbreviations.com/vicwater\nWikipedia: https://en.wikipedia.org/wiki/vicwater\nWiktionary: https://en.wiktionary.org/wiki/vicwater\nSentiment:???\n\n\nLooks good.\nQuestion- I typically use Rprojects and renv to manage dependencies and sandbox projects. I also know that I can just devtools::create() (which I think just wraps usethis::create_package(). Can I start with the Rproj and then turn it into a package? Should I want to?\nAnswer- I just needed to read a bit further. Rstudio has devtools and Rprojects working together. So calling usethis::create_package() builds the project and puts all the scaffolding where it needs to be. I’ll need to cross the existing complex Rproj –> package bridge with another project later, but this is fairly straightforward here.\nSo, let’s create the package.\n\nusethis::create_package('~Galen/Documents/vicwater')\n\nAnd that worked with an existing directory. Was kind of worried about that. And it auto-opens a new Rstudio session.\nNow I’m mostly moving over there, but I ran usethis::use_mit_license() to set the license. Looks like description and namespace need work, but do that later.\nLet’s start building.\n\n\n\nI’ve been testing and poking at the API in some qmds here. I expect a lot of that ends up as vignettes in the package, and some is ready to become functions. I’ll likely maintain that flow- test in the qmd, make into functions there, repeat.\nI’m going to go write a function, and then figure out how to use it.\nSwitching to the native pipe |> to see how it goes and reduce dependencies.\n\n\nFor dependencies, I used usethis::use_package(), which installs and auto-populates the DESCRIPTION file. But I think I’m going to try using renv in here too, so I don’t always overwrite system-wide libraries. Hope it doesn’t screw anything up. Usual renv::init().\npackages that are nice to have (e.g. to allow parallelisation) are usethis::use_package('packagename', type = \"suggests\"). And if we want to import a function and not use package::function, use_import_from()- see below for the %dopar%.\n\n\n\nSo, I think usually the thing to do is run devtools::load_all() within the package project. I’m sure I’ll end up doing that. But it is also be possible to run it here, just passing the path, e.g. devtools::load_all(\"path/to/package/dir\"). That lets me work on test and development qmds and scripts here. For a bit. But why? For one, seems like vignettes have to use rmd at least at present. And it keeps all the trial and error out of that repo.\nI got hung up here for a while trying to pre-figure out how I’d install it once it was on github. Turns out it’s super straightforward (see below). It ends up just working as long as the thing on github has basic package structure.\n\n\n\nI’m using roxygen comments, as in the package dev book and roxygen docs for things like inheriting parameters and sections. Running devtools::document() builds the .rd files and means ?function works. There’s a lot of fancy stuff we could do there, but keeping it simple at first.\n\n\n\nI like having actual demonstrations of the code, rather than just function docs, so using usethis::use_vignette to start building some. They have to be in rmd, not qmd. But the visual editor still works, which is nice. Just going to have to re-remember rmd chunk headers.\nI can’t get df_print: paged to work. I think it might be a difference between html and html_vignette, but it is listed as an option in the help. For now using kable even though it’s huge for tables.\nI ended up using the main vignette as an example in the primary github readme. To do that, I did usethis::use_readme_rmd(). Would be good to sort out {pkgdown}, or maybe there’s a streamlined quarto version that builds a website?\n\n\n\nUsing usethis::use_testthat(3) and writing tests was fairly straighforward, but I think there will be a learning curve about what and how to test. I tend to look very granularly at ad-hoc tests, i.e. scanning for weird NA, types, etc. But testthat and the expect_* functions lend themselves to simpler checks.\nIt gets sort of cumbersome if a function takes a while and generates something complex. In that case, I built tests that run the function (and so are fragile to the function just erroring out), and then run multiple different expect_* tests against it to make sure the output is right. As an example,\n\ntest_that(\"derived variables work for ts\", {\n  s3 <- get_response(\"https://data.water.vic.gov.au/cgi/webservice.exe?\",\n                     paramlist = list(\"function\" = 'get_ts_traces',\n                                      \"version\" = \"2\",\n                                      \"params\" = list(\"site_list\" = '233217',\n                                                      \"start_time\" = 20200101,\n                                                      \"varfrom\" = \"100\",\n                                                      \"varto\" = \"140\",\n                                                      \"interval\" = \"day\",\n                                                      \"datasource\" = \"A\",\n                                                      \"end_time\" = 20200105,\n                                                      \"data_type\" = \"mean\",\n                                                      \"multiplier\" = 1)))\n  expect_equal(class(s3), 'list')\n  expect_equal(s3[[1]], 0)\n\n})\n\nAnd then, if I want to hit the function with edge cases, etc, I have to do that over and over. There’s likely a better way, but I’ll need to experiment.\n\n\n\n\nTrying to use %dopar%, but can’t get foreach::%dopar% to work, or with backticks. Putting it in a roxygen comment as @importFrom foreach %dopar% failed too. Seems to have worked to do usethis::use_import_from('foreach', '%dopar%'), which built some new files.\nHaving a hard time testing with doFuture, since it can’t find this package. pause that for a while\n\n\n\nOnce it’s pushed to github, it’s fairly straightforward to install- just\n\ndevtools::install_github(\"galenholt/vicwater\")\n\n\n\n\nIt ended up being pretty straightforward to use devtools::check() and using continuous integration with github to run the checks and put the little badges on, as described in the book."
  },
  {
    "objectID": "plotting/faded_colors.html",
    "href": "plotting/faded_colors.html",
    "title": "Faded colors",
    "section": "",
    "text": "There are a number of reasons we might want bivariate color axes in plots. The particular use I’m looking for now is to use a faded color to indicate less certainty in a result. Other uses will be developed later or elsewhere, but should build on this fairly straightforwardly.\nI’m doing this with colorspace because it’s hue-chroma-luminance approach makes it at least appear logical to shift along those dimensions. We might want hue (or luminance) to show one thing, and intensity to show another. Though we will play around with how that looks in practice. The specific use motivatiung this is to show the predicted amount of something with hue, and certainty with chroma or luminance (in particular, we have a model that makes predictions more accurately in some places than others). But there are many other potential uses.\nIn the HCL exploration file, I figure out HOW to generate faded colors and find some palettes that might work. Here, I’m going to sort out how to go from there to using them in plots, including creating legends."
  },
  {
    "objectID": "plotting/faded_colors.html#plot-the-bivariate-colors",
    "href": "plotting/faded_colors.html#plot-the-bivariate-colors",
    "title": "Faded colors",
    "section": "Plot the bivariate colors",
    "text": "Plot the bivariate colors\nBefore trying to plot with the colors, first I want to actually plot them themselves. One reason is to test how they are being created and specified, and the other is potentially to use the plot as a legend.\nWhy? The legend() part of ggplot may not handle the bivariate nature of the colors well, so need to basically homebrew one. This is the most flexible option- make the plot, then shrink and pretend it’s a legend. But, could also make a legend in vector form, then stack. Just not sure how well that’ll work. The shrunk plot would work better for continuous variables, the legend probably works better to use other parts of ggplot and not always have to screw around with grobs or ggarrange or patchwork or cowplot. I’ll try them all, I guess.\nFirst, make a matrix of colors. Take the base palette, fade it and save the color values for the whole thing. The for loop is lame, should be a function, but I’m just looking right now.\n\nbaseramp <- sequential_hcl(8, 'ag_Sunset')\n\nfadesteps <- seq(0,1, by = 0.25)\n\ncolormat <- matrix(rep(baseramp, length(fadesteps)), nrow = 5, byrow = TRUE)\n\nfor(i in 1:length(fadesteps)) {\n  colormat[i, ] <- lighten(colormat[i, ], amount = fadesteps[i]) %>%\n    desaturate(amount = fadesteps[i])\n}\n\nOption 1 is to make that into a plot that we can then smash on top\n\n# Make a tibble from the matrix to feed to ggplot\ncoltib <- as_tibble(colormat, rownames = 'row') %>%\n  pivot_longer(cols = starts_with('V'), names_to = 'column')\n\nWarning: The `x` argument of `as_tibble.matrix()` must have unique column names if\n`.name_repair` is omitted as of tibble 2.0.0.\nℹ Using compatibility `.name_repair`.\n\n# coltib\n\nggplot(coltib, aes(y = row, x = column, fill = value)) + \n  geom_tile() + scale_fill_identity()\n\n\n\n\nThat’s upside-down with how I tend to think about it. How about flipping the construction?\n\nfadesteps <- rev(seq(0,1, by = 0.25))\ncolormat <- matrix(rep(baseramp, length(fadesteps)), nrow = 5, byrow = TRUE)\n\nfor(i in 1:length(fadesteps)) {\n  colormat[i, ] <- lighten(colormat[i, ], amount = fadesteps[i]) %>%\n    desaturate(amount = fadesteps[i])\n}\n\ncoltib <- as_tibble(colormat, rownames = 'row') %>%\n  pivot_longer(cols = starts_with('V'), names_to = 'column')\n\n\nggplot(coltib, aes(y = row, x = column, fill = value)) +\n  geom_tile() + scale_fill_identity()"
  },
  {
    "objectID": "plotting/faded_colors.html#programmatic-color-setting",
    "href": "plotting/faded_colors.html#programmatic-color-setting",
    "title": "Faded colors",
    "section": "Programmatic color setting",
    "text": "Programmatic color setting\nCreate a function basically following the above. But allow it to take palettes by name or raw hue values if they are obtained elsewhere (like from a manually specified hue ramp). hex color vals and pal names are both characters, but hex always starts with ‘#’, so should be able to auto-detect. It can take a number of fades, or a vector of specific fade levels, and returns the matrix of colors.\n\ncol2dmat <- function(pal, n1, n2 = 2, dropwhite = TRUE, fadevals = NULL) {\n  # pal can be either a palette name or a vector of hex colors (or single hex color)\n  # dropwhite is there to by default knock off the bottom row that's all white\n  # fadevals is a way to bypass the n2 and specify specific fade levels (ie if nonlinear)\n\n  if (all(str_detect(pal, '#'))) {\n    baseramp <- pal\n  } else {\n    baseramp <- sequential_hcl(n1, pal)\n  }\n\n  if (is.null(fadevals)) {\n    if (dropwhite) {n2 = n2+1}\n\n    fadesteps <- rev(seq(0,1, length.out = n2))\n\n    if (dropwhite) {fadesteps <- fadesteps[2:length(fadesteps)]}\n\n  }\n\n  if (!is.null(fadevals)) {\n    fadesteps <- sort(fadevals, decreasing = TRUE)\n  }\n\n  colormat <- matrix(rep(baseramp, length(fadesteps)), nrow = length(fadesteps), byrow = TRUE)\n\n\n  for(i in 1:length(fadesteps)) {\n    colormat[i, ] <- lighten(colormat[i, ], amount = fadesteps[i]) %>%\n      desaturate(amount = fadesteps[i])\n  }\n\n  return(colormat)\n}\n\nCreate another function that plots a matrix of colors. Typically that matrix comes out of col2dmat. Why not make one big function? because we will often want to access the color values themselves, and not always just plot them.\n\nplot2dcols <- function(colmat) {\n  coltib <- as_tibble(colmat, rownames = 'row') %>%\n    pivot_longer(cols = starts_with('V'), names_to = 'column') %>%\n    mutate(row = as.numeric(row), column = as.numeric(str_remove(column, 'V')))\n\n  colplot <- ggplot(coltib, aes(y = row, x = column, fill = value)) +\n    geom_tile() + scale_fill_identity()\n\n  return(colplot)\n}\n\nTest that works with a given number of fades\n\nnewcolors <- col2dmat('ag_Sunset', n1 = 8, n2 = 4)\nplot2dcols(newcolors)\n\n\n\n\nTest with set fade levels. REMEMBER FADE is FADE, not intensity. ie 0 is darkest.\n\nnewcolsuneven <- col2dmat('ag_Sunset', n1 = 8, fadevals = c(0, 0.33, 0.8))\nplot2dcols(newcolsuneven)\n\n\n\n\nTest with non-built in palettes- ie setting hue manually. This could be particularly useful if we want quantitative hues. This tests the ability to auto-detect a vector of colors.\nUse the manual-set colors from hcl exploration for testing.\n\nhclmat <- cbind(50, max_chroma(h = seq(from = 130, to = 275, length.out = 8), l = 50, floor = TRUE),\n                seq(from = 130, to = 275, length.out = 8))\n\npg <- polarLUV(hclmat)\nswatchplot(hex(pg))\n\n\n\n\nWorks!\n\npgmat <- col2dmat(hex(pg), n2 = 4)\nplot2dcols(pgmat)"
  },
  {
    "objectID": "plotting/faded_colors.html#plotting-the-data",
    "href": "plotting/faded_colors.html#plotting-the-data",
    "title": "Faded colors",
    "section": "Plotting the data",
    "text": "Plotting the data\nAbove, we were trying to plot the colors. Now, we want to assign those colors to data so we can plot the data with the appropriate color.\n\nSingle datapoint\nThe above is fine for looking at a color matrix, but in general, we’ll have a dataframe with a value for each dimension, and need to assign it a single color. Step one is figuring out how to do that assignment.\nCan I take a ‘datapoint’ with arbitrary values on both axes and choose its color?\nCan we do that for both color bins or continuous color?\nWe’ll need to relativise the data, since neither hue or fade are defined on the real line, but by their endpoints.\nLet’s fake some data. Don’t use round numbers (e.g. 0, 100) to avoid making stupid mistakes relating to relativising the scale. We need to know the endpoints of the data to match the endpoints of the hue and fade, and then a datapoint somewhere in the middle to create.\n\n# what is the range of the data?\n  # don't use round numbers (e.g. 0, 100)\nmax1 <- 750\nmin1 <- 150\n\nmax2 <- 67\nmin2 <- -55\n\n\n# get color for a single value pair\nval1 <- 455\nval2 <- 8\n\njust use a simple linear transform to get position on the min-max axes. Could use logit or something for either, but keeping it simple. The value above the min divided by the range gives where the data point is on a 0-1 scale from min to max. In reality, we will have two vectors (well, cols in a dataframe), and this is actually easier to do in that case because we can just get the min and max directly.\n\nvalpos1 <- (val1-min1)/(max1-min1)\nvalpos2 <- (val2-min2)/(max2-min2)\n\nThat’s easy to vectorize, which is basically how we’ll do it with a dataframe.\nFor now, can we just get individual colors to assign to a value pair?\nNeed to specify the min and max hue- these are the hue endpoints, not data endpoints.\n\nminhue <- 130\nmaxhue <- 275\n\nfind the hue value at the same relative position as the datapoint\n\nmatchH1 <- (maxhue-minhue)*valpos1 + minhue\n\nUsing the manual colors\n\nsinglehclmat1 <- cbind(50, max_chroma(h = matchH1, l = 50, floor = TRUE),\n                matchH1)\n\npgsingle1 <- polarLUV(singlehclmat1)\nswatchplot(hex(pgsingle1))\n\n\n\n\nalso need the other axis. That’s also just on 0-1 (well, 1-0, since it’s fade, not intensity) and so would be done the same way.\n\nsinglecol <- col2dmat(hex(pgsingle1), fadevals = (1-valpos2))\nswatchplot(singlecol)\n\n\n\n\nIt’s clear we can write all this as functions, and that we’ll need to. So…\n\n\nProgramatically finding colors\nEarlier, we made col2dmat, which found colors and faded them. We want to do something similar here, but the goal isn’t quite the same- we don’t really care about the full matrix, but about a single point. We could modify col2dmat, but probably easier (and fewer horrible logicals) to just write purpose-built functions.\nNeed new functions to 1) find the hue, 2) adjust the fade\n\nFind the hue\nTakes either a number of bins or Inf for continuous.\n\nhuefinder <- function(hueval, minhue, maxhue, n = Inf, palname = NULL) {\n\n  # If continuous, use the value\n  # If binned, find the value of the bin the value is in\n  if (is.infinite(n)) {\n    matchH <- (maxhue-minhue)*hueval + minhue\n  } else if (!is.infinite(n)) {\n\n    nvec <- seq(from = 0, to = 1, length.out = n)\n\n    # The nvecs need to choose the COLOR, but the last one gets dropped in\n    # findInterval, so need an n+1\n    whichbin <- findInterval(hueval,\n                             seq(from = 0, to = 1, length.out = n+1),\n                             rightmost.closed = TRUE)\n\n    # Don't build if using named palette because won't have min and max\n    if (is.null(palname)) {\n      binhue <- nvec[whichbin]\n      matchH <- (maxhue-minhue)*binhue + minhue\n    }\n\n  }\n\n  if (is.null(palname)) {\n    h <- cbind(50, max_chroma(h = matchH, l = 50, floor = TRUE),\n               matchH)\n    h <- hex(polarLUV(h))\n  } else {\n    h <- sequential_hcl(n, palname)[whichbin]\n  }\n\n  return(h)\n}\n\n\n\nFind the fade\nThis takes the just found hue as basehue, and fades it. Again, n specifies either a number of fade bins or if infinite it is continuous and so just fades by whatever the value is.\n\nfadefinder <- function(fadeval, basehue, n = Inf) {\n\n  # If n is infinite, just use fadeval. Otherwise, bin, dropping the all-white level\n  if (is.infinite(n)) {\n    fadeval <- fadeval\n  } else {\n    # The +1 drops the white level\n    fadevec <- seq(from = 0, to = 1, length.out = n + 1)\n\n    # Rightmost closed fixes an issue right at 1\n    fadeval <- fadevec[findInterval(fadeval, fadevec, rightmost.closed = TRUE) + 1]\n  }\n\n  fadedcol <- lighten(basehue, amount = 1-fadeval) %>%\n    desaturate(amount = 1-fadeval)\n}\n\n\n\nHue and fade\nThis is meant to use in a mutate to take two columns of data and find the appropriate color. Should use … to pass, but whatever\n\ncolfinder <- function(hueval, fadeval, minhue, maxhue, nhue = Inf, nfade = Inf, palname = NULL) {\n  thishue <- huefinder(hueval, minhue, maxhue, nhue, palname)\n  thiscolor <- fadefinder(fadeval, thishue, nfade)\n}\n\nQuick tests\n\nfunhue <- huefinder(valpos1, minhue = minhue, maxhue = maxhue)\nfunfaded <- fadefinder(valpos2, funhue)\nswatchplot(funfaded)\n\n\n\n\nshould be the same as\n\nfunboth <- colfinder(valpos1, valpos2, minhue, maxhue)\nswatchplot(funboth)\n\n\n\n\n\n\n\nCalculating for dataframes\nVectorizing the relativization calculations is straightforward.\n\nvec1 <- c(150, 588, 750, 455, 234)\n\n# get it for each value in vectorized way\n(vec1 - min(vec1))/(max(vec1)-min(vec1))\n\n[1] 0.0000000 0.7300000 1.0000000 0.5083333 0.1400000\n\n\nMaking a function to get the relative position. We can use this in the mutate once we move on to dataframes.\n\nrelpos <- function(vec) {\n  (vec - min(vec))/(max(vec)-min(vec))\n}\n\nNow, let’s make a dataframe of fake data, with one column that should map to hue and the other mapping to fade. This just puts points all across the space of both variables so we can make sure everything is getting assigned correctly. Then, we’ll use the functions we just created to do a few different things:\n\ncustom hue ramps and built-in palettes\nbinned hue and fade\ncontinuous hue and binned fade\nboth continuous\n\nThe ‘continuous’ examples using inbuilt palettes are only pseudo-continuous by using large numbers of bins because that’s easier for the moment given the way sequential_hcl() works. There’s probably a way around it, but for the moment I’ll ignore it.\n\ncolortibble <- tibble(rvec1 = runif(10000, min = -20, max = 50),\n       rvec2 = runif(10000, min = 53, max = 99)) %>%\n  mutate(rel1 = relpos(rvec1),\n         rel2 = relpos(rvec2)) %>%\n  mutate(colorval = colfinder(rel1, rel2, minhue, maxhue),\n         binval = colfinder(rel1, rel2, minhue, maxhue, nhue = 8, nfade = 4),\n         # need to bypass some args\n         binsun = colfinder(rel1, rel2, nhue = 8, nfade = 4, palname = 'ag_Sunset',\n                            minhue = NULL, maxhue = NULL),\n         pseudoconsun = colfinder(rel1, rel2, nhue = 1000, nfade = 4, palname = 'ag_Sunset',\n                                  minhue = NULL, maxhue = NULL),\n         pseudoconsun2 = colfinder(rel1, rel2, nhue = 1000, nfade = Inf, palname = 'ag_Sunset',\n                                  minhue = NULL, maxhue = NULL))\n\nContinuous in both dimensions, using custom hue ramp\n\nggplot(colortibble, aes(x = rvec1, y = rvec2, color = colorval)) +\n  geom_point() +\n  scale_color_identity()\n\n\n\n\nBinned both dims, custom ramp\n\nggplot(colortibble, aes(x = rvec1, y = rvec2, color = binval)) +\n  geom_point() +\n  scale_color_identity()\n\n\n\n\nInbuilt palette, binned both dims.\nThere is a spot in this ag_Sunset palette that matches the ggplot default grey background and so hard to see, but I’ll ignore that for the moment since it doesn’t affect the main thing we’re doing. THese aren’t production plots.\n\nggplot(colortibble, aes(x = rvec1, y = rvec2, color = binsun)) +\n  geom_point() +\n  scale_color_identity()\n\n\n\n\nPseudo-continuous, binned fades.\n\nggplot(colortibble, aes(x = rvec1, y = rvec2, color = pseudoconsun)) +\n  geom_point() +\n  scale_color_identity()\n\n\n\n\nPseudo-continuous both dimensions.\n\nggplot(colortibble, aes(x = rvec1, y = rvec2, color = pseudoconsun2)) +\n  geom_point() +\n  scale_color_identity()"
  },
  {
    "objectID": "plotting/faded_colors.html#plotting-data",
    "href": "plotting/faded_colors.html#plotting-data",
    "title": "Faded colors",
    "section": "Plotting data",
    "text": "Plotting data\nNow, let’s see how that might look for some real data. I’ll use some with point data (iris) and then move on to maps, since that’s originally what this was developed for. It should easily extend to anything we can aes() on, e.g. barplot fills, etc.\n\nScatterplot\nTo keep it simple, let’s use iris\nIt won’t span the full space because of the relationship, but that’s OK, I think. We did that above. Here’s iris- now let’s color this plot.\n\nggplot(iris, aes(x = Sepal.Length, y = Petal.Width)) + geom_point()\n\n\n\n\n\nFade defined by an axis\nThis is how we did it above when plotting the colors to make sure they were working.\nRelativize the x and y to define colors.\n\ncoloriris <- iris %>%\n  mutate(rel1 = relpos(Sepal.Length),\n         rel2 = relpos(Petal.Width)) %>%\n  mutate(colorval = colfinder(rel1, rel2, minhue, maxhue),\n         binval = colfinder(rel1, rel2, minhue, maxhue, nhue = 8, nfade = 4),\n         # need to bypass some args\n         binsun = colfinder(rel1, rel2, nhue = 8, nfade = 4, palname = 'ag_Sunset',\n                            minhue = NULL, maxhue = NULL),\n         pseudoconsun = colfinder(rel1, rel2, nhue = 1000, nfade = 4, palname = 'ag_Sunset',\n                                  minhue = NULL, maxhue = NULL),\n         pseudoconsun2 = colfinder(rel1, rel2, nhue = 1000, nfade = Inf, palname = 'ag_Sunset',\n                                   minhue = NULL, maxhue = NULL))\n\nMake some plots to see the colors and fades correspond to the axis values in binned and unbinned ways.\n\nggplot(coloriris, aes(x = Sepal.Length, y = Petal.Width, color = colorval)) +\n  geom_point() +\n  scale_color_identity()\n\n\n\nggplot(coloriris, aes(x = Sepal.Length, y = Petal.Width, color = pseudoconsun2)) +\n  geom_point() +\n  scale_color_identity()\n\n\n\nggplot(coloriris, aes(x = Sepal.Length, y = Petal.Width, color = binsun)) +\n  geom_point() +\n  scale_color_identity()\n\n\n\n\n\n\nFade as a new aesthetic\nTo actually match what I want to use this for, it’s more like we’d say versicolor is less certain. IE Species defines the fade. This is like fade is an aesthetic in ggplot, but we’re sort of manually doing it.\nLet’s set hue by sepal length, and fade by species\n\nuncertainVers <- iris %>%\n  mutate(rel1 = relpos(Sepal.Length),\n         faded = ifelse(Species == 'versicolor', 0.50, 1)) %>%\n  mutate(binhue = huefinder(rel1, n = 8, palname = 'ag_Sunset'),\n         conhue = huefinder(rel1, n = 1000, palname = 'ag_Sunset'),\n         binfade = fadefinder(faded, binhue),\n         confade = fadefinder(faded, conhue))\n\nNow, versicolor should be faded relative to the others\n\nggplot(uncertainVers, aes(x = Sepal.Length, y = Petal.Width, color = binfade)) +\n  geom_point() +\n  scale_color_identity()\n\n\n\nggplot(uncertainVers, aes(x = Sepal.Length, y = Petal.Width, color = confade)) +\n  geom_point() +\n  scale_color_identity()\n\n\n\n\nThat seems to be working, both binned and continous on the hue scale.\n\n\n\nMaps\nWhat I really want this for is a map, with each polygon having a value of the variable of interest mapped to hue, and a ‘certainty’ determining the fade. Though that axis could really be any other value. Can I mock that up?\nRead a map in of catchments in Australia.\n\nallbasins <- read_sf(file.path('data', '42343_shp', 'rbasin_polygon.shp'))\n\nIgnoring fade for the minute, what should we color by? Probably should be random, really, for the demo.\nColoring by centroid will just put a cross-country fade on:\n\nggplot(allbasins, aes(fill = CENTROID_X)) + geom_sf() + scale_fill_continuous_sequential('ag_Sunset')\n\n\n\n\nLet’s make a column representing the value we want to plot for each basin, just chosen at random\n\nallbasins <- allbasins %>%\n  mutate(fakevals = runif(nrow(allbasins))) %>%\n  mutate(rel1 = relpos(fakevals)) %>%\n  mutate(binhue = huefinder(rel1, n = 8, palname = 'ag_Sunset'),\n         conhue = huefinder(rel1, n = 1000, palname = 'ag_Sunset'))\n\nI can use the values directly here with scale_fill_XX if I don’t care about fade\n\nggplot(allbasins, aes(fill = fakevals)) + geom_sf() + scale_fill_continuous_sequential('ag_Sunset')\n\n\n\n\nbut the hues for the faded should match the set hues. Now, I need to use scale_fill_identity(). Works for binned and pseudo-continuous. I’ll save the binned to compare later with the faded version.\n\nhuesonly <- ggplot(allbasins, aes(fill = binhue)) +\n  geom_sf() +\n  scale_fill_identity()\nhuesonly\n\n\n\nggplot(allbasins, aes(fill = conhue)) +\n  geom_sf() +\n  scale_fill_identity()\n\n\n\n\nNow, fade some out (with relatively low probability)\n\nallbasins <- allbasins %>%\n  mutate(faded = sample(x = c(1, 0.5),\n                           size = nrow(allbasins),\n                           replace = TRUE,\n                           prob = c(0.8, 0.2))) %>%\n  mutate(binfade = fadefinder(faded, binhue),\n         confade = fadefinder(faded, conhue))\n\nBinned and continuous. Again, save the binned for comparison\n\nhuefade <- ggplot(allbasins, aes(fill = binfade)) +\n  geom_sf() +\n  scale_fill_identity()\nhuefade\n\n\n\nggplot(allbasins, aes(fill = confade)) +\n  geom_sf() +\n  scale_fill_identity()\n\n\n\n\nplot the raw and faded next to each other using patchwork. We can now see that some of the catchments are faded versions of the original hue.\n\nhuesonly + huefade\n\n\n\n\n\nLegends\nWe need legends. Could be done by playing with the actual ggplot legend or making mini plot and gluing on.\nQuick attempt at guide fails, because the colors are mixed up because of the RGB sorting.\n\nggplot(allbasins, aes(fill = binfade)) +\n  geom_sf() +\n  scale_fill_identity(guide = 'legend') +\n  guides(fill = guide_legend(ncol = 2))\n\n\n\n\nCan I change the order by basing it on the hues and then the fades? Does ‘breaks’ work? Yeah, sort of. And need to sort them in the right way.\n\nggplot(allbasins, aes(fill = binfade)) +\n  geom_sf() +\n  scale_fill_identity(guide = 'legend',\n                      breaks = unique(allbasins$binhue))\n\n\n\n\nI think that will basically work, but I’ll need to edit a bit There’s probably a way to write the functions better to just do this all in the mutates, but for now, I can create a tibble of breaks and labels using summarise.\n\nbreaksnlabels <- allbasins %>%\n  st_drop_geometry() %>%\n  group_by(binhue) %>%\n  summarize(minbin = min(fakevals),\n            maxbin = max(fakevals),\n            fromto = paste0(as.character(round(minbin, 2)),\n                            ' to ',\n                            as.character(round(maxbin, 2)))) %>%\n  ungroup() %>%\n  arrange(minbin)\n\nWorks for the unfaded\n\nggplot(allbasins, aes(fill = binfade)) +\n  geom_sf() +\n  scale_fill_identity(guide = 'legend',\n                      breaks = breaksnlabels$binhue,\n                      labels = breaksnlabels$fromto)\n\n\n\n\nI could now ALSO fade those, but I might be able to do it as one summarise using the faded column\n\nfadebreaks <- allbasins %>%\n  st_drop_geometry() %>%\n  # needs to capture the color boundaries, whether or not faded\n  group_by(binhue) %>%\n  mutate(minbin = min(fakevals),\n            maxbin = max(fakevals),\n            fromto = paste0(as.character(round(minbin, 2)),\n                            ' to ',\n                            as.character(round(maxbin, 2)))) %>%\n  ungroup() %>%\n  group_by(binfade, faded) %>%\n  summarize(minbin = first(minbin),\n            maxbin = first(maxbin),\n            fromto = first(fromto)) %>%\n  ungroup() %>%\n  arrange(minbin, desc(faded))\n\n`summarise()` has grouped output by 'binfade'. You can override using the\n`.groups` argument.\n\n\n\nggplot(allbasins, aes(fill = binfade)) +\n  geom_sf() +\n  scale_fill_identity(guide = 'legend',\n                      breaks = fadebreaks$binfade,\n                      labels = fadebreaks$fromto) +\n  guides(fill = guide_legend(title = 'Value', title.position = 'top',\n                             nrow = 2, label.position = 'top')) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\nPlot tweaking\nThat’s close. Can I make the labels better? Ideally, drop from the faded, and make them at 45 or something. and fix up the size.\nFirst, drop the labels on the faded, since they are the same as the base hue.\n\nfb2 <- fadebreaks %>%\n  mutate(fromto = ifelse(faded == 0.5, '', fromto))\n\n\nggplot(allbasins, aes(fill = binfade)) +\n  geom_sf() +\n  scale_fill_identity(guide = 'legend',\n                      breaks = fb2$binfade,\n                      labels = fb2$fromto) +\n  guides(fill = guide_legend(title = 'Value', title.position = 'top',\n                             nrow = 2, label.position = 'top')) +\n  theme(legend.position = 'bottom')\n\n\n\n\nFixing up the sizes and angles. The size doesn’t do what I want (square), because the text is too big.\n\nggplot(allbasins, aes(fill = binfade)) +\n  geom_sf() +\n  scale_fill_identity(guide = 'legend',\n                      breaks = fb2$binfade,\n                      labels = fb2$fromto) +\n  guides(fill = guide_legend(title = 'Value', title.position = 'top',\n                             nrow = 2, label.position = 'top')) +\n  theme(legend.position = 'bottom',\n      legend.background = element_blank(),\n      legend.key.size = unit(0.3, 'cm'), # This should make them square, but isn't.\n      legend.text = element_text(angle = 45, vjust = 0.4))\n\n\n\n\nCan I fake it on the row labels by inserting line breaks? The number of lines is really unstable across device sizes or saving the figure, so the number of line breaks will have to be adjusted every time this gets saved etc. But it might kind of work.\n\nggplot(allbasins, aes(fill = binfade)) +\n  geom_sf() +\n  scale_fill_identity(guide = 'legend',\n                      breaks = fb2$binfade,\n                      labels = fb2$fromto) +\n  guides(fill = guide_legend(title = 'Value\\n\\n\\n\\nCertain\\n\\n\\nUncertain', title.position = 'left',\n                             nrow = 2, label.position = 'top')) +\n  theme(legend.position = 'bottom',\n        legend.background = element_blank(),\n        legend.key.size = unit(0.3, 'cm'), # This should make them square, but isn't.\n        legend.text = element_text(angle = 45, vjust = 0.4))\n\n\n\n\nCan I bold that title?\n\nggplot(allbasins, aes(fill = binfade)) +\n  geom_sf() +\n  scale_fill_identity(guide = 'legend',\n                      breaks = fb2$binfade,\n                      labels = fb2$fromto) +\n  guides(fill = guide_legend(title = expression(atop(bold('Value'),atop('Certain','Uncertain'))),\n                             title.position = 'left',\n                             nrow = 2, label.position = 'top')) +\n  theme(legend.position = 'bottom',\n        legend.background = element_blank(),\n        legend.key.size = unit(0.3, 'cm'), # This should make them square, but isn't.\n        legend.text = element_text(angle = 45, vjust = 0.4))\n\n\n\n\nThat doesn’t work very well. Does ggtext do it? Allows markdown syntax and HTML (hence the  instead of ). It works, but still, the number of breaks will depend on the size of the figure device or file\n\nggplot(allbasins, aes(fill = binfade)) +\n  geom_sf() +\n  scale_fill_identity(guide = 'legend',\n                      breaks = fb2$binfade,\n                      labels = fb2$fromto) +\n  guides(fill = guide_legend(title = '**Value**<br><br><br><br>Certain<br><br>Uncertain',\n                             title.position = 'left',\n                             nrow = 2, label.position = 'top')) +\n  theme(legend.title = ggtext::element_markdown(),\n        legend.position = 'bottom',\n        legend.background = element_blank(),\n        legend.key.size = unit(0.5, 'cm'), # This should make them square, but isn't because the angled value labels don't allow it.\n        legend.text = element_text(angle = 45, vjust = 0.4))\n\n\n\n\nIf we want square legend boxes and readable text for the value labels, might have to go vertical and that means re-doing the breaks and labels dataframe\n\nfbv <- fadebreaks %>%\n  mutate(fromto = ifelse(faded == 1, '', fromto)) %>%\n  arrange(desc(faded), minbin)\n\n\nggplot(allbasins, aes(fill = binfade)) +\n  geom_sf() +\n  scale_fill_identity(guide = 'legend',\n                      breaks = fbv$binfade,\n                      labels = fbv$fromto) +\n  guides(fill = guide_legend(title = '**Value**<br><br>Certain Uncertain',\n                             title.position = 'top',\n                             ncol = 2, label.position = 'right')) +\n  theme(legend.title = ggtext::element_markdown(),\n        legend.position = 'right',\n        legend.background = element_blank(),\n        legend.key.size = unit(0.5, 'cm'))\n\n\n\n\nThat works pretty well. If we wanted multiple levels of uncertainty (fades), a similar thing would work with just having more columns. That basically works. If I want to label the fades more robustly, I think I’ll likely need to resort to grobs, in which case I probably might as well do the figure as legend method.\n\n\nMini-figure legends\nSometimes we want to create a legend and then add it back into a figure (maybe if it’s shared, or we want a standard legend across a group of figures). Here, we might want to create a different legend for the certian and uncertain, glue them together, and then glue them back on the main figure.\nto show how this might make sense, let’s make three plots- one with just the certain, one with uncertain, and one with no legend, and then glue together Making this as vertical, but easy enough to swap\nMake the map alone\n\njustmap <- ggplot(allbasins, aes(fill = binfade)) +\n  geom_sf() +\n  scale_fill_identity(guide = 'legend',\n                      breaks = fbv$binfade,\n                      labels = fbv$fromto) +\n  theme(legend.position = 'none')\n\n# used later- continuous specification of color and fade\njustmapcon <- ggplot(allbasins, aes(fill = confade)) +\n  geom_sf() +\n  scale_fill_identity(guide = 'legend',\n                      breaks = fbv$binfade,\n                      labels = fbv$fromto) +\n  theme(legend.position = 'none')\n\nGet the indices for the two fades\n\ncerts <- which(fbv$faded == 1)\nuncerts <- which(fbv$faded == 0.5)\n\nMake the legend for the unfaded\n\ncertleg <- ggplot(allbasins, aes(fill = binfade)) +\n  geom_sf() +\n  scale_fill_identity(guide = 'legend',\n                      breaks = fbv$binfade[certs],\n                      labels = fbv$fromto[certs]) +\n  guides(fill = guide_legend(title = 'Certain',\n                             title.position = 'top',\n                             ncol = 1, label.position = 'right')) +\n  theme(legend.title = ggtext::element_markdown(),\n        legend.position = 'right',\n        legend.background = element_blank(),\n        legend.key.size = unit(0.5, 'cm'))\n\n# I don't actually want the plot, just the legend, so\n certleg <- ggpubr::get_legend(certleg)\n\nAnd the faded\n\n uncertleg <- ggplot(allbasins, aes(fill = binfade)) +\n   geom_sf() +\n   scale_fill_identity(guide = 'legend',\n                       breaks = fbv$binfade[uncerts],\n                       labels = fbv$fromto[uncerts]) +\n   guides(fill = guide_legend(title = 'Uncertain',\n                              title.position = 'top',\n                              ncol = 1, label.position = 'right')) +\n   theme(legend.title = ggtext::element_markdown(),\n         legend.position = 'right',\n         legend.background = element_blank(),\n         legend.key.size = unit(0.5, 'cm'))\n\n # I don't actually want the plot, just the legend, so\n uncertleg <- ggpubr::get_legend(uncertleg)\n\nGlue those legends\n\nbothleg <- ggpubr::ggarrange(certleg, uncertleg)\n\nand glue on the plot\n\n plotpluslegs <- ggpubr::ggarrange(justmap, bothleg, widths = c(8,2))\n plotpluslegs\n\n\n\n\nThat’s not really any better than what I had before. It is useful to have this level of control sometimes though. In particular, we might want to use a PLOT as a legend, either binned or not.\nTo use a plot as a legend\nHere, binned is obviously the way to go, especially for the two fade levels, but let’s demo both.\nabove, we defined a function col2dmat that makes a plot of the color matrix. Let’s use that to demo a few options. First create the figures that will be the legends.\nBinned both dims, two fades, but just low-high labels\n\nbinnedplotmat <- col2dmat('ag_Sunset', n1 = 8, fadevals = c(0, 0.5))\n bin2legqual <- plot2dcols(binnedplotmat) +\n   # Breaks aren't centered on the values for this geom, so instead of 0.5 and 1, need to shift\n   theme_void() +\n   scale_y_continuous(breaks = c(1, 2), labels = c('Uncertain', 'Certain')) +\n   # Vague levels\n   scale_x_continuous(breaks = c(1, 8), labels = c('Low', 'High')) +\n   theme(axis.text = element_text())\n bin2legqual\n\n\n\n\nBinned both dims, but now the hue values are quantitatively labeled\n\nnamedlabs <- filter(fb2, fromto != '') %>% select(fromto) %>% pull()\n bin2legquant <- plot2dcols(binnedplotmat) +\n   # Breaks aren't centered on the values for this geom, so instead of 0.5 and 1, need to shift\n   theme_void() +\n   scale_y_continuous(breaks = c(1, 2), labels = c('Uncertain', 'Certain')) +\n   # Vague levels\n   scale_x_continuous(breaks = 1:8, labels = namedlabs) +\n   theme(axis.text.y = element_text(),\n         axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +\n   ggtitle('Value')\n bin2legquant\n\n\n\n\nA few levels of fade. Very similar to above\n\nmat4fade <- col2dmat('ag_Sunset', n1 = 8, n2 = 4)\n\n fadevals <- rev(seq(0,1, length.out = 4+1))[1:4]\n bin4leg <- plot2dcols(mat4fade) +\n   # Breaks aren't centered on the values for this geom, so instead of 0.5 and 1, need to shift\n   theme_void() +\n   scale_y_continuous(breaks = 1:4, labels = rev(fadevals), name = 'Certainty') +\n   scale_x_continuous(breaks = 1:8, labels = namedlabs, name = 'Value') +\n   theme(axis.text.y = element_text(),\n         axis.title.y = element_text(angle = 90),\n         axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),\n         axis.title.x = element_text())\n bin4leg\n\n\n\n\npseudo-continuous. put the x-axis on top, because that’s what we’d expect for a legend, really. Labels can take a lambda function of the breaks, allowing us to use auto-chosen breaks. But probably better to reference the values they correspond to. It’s just that for this silly demo they are 0-1. Let’s pretend for the minute that they’re logged just for fun and to demo how to do it.\n\nmatcfade <- col2dmat('ag_Sunset', n1 = 100, n2 = 100)\n conleg <- plot2dcols(matcfade) +\n   theme_void() +\n   scale_y_continuous(name = 'Certainty %') +\n   #\n   scale_x_continuous(labels = ~round(log(.), 2), name = 'Value', position = 'top') +\n   theme(axis.text.y = element_text(),\n         axis.title.y = element_text(angle = 90),\n         axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),\n         axis.title.x = element_text())\n conleg\n\n\n\n\nNow, attach those to the map as legends.\nI’ll use patchwork for most of them, but ggpubr::ggarrange would work too, just with different tweaking. The way patchwork does insets and sizes is working better for me right now, so that’s what I’ll use.\nTaking the grey background off because it’s distracting with inset legends.\nTwo-level binned legend with high-low\n\n(justmap + theme_bw() + theme(legend.position = 'none')) +\n   inset_element(bin2legqual, left = 0.1, bottom = 0.1, right = 0.5, top = 0.2)\n\n\n\n\nSame, but quantitative legend labels. Text is a bit absurd.\n\n(justmap + theme_bw() + theme(legend.position = 'none')) +\n   inset_element((bin2legquant + theme(axis.text = element_text(size = 8),\n                                       title = element_text(size = 8))),\n                 left = 0.1, bottom = 0, right = 0.5, top = 0.25)\n\n\n\n\nA 4-fade example with quantitative fades as well. That’s not our immediate need, but good to be able to do. maybe fade according to standard error or something.\n\n(justmap + theme_bw() + theme(legend.position = 'none')) +\n   inset_element((bin4leg + theme(axis.text = element_text(size = 8),\n                                       title = element_text(size = 8))),\n                 left = 0.1, bottom = 0, right = 0.5, top = 0.25)\n\n\n\n\nContinuous values in both dimensions. Here, we use a map where colors and fades are both defined continuously.\n\n(justmapcon + theme_bw() + theme(legend.position = 'none')) +\n   inset_element((conleg + coord_fixed() +\n                    theme(axis.text = element_text(size = 8),\n                          title = element_text(size = 8))),\n                 left = 0.1, bottom = 0.05, right = 0.5, top = 0.25)\n\n\n\n\nCan I put the legend off to the side just by specifying bigger coords? sort of- it goes but gets lost\n\n(justmap + theme_bw() + theme(legend.position = 'none')) +\n   inset_element((conleg + coord_fixed() +\n                    theme(axis.text = element_text(size = 8),\n                          title = element_text(size = 8))),\n                 left = 1, bottom = 0.4, right = 1.5, top = 0.75)\n\n\n\n\nWorks with making a small plot with spacers and then glueing that onto the big plot\n\nguidespot <- plot_spacer() /\n   (conleg + coord_fixed() +\n   theme(axis.text = element_text(size = 8),\n         title = element_text(size = 8))) /\n   plot_spacer()\n\n (justmap + theme_bw() + theme(legend.position = 'none')) +\n   guidespot +\n   plot_layout(widths = c(9, 1))\n\n\n\n\nDoes that work with the simpler ones? Yeah, although the 2-fades makes more sense horizontal, so do that\n\n# I can't fiugre out why this creates a dataframe. results = 'hide' doesn't hide it, wrapping with invisible(), etc. I give up. Giving it its own code block\nguidespot2 <- plot_spacer() |\n   (bin2legquant + theme(axis.text = element_text(size = 8),\n                         title = element_text(size = 8))) |\n   plot_spacer()\n\n\n (justmap + theme_bw() + theme(legend.position = 'none')) /\n   guidespot2 +\n   plot_layout(heights = c(9, 1))\n\n\n\n\nA very similar approach would work for ggpubr::ggarrange\nThere’s quite a lot more that could be done here, but this gets me what I need for now."
  },
  {
    "objectID": "plotting/faded_colors.html#notes",
    "href": "plotting/faded_colors.html#notes",
    "title": "Faded colors",
    "section": "Notes",
    "text": "Notes\nif this were truly bivariate (ie two variables of interest), could rotate 45 degrees to equally weight (and likely use different color ramps). But it’s not- it’s certainty along one axis, so leaving horiz and having a lightness axis fits what we’re doing here better."
  },
  {
    "objectID": "plotting/fonts.html",
    "href": "plotting/fonts.html",
    "title": "Fonts",
    "section": "",
    "text": "knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())\n\nUsing knitr::inline_expr(r message = FALSE, warning = FALSE) hopefully stops it printing all the package messages\n\nlibrary(tidyverse) # Overkill, but easier than picking and choosing\n\nThese are mostly little plot tweaks and small things that I find and forget all the time.\n\nAccessing fonts\nIn the past, I’ve used extrafonts to use fonts within figures, but it’s failing for me (‘No FontName, skipping’ error as in https://github.com/wch/extrafont/issues/88).\nTry sysfonts. Actually, showtext on top of sysfonts. First, look at how it finds the fonts.\n\nlibrary(showtext)\n\nWarning: package 'showtext' was built under R version 4.2.2\n\n\nLoading required package: sysfonts\n\n\nWarning: package 'sysfonts' was built under R version 4.2.2\n\n\nLoading required package: showtextdb\n\n\nWarning: package 'showtextdb' was built under R version 4.2.2\n\nfontsIhave <- font_files()\nfontsIhave\n\n\n\n  \n\n\nstr(fontsIhave)\n\n'data.frame':   349 obs. of  6 variables:\n $ path   : chr  \"C:/Windows/Fonts\" \"C:/Windows/Fonts\" \"C:/Windows/Fonts\" \"C:/Windows/Fonts\" ...\n $ file   : chr  \"AGENCYB.TTF\" \"AGENCYR.TTF\" \"ALGER.TTF\" \"ANTQUAB.TTF\" ...\n $ family : chr  \"Agency FB\" \"Agency FB\" \"Algerian\" \"Book Antiqua\" ...\n $ face   : chr  \"Bold\" \"Regular\" \"Regular\" \"Bold\" ...\n $ version: chr  \"Version 1.01\" \"Version 1.01\" \"Version 1.57\" \"Version 2.35\" ...\n $ ps_name: chr  \"AgencyFB-Bold\" \"AgencyFB-Reg\" \"Algerian\" \"BookAntiqua-Bold\" ...\n\n\nI should be able to use font_add\nFirst, what fonts are CURRENTLY available in R?\n\nwindowsFonts()\n\n$serif\n[1] \"TT Times New Roman\"\n\n$sans\n[1] \"TT Arial\"\n\n$mono\n[1] \"TT Courier New\"\n\nfont_families()\n\n[1] \"sans\"         \"serif\"        \"mono\"         \"wqy-microhei\"\n\n\nTest with one of the\n\nfont_add('Bookman Old Style', regular = 'BOOKOS.TTF', \n         italic = 'BOOKOSI.TTF', \n         bold = 'BOOKOSB.TTF', \n         bolditalic = 'BOOKOSBI.TTF')\n\nwindowsFonts()\n\n$serif\n[1] \"TT Times New Roman\"\n\n$sans\n[1] \"TT Arial\"\n\n$mono\n[1] \"TT Courier New\"\n\nfont_families()\n\n[1] \"sans\"              \"serif\"             \"mono\"             \n[4] \"wqy-microhei\"      \"Bookman Old Style\"\n\n\nI’m not quite understanding how this object is organised. What is that last line? are the $xxxx the defaults?\nTo test, let’s make a plot and try to change font.\nThe help (https://cran.rstudio.com/web/packages/showtext/vignettes/introduction.html) says we need to tell R to use showtext for text.\n\nshowtext_auto()\n\n\nbaseiris <- ggplot(iris, aes(x = Sepal.Length, y = Petal.Width, color = Species)) +\n  geom_point()\nbaseiris + theme(axis.title = element_text(family = 'Bookman Old Style'),\n                 legend.title = element_text(family = 'Bookman Old Style', face = 'bold.italic'))\n\n\n\n\nThat seems to work. Can I feed in all the fonts on my system automaticallly? Is that a bad idea? Might be if it takes a while and we only want one.\nFirst, though, can I give it a font name as a character and it load all of the faces automatically?\nNote: some of the fonts I have have weird faces. For now, just fail on those and stick with the ones supported by showtext. That should be fine.\n\nunique(fontsIhave$face)\n\n [1] \"Bold\"            \"Regular\"         \"Bold Italic\"     \"Italic\"         \n [5] \"Demibold\"        \"Demibold Italic\" \"Demibold Roman\"  \"Bold Oblique\"   \n [9] \"Oblique\"         \"Light\"          \n\n\nThis is a) a useful thing to simplify adding single fonts, and b) precursor to loading them all.\n\n# chosen more or less at random for testing\nfamilyname <- 'Candara'\n\n# I could use dplyr but this seems better to just use base logical indexing.\n# fontsIhave %>%\n#   filter(family == familyname & face == 'Regular') %>%\n#   select(file) %>%\n#   pull()\n\n# Could do all the indexing in the function call to font_add(), but it just gets ridiculous\nregfile <- fontsIhave[which(fontsIhave$family == familyname &\n                   fontsIhave$face == 'Regular'), 'file']\n\nitalfile <- fontsIhave[which(fontsIhave$family == familyname &\n                   fontsIhave$face == 'Italic'), 'file']\n\nboldfile <- fontsIhave[which(fontsIhave$family == familyname &\n                   fontsIhave$face == 'Bold'), 'file']\n\nbifile <- fontsIhave[which(fontsIhave$family == familyname &\n                   fontsIhave$face == 'Bold Italic'), 'file']\n\n\n# NEED TO TEST WHEN THE FACE DOESN'T EXIST AND THROW NULL\n  # If not there, the value will be character(0). testing for that and returning NULL (which is what the function needs) is a bit tricky:\nnoface <- function(x) {ifelse(rlang::is_empty(x), return(NULL), return(x))}\n\nfont_add(familyname, \n         regular = noface(regfile), \n         italic = noface(italfile), \n         bold = noface(boldfile), \n         bolditalic = noface(bifile))\n\nTest that with a figure\n\nbaseiris + theme(axis.title.x = element_text(family = familyname, face = 'italic'),\n                 axis.title.y = element_text(family = familyname, face = 'bold'),\n                 legend.text = element_text(family = familyname),\n                 legend.title = element_text(family = familyname, face = 'bold.italic'))\n\n\n\n\nHow bad an idea is it to just read them ALL in at once?\nEasy enough to feed the font_add above in a loop. Probably vectorizable too, but why bother?\nWrite it as a function, then it will work for all fonts or a subset if that’s a bad idea. Either feed it a dataframe of fonts or just use font_files() directly. It can also take NULL for fontvec, in which case it loads all the fonts.\n\nloadfonts <- function(fontvec = NULL, fontframe = NULL) {\n  \n  # Get all fonts if no fontframe\n  if (is.null(fontframe)) {\n    fontframe <- font_files()\n  }\n  \n  # Load all fonts if no fontvec\n  if (is.null(fontvec)) {\n    fontvec <- unique(fontframe$family)\n  }\n  \n  # Loop over the font families\n  for (i in 1:length(fontvec)) {\n    familyname <- fontvec[i]\n    regfile <- fontframe[which(fontframe$family == familyname &\n                   fontframe$face == 'Regular'), 'file']\n\n    italfile <- fontframe[which(fontframe$family == familyname &\n                       fontframe$face == 'Italic'), 'file']\n    \n    boldfile <- fontframe[which(fontframe$family == familyname &\n                       fontframe$face == 'Bold'), 'file']\n    \n    bifile <- fontframe[which(fontframe$family == familyname &\n                       fontframe$face == 'Bold Italic'), 'file']\n    \n## TODO: THROW A TRYCATCH ON HERE TO BYPASS AND ALERT FOR FAILURES\n    # For example, Berlin Sans FB Demi has no 'regular' and so fails. let's just skip those, this isn't supposed to be the most robust thing ever that handles all cases flawlessly.\n    try(font_add(fontvec[i], \n         regular = noface(regfile), \n         italic = noface(italfile), \n         bold = noface(boldfile), \n         bolditalic = noface(bifile)))\n    \n    # To avoid unforeseen carryover through the loop\n    rm(familyname, regfile, italfile, boldfile, bifile)\n  }\n  \n}\n\nLet’s try just reading everything in. Use try in the function above because there are failures for a few reasons, and instead of dealing with them I just want to quickly read in what’s easy to read in. I don’t have a ton of interest here in figuring out corner cases for weird fonts.\nTest the function with a vector of fontnames first, because can’t do that after try with everything\n\nloadfonts(fontvec = c('Consolas', 'Comic Sans MS', 'Tahoma'))\nfont_families()\n\n[1] \"sans\"              \"serif\"             \"mono\"             \n[4] \"wqy-microhei\"      \"Bookman Old Style\" \"Candara\"          \n[7] \"Consolas\"          \"Comic Sans MS\"     \"Tahoma\"           \n\n\nNow, go for it with everything. There are a million errors, so I’ve turned error reporting off for this code chunk.\n\nsystem.time(loadfonts())\n\nThat was pretty quick. What do I have?\n\nfont_families()\n\n  [1] \"sans\"                            \"serif\"                          \n  [3] \"mono\"                            \"wqy-microhei\"                   \n  [5] \"Bookman Old Style\"               \"Candara\"                        \n  [7] \"Consolas\"                        \"Comic Sans MS\"                  \n  [9] \"Tahoma\"                          \"Agency FB\"                      \n [11] \"Algerian\"                        \"Book Antiqua\"                   \n [13] \"Arial\"                           \"Arial Narrow\"                   \n [15] \"Arial Black\"                     \"Arial Rounded MT Bold\"          \n [17] \"Bahnschrift\"                     \"Baskerville Old Face\"           \n [19] \"Bauhaus 93\"                      \"Bell MT\"                        \n [21] \"Bernard MT Condensed\"            \"Bodoni MT\"                      \n [23] \"Bodoni MT Black\"                 \"Bodoni MT Condensed\"            \n [25] \"Bodoni MT Poster Compressed\"     \"Bradley Hand ITC\"               \n [27] \"Britannic Bold\"                  \"Berlin Sans FB\"                 \n [29] \"Broadway\"                        \"Bookshelf Symbol 7\"             \n [31] \"Calibri\"                         \"Calibri Light\"                  \n [33] \"Californian FB\"                  \"Calisto MT\"                     \n [35] \"Cambria\"                         \"Candara Light\"                  \n [37] \"Cascadia Code\"                   \"Cascadia Mono\"                  \n [39] \"Castellar\"                       \"Century Schoolbook\"             \n [41] \"Centaur\"                         \"Century\"                        \n [43] \"Chiller\"                         \"Colonna MT\"                     \n [45] \"Constantia\"                      \"Cooper Black\"                   \n [47] \"Copperplate Gothic Bold\"         \"Copperplate Gothic Light\"       \n [49] \"Corbel\"                          \"Corbel Light\"                   \n [51] \"Courier New\"                     \"Curlz MT\"                       \n [53] \"Dubai\"                           \"Dubai Light\"                    \n [55] \"Dubai Medium\"                    \"Ebrima\"                         \n [57] \"Elephant\"                        \"Engravers MT\"                   \n [59] \"Eras Bold ITC\"                   \"Eras Demi ITC\"                  \n [61] \"Eras Light ITC\"                  \"Eras Medium ITC\"                \n [63] \"Felix Titling\"                   \"Forte\"                          \n [65] \"Franklin Gothic Book\"            \"Franklin Gothic Demi\"           \n [67] \"Franklin Gothic Demi Cond\"       \"Franklin Gothic Heavy\"          \n [69] \"Franklin Gothic Medium\"          \"Franklin Gothic Medium Cond\"    \n [71] \"Freestyle Script\"                \"French Script MT\"               \n [73] \"Footlight MT Light\"              \"Gabriola\"                       \n [75] \"Gadugi\"                          \"Garamond\"                       \n [77] \"Georgia\"                         \"Gigi\"                           \n [79] \"Gill Sans MT\"                    \"Gill Sans MT Condensed\"         \n [81] \"Gill Sans Ultra Bold Condensed\"  \"Gill Sans Ultra Bold\"           \n [83] \"Gloucester MT Extra Condensed\"   \"Gill Sans MT Ext Condensed Bold\"\n [85] \"Century Gothic\"                  \"Goudy Old Style\"                \n [87] \"Goudy Stout\"                     \"Harrington\"                     \n [89] \"Haettenschweiler\"                \"Microsoft Himalaya\"             \n [91] \"HoloLens MDL2 Assets\"            \"HP Simplified\"                  \n [93] \"HP Simplified Light\"             \"HP Simplified Hans Light\"       \n [95] \"HP Simplified Hans\"              \"HP Simplified Jpan Light\"       \n [97] \"HP Simplified Jpan\"              \"High Tower Text\"                \n [99] \"Impact\"                          \"Imprint MT Shadow\"              \n[101] \"Informal Roman\"                  \"Ink Free\"                       \n[103] \"Blackadder ITC\"                  \"Edwardian Script ITC\"           \n[105] \"Kristen ITC\"                     \"Javanese Text\"                  \n[107] \"Jokerman\"                        \"Juice ITC\"                      \n[109] \"Kunstler Script\"                 \"Lucida Sans Unicode\"            \n[111] \"Wide Latin\"                      \"Lucida Bright\"                  \n[113] \"Leelawadee UI\"                   \"Leelawadee UI Semilight\"        \n[115] \"Lucida Fax\"                      \"Lucida Sans\"                    \n[117] \"Lucida Sans Typewriter\"          \"Lucida Console\"                 \n[119] \"Maiandra GD\"                     \"Malgun Gothic\"                  \n[121] \"Malgun Gothic Semilight\"         \"Marlett\"                        \n[123] \"Matura MT Script Capitals\"       \"Microsoft Sans Serif\"           \n[125] \"MingLiU-ExtB\"                    \"Mistral\"                        \n[127] \"Myanmar Text\"                    \"Modern No. 20\"                  \n[129] \"Mongolian Baiti\"                 \"MS Gothic\"                      \n[131] \"Microsoft JhengHei\"              \"Microsoft JhengHei Light\"       \n[133] \"Microsoft YaHei\"                 \"Microsoft YaHei Light\"          \n[135] \"Microsoft Yi Baiti\"              \"Monotype Corsiva\"               \n[137] \"MT Extra\"                        \"MV Boli\"                        \n[139] \"Niagara Engraved\"                \"Niagara Solid\"                  \n[141] \"Nirmala UI\"                      \"Nirmala UI Semilight\"           \n[143] \"Microsoft New Tai Lue\"           \"OCR A Extended\"                 \n[145] \"Old English Text MT\"             \"Onyx\"                           \n[147] \"MS Outlook\"                      \"Palatino Linotype\"              \n[149] \"Palace Script MT\"                \"Papyrus\"                        \n[151] \"Parchment\"                       \"Perpetua\"                       \n[153] \"Microsoft PhagsPa\"               \"Playbill\"                       \n[155] \"Poor Richard\"                    \"Pristina\"                       \n[157] \"Rage Italic\"                     \"Ravie\"                          \n[159] \"MS Reference Sans Serif\"         \"MS Reference Specialty\"         \n[161] \"Rockwell Condensed\"              \"Rockwell\"                       \n[163] \"Rockwell Extra Bold\"             \"Sans Serif Collection\"          \n[165] \"Script MT Bold\"                  \"Segoe MDL2 Assets\"              \n[167] \"Segoe Fluent Icons\"              \"Segoe Print\"                    \n[169] \"Segoe Script\"                    \"Segoe UI\"                       \n[171] \"Segoe UI Light\"                  \"Segoe UI Semilight\"             \n[173] \"Segoe UI Black\"                  \"Segoe UI Emoji\"                 \n[175] \"Segoe UI Historic\"               \"Segoe UI Semibold\"              \n[177] \"Segoe UI Symbol\"                 \"Segoe UI Variable\"              \n[179] \"Showcard Gothic\"                 \"SimSun\"                         \n[181] \"SimSun-ExtB\"                     \"Sitka Text\"                     \n[183] \"Snap ITC\"                        \"Stencil\"                        \n[185] \"Sylfaen\"                         \"Symbol\"                         \n[187] \"Microsoft Tai Le\"                \"Tw Cen MT\"                      \n[189] \"Tw Cen MT Condensed\"             \"Tw Cen MT Condensed Extra Bold\" \n[191] \"Tempus Sans ITC\"                 \"Times New Roman\"                \n[193] \"Trebuchet MS\"                    \"Verdana\"                        \n[195] \"Viner Hand ITC\"                  \"Vladimir Script\"                \n[197] \"Webdings\"                        \"Wingdings\"                      \n[199] \"Wingdings 2\"                     \"Wingdings 3\"                    \n[201] \"Yu Gothic\"                       \"Yu Gothic Light\"                \n[203] \"Yu Gothic Medium\"                \"ZWAdobeF\"                       \n\n\nI’m sure if there were something that got bypassed that I really needed I could get it directly with font_add(), but this is sure quick to get them all. Test a couple of the new ones.\n\nbaseiris + theme(axis.title.x = element_text(family = 'Poor Richard', face = 'italic'),\n                 axis.title.y = element_text(family = 'Stencil', face = 'bold'),\n                 legend.text = element_text(family = 'Papyrus'),\n                 legend.title = element_text(family = 'Onyx', face = 'bold.italic'))\n\n\n\n\nI have also put loadfonts in the functions folder so I can use it elsewhere."
  },
  {
    "objectID": "plotting/hcl_exploration.html",
    "href": "plotting/hcl_exploration.html",
    "title": "hcl exploration",
    "section": "",
    "text": "knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())\nUsing knitr::inline_expr(r message = FALSE, warning = FALSE) hopefully stops it printing all the package messages\nFinding colors to use for a given plot can be a pain. I’m trying to find some good color ramps for a project, and also sort out manipulating those colors to allow fading. This is me playing around to try to understand how to do those manipulations and looking at the various potential color palettes.\nColorspace (https://colorspace.r-forge.r-project.org/index.html) is a particularly useful package (though it is not the only color package I use).\nColorspace uses a hue-chroma-luminance specification for colors that is really powerful. It also has built-in palettes. For some other work, I was interested in exploring moving along those dimensions and generating color palettes for plotting.\nPreviously (for the project that gave rise to looking at fading colors), I was using purples and emerald, so let’s start there. But for simplicity switch to greens so constant hue.\nI actually like those single-hue fades a lot for showing more or less of something. But it SHOULD be possible to do a hue shift from green to purple for one axis? will that make sense?"
  },
  {
    "objectID": "plotting/hcl_exploration.html#hue-sequences",
    "href": "plotting/hcl_exploration.html#hue-sequences",
    "title": "hcl exploration",
    "section": "Hue sequences",
    "text": "Hue sequences\nI’d like to be able to specify the endpoints of a hue sequence and just shift along that axis. I’ll try it out with the purple and green above.\nFirst, I want to try to get the hue values (and the L and C as well) to make the endpoints. I can’t find a straightforward extraction in colorspace to get the HCLs though. So, since I know the endpoints are coming from those palettes above, I want their values. Make the palette, turn it into RGB, then turn the RGB into polarLUV to get the three axis values. Here, rows are the 8 fades in the palettes above.\n\nrgbpurps <- hex2RGB(sequential_hcl(8, 'Purples'))\n\nluvpurps <- as(rgbpurps, 'polarLUV')\nluvpurps\n\n            L         C        H\n[1,] 19.88570 55.128356 274.8415\n[2,] 34.37280 69.304529 274.3131\n[3,] 47.99202 56.799744 273.3506\n[4,] 60.90031 43.200021 272.3221\n[5,] 72.77975 31.772302 271.4182\n[6,] 83.46538 21.076091 271.6285\n[7,] 92.78865 10.863733 268.7090\n[8,] 98.79258  2.985742 276.3941\n\n\nThat’s sure roundabout, going palette that’s polarLUV under the hood but returns in hex to rgb and then back to polarLUV. Seems to work though.\n\nswatchplot(hex(luvpurps))\n\n\n\n\n\nrgbgrns <- hex2RGB(sequential_hcl(8, 'Greens'))\n\nluvgrns <- as(rgbgrns, 'polarLUV')\nluvgrns\n\n            L         C        H\n[1,] 25.06952 33.792199 132.8916\n[2,] 40.15678 49.456834 132.0640\n[3,] 54.06676 63.854764 129.4059\n[4,] 66.47833 62.340742 126.5380\n[5,] 77.49000 47.581607 123.8001\n[6,] 86.86700 33.248323 120.6451\n[7,] 93.95644 19.112933 117.4570\n[8,] 98.08100  5.367478 116.7639\n\n\nI can swatchplot them up together.\n\nswatchplot(hex(luvpurps), hex(luvgrns))\n\n\n\n\nNow, the goal is actually to identify those dark colors and transition between them. Now, can I get from purple to green? The L and C are quite different, unfortunately. Pick something the middle?\nHardcode numbers for now, though ideally we’ll get to a function that takes a start and end value.\n\npg <- polarLUV(L = 20, C = 40, H = seq(from = 130, to = 275, length.out = 8))\nswatchplot(hex(pg))\n\nWarning in max(nchar(rnam) - 1L): no non-missing arguments to max; returning\n-Inf\n\n\n\n\n\nThat fails. So, now we learned the ranges of the other axes matter. Likely chroma?\n\n# Fails\nmax_chroma(h = seq(from = 130, to = 275, length.out = 8), l = 20)\n\n[1] 29.55000 19.90429 16.62571 16.05429 17.74000 23.18000 41.07429 66.11000\n\n\nCan I just use the minimum max_chroma? Not really…\n\n# Guessing I can't just go with 16, but let's try\npg <- polarLUV(L = 20, C = 16, H = seq(from = 130, to = 275, length.out = 8))\nswatchplot(hex(pg))\n\n\n\n\nIf I try to fix how dark that is with chroma, it doesn’t work very well and I still lose one.\n\npg <- polarLUV(L = 20, \n               C = max_chroma(h = seq(from = 130, to = 275, length.out = 8), l = 20),\n               H = seq(from = 130, to = 275, length.out = 8))\nswatchplot(hex(pg))\n\n\n\n\nUsing a matrix isn’t the answer- same thing, though a floor argument puts the missing color back\n\nhclmat <- cbind(20, max_chroma(h = seq(from = 130, to = 275, length.out = 8), l = 20, floor = TRUE),\n      seq(from = 130, to = 275, length.out = 8))\n\npg <- polarLUV(hclmat)\nswatchplot(hex(pg))\n\n\n\n\nGuessing I don’t want to just turn up luminance, but let’s see what that does to get a better sense how this all works.\n\nhclmat <- cbind(80, max_chroma(h = seq(from = 130, to = 275, length.out = 8), l = 80, floor = TRUE),\n                seq(from = 130, to = 275, length.out = 8))\n\npg <- polarLUV(hclmat)\nswatchplot(hex(pg))\n\n\n\n\nLower luminance does work OK, but it’s still ‘darker’ in the middle and the shift to blue on the right is abrupt. The darker middle is likely why a lot of the colorspace palettes have triangular luminance. I don’t particularly want to get so fine-tuned here. I was looking for a way to programatically define these sequences, and getting into tweaking luminance in a nonlinear and nonmonotonic way could get very bespoke very quickly. Likely better to just use the built-in palettes where someone who understands color theory has already done that.\n\nhclmat <- cbind(50, max_chroma(h = seq(from = 130, to = 275, length.out = 8), l = 50, floor = TRUE),\n                seq(from = 130, to = 275, length.out = 8))\n\npg <- polarLUV(hclmat)\nswatchplot(hex(pg))"
  },
  {
    "objectID": "plotting/hcl_exploration.html#fading",
    "href": "plotting/hcl_exploration.html#fading",
    "title": "hcl exploration",
    "section": "Fading",
    "text": "Fading\nI also want to make faded versions of palettes, and control levels of fade. The particular use I have in mind is to illustrate levels of uncertainty, but it could be any bivariate outcomes.\nI originally thought that I would need to manually adjust the chroma and luminance manually. But the exploration above suggests they interact and so it’s unlikely to just shift one or the other. Still, colorspace provides lighten, darken (which both shift luminance), and desaturate, which shifts chroma. I should be able to play with these to see how they work using either a homebrew base palette as above or the inbuilt ones.\nIn either case, we need the hex values\n\nhexcols <- hex(pg)\n\nLighten (increase luminance)\n\nswatchplot('orig' = hexcols,\n           '25' = lighten(hexcols, amount = 0.25),\n           '50' = lighten(hexcols, amount = 0.5),\n           '75' = lighten(hexcols, amount = 0.75),\n           '100' = lighten(hexcols, amount = 1))\n\n\n\n\nDarken (decrease luminance)\n\nswatchplot('orig' = hexcols,\n           '25' = darken(hexcols, amount = 0.25),\n           '50' = darken(hexcols, amount = 0.5),\n           '75' = darken(hexcols, amount = 0.75),\n           '100' = darken(hexcols, amount = 1))\n\n\n\n\nDesaturate (adjust chroma)\n\nswatchplot('orig' = hexcols,\n           '25' = desaturate(hexcols, amount = 0.25),\n           '50' = desaturate(hexcols, amount = 0.5),\n           '75' = desaturate(hexcols, amount = 0.75),\n           '100' = desaturate(hexcols, amount = 1))\n\n\n\n\nFor my particular use, I like desaturating better, in that it implies less information. But it also makes the values look more similar across the range, and we don’t want that. That gets captured better by lightening.\nAs a bit of an aside, the ends of the lightened versions are effectively ‘Purples’ and ‘Greens’, reading down instead of across. What does it look like if I desaturate those built-in palettes?\n\npurp8 <- sequential_hcl(8, 'Purples')\nswatchplot('orig' = purp8,\n           '25' = desaturate(purp8, amount = 0.25),\n           '50' = desaturate(purp8, amount = 0.5),\n           '75' = desaturate(purp8, amount = 0.75),\n           '100' = desaturate(purp8, amount = 1))\n\n\n\n\nIt does remove color, but it perceptually darkens as well, which is NOT what I want.\nWhat about choosing a pre-built set of colors and lightening/darkening? Start with viridis, we know it has good properties in greyscale, etc.\n\nvir8 <- sequential_hcl(8, 'Viridis')\nswatchplot('orig' = vir8,\n                 '25' = lighten(vir8, amount = 0.25),\n                 '50' = lighten(vir8, amount = 0.5),\n                 '75' = lighten(vir8, amount = 0.75),\n                 '100' = lighten(vir8, amount = 1))\n\n\n\n\nThat actually works pretty well, even though the original had a luminance ramp on it already (https://colorspace.r-forge.r-project.org/articles/approximations.html), this just shifts it each time, I think. We can compare using specplot.\n\nspecplot(vir8, lighten(vir8, amount = 0.75))\n\n\n\n\nWhat does a desaturated viridis look like?\n\nswatchplot('orig' = vir8,\n           '25' = desaturate(vir8, amount = 0.25),\n           '50' = desaturate(vir8, amount = 0.5),\n           '75' = desaturate(vir8, amount = 0.75),\n           '100' = desaturate(vir8, amount = 1))\n\n\n\n\nAgain, makes them more similar, though the underlying luminance ramp helps. I don’t like that the first level still ends up darker though.\n\nInteracting chroma and luminance\nSo, changing luminance makes colors brighter or darker, while adjusting chroma removes color but tends to make them darker. Neither is exactly what I want- a color ramp that look the same, just “faded”. Is the answer to control this interaction? Does a simultaneous lighten and desaturate give me what I want by avoiding the perceptual darkening from the desaturation?\n\nswatchplot('orig' = vir8,\n           '25' = desaturate(vir8, amount = 0.25) %>%\n             lighten(amount = 0.25),\n           '50' = desaturate(vir8, amount = 0.5) %>%\n             lighten(amount = 0.5),\n           '75' = desaturate(vir8, amount = 0.75) %>%\n             lighten(amount = 0.75),\n           '100' = desaturate(vir8, amount = 1) %>%\n             lighten(amount = 1))\n\n\n\n\nThat works really well, actually. Does the order of operations matter? No:\n\nswatchplot('orig' = vir8,\n           '25' = lighten(vir8, amount = 0.25) %>%\n             desaturate(amount = 0.25),\n           '50' = lighten(vir8, amount = 0.5) %>%\n             desaturate(amount = 0.5),\n           '75' = lighten(vir8, amount = 0.75) %>%\n             desaturate(amount = 0.75),\n           '100' = lighten(vir8, amount = 1) %>%\n             desaturate(amount = 1))\n\n\n\n\nDid I just get lucky with viridis, or does it work with other palettes too? how about my ramp that I made from green to purple? Seems to:\n\nswatchplot('orig' = hexcols,\n           '25' = lighten(hexcols, amount = 0.25) %>%\n             desaturate(amount = 0.25),\n           '50' = lighten(hexcols, amount = 0.5) %>%\n             desaturate(amount = 0.5),\n           '75' = lighten(hexcols, amount = 0.75) %>%\n             desaturate(amount = 0.75),\n           '100' = lighten(hexcols, amount = 1) %>%\n             desaturate(amount = 1))\n\n\n\n\nDoes the lighten and desat work for the single-hue scales? Seems like it shouldn’t because they’re already changing along those axes.\n\nswatchplot('orig' = purp8,\n           '25' = lighten(purp8, amount = 0.25) %>%\n             desaturate(amount = 0.25),\n           '50' = lighten(purp8, amount = 0.5) %>%\n             desaturate(amount = 0.5),\n           '75' = lighten(purp8, amount = 0.75) %>%\n             desaturate(amount = 0.75),\n           '100' = lighten(purp8, amount = 1) %>%\n             desaturate(amount = 1))\n\n\n\n\nNot really. It basically does what it should, but the light end is just always light and so doesn’t contain info in the faded dimension and very similar colors appear in both dimensions- values at row n and col m are frequently very similar to row n + 1 and col m - 1.\nI suppose that might be OK for particular situations, but still not ideal. Might work ok though if we limited that lower end? ie don’t let it fall all the way to white in the original? Getting pretty hacky at that point and the diagonals are still too similar.\n\nswatchplot('orig' = purp8[1:6],\n           '25' = lighten(purp8[1:6], amount = 0.25) %>%\n             desaturate(amount = 0.25),\n           '50' = lighten(purp8[1:6], amount = 0.5) %>%\n             desaturate(amount = 0.5),\n           '75' = lighten(purp8[1:6], amount = 0.75) %>%\n             desaturate(amount = 0.75),\n           '100' = lighten(purp8[1:6], amount = 1) %>%\n             desaturate(amount = 1))\n\n\n\n\n\nTesting with other palettes\nViridis and the one I made are both fine, but look at a couple other palettes too. This is not comprehensive, mostly looking at those that have greens and purples for the use I have in mind.\nWrite a little function to do the fade and make this less cut and paste\n\npalcheck <- function(palname, n = 8) {\n pal8 <- sequential_hcl(n, palname)\n \n swatchplot('orig' = pal8,\n            '25' = lighten(pal8, amount = 0.25) %>%\n              desaturate(amount = 0.25),\n            '50' = lighten(pal8, amount = 0.5) %>%\n              desaturate(amount = 0.5),\n            '75' = lighten(pal8, amount = 0.75) %>%\n              desaturate(amount = 0.75),\n            '100' = lighten(pal8, amount = 1) %>%\n              desaturate(amount = 1))\n \n}\n\nPlasma\n\npalcheck('Plasma')\n\n\n\n\nGreen-based\nag_GrnYl is OK, but does get a bit of the diagonal issue\n\npalcheck('ag_GrnYl')\n\n\n\n\nditto Emrld, but might work?\n\npalcheck('Emrld')\n\n\n\n\nTerrains might be OK? 2 is less gaudy\n\npalcheck('Terrain')\n\n\n\npalcheck('Terrain2')\n\n\n\n\nmints and TealGrn fail diagonal test\n\npalcheck('Dark Mint')\n\n\n\npalcheck('Mint')\n\n\n\npalcheck('TealGrn')\n\n\n\n\nYlGn is pretty good, actually.\n\npalcheck('YlGn')\n\n\n\n\nFor the specific use, keep in mind that it will be two levels of fade, and so I can do something like orig and 75% and it’ll be pretty different. But here I’m trying to be fairly general.\nMeh\n\npalcheck('BluGrn')\n\n\n\n\nas expected, batlow and Hawaii are extreme, though might be OK?\n\npalcheck('Batlow')\n\n\n\npalcheck('Hawaii')\n\n\n\n\nPurple-based\nsingle hue doesn’t work\n\npalcheck('Purples')\n\n\n\npalcheck('Purples 3')\n\n\n\n\nthese are all maybes with tricky diagonals\n\npalcheck('Purple-Blu')\n\n\n\npalcheck('Purple-Ora')\n\n\n\npalcheck('Purp')\n\n\n\npalcheck('PurpOr')\n\n\n\npalcheck('Sunset')\n\n\n\npalcheck('Magenta')\n\n\n\npalcheck('SunsetDark')\n\n\n\n\npretty good, but have a fair amount of green in, so could be confusing\n\npalcheck('Purple-Yellow')\n\n\n\npalcheck('Viridis')\n\n\n\npalcheck('Mako')\n\n\n\n\nPlasma pretty good\n\npalcheck('Plasma')\n\n\n\n\nInferno might actually be pretty good if I cut off the first one\n\npalcheck('Inferno')\n\n\n\n\nag_Sunset is better on the diagonals than similar hue sequences\n\npalcheck('ag_Sunset')\n\n\n\n\nGood, but would need to cut the last one; too white. It is less gaudy/ more obviously a hue ramp than ag sunset. Diagonals are tricky too\n\npalcheck('RdPu')\n\n\n\n\nPretty good, but blue could be an issue getting confused with water for this project.\n\npalcheck('BuPu')\n\n\n\n\n\n\n\nContinuous hue from specified palettes\nIf I want to map values to colors continously, that gets tricky using the specified palettes because sequential_hcl takes an n argument.\nCan I get the endpoints and make my own (as I did above with green and purple?)\ndoes the one I’m using use a linear hue scale\n\nspecplot(sequential_hcl(8, 'ag_Sunset'))\n\n\n\n\nIt does, but doesn’t use linear chroma. and it has luminance shift too.\nCan I extract the hue from the ends? The same way I did right at the beginning for the greens and purples.\n\nspecplot(sequential_hcl(2, 'ag_Sunset'))\n\n\n\nrgbsun <- hex2RGB(sequential_hcl(8, 'ag_Sunset'))\n\nluvsun <- as(rgbsun, 'polarLUV')\nluvsun\n\n            L         C          H\n[1,] 25.00933  69.80052 274.922758\n[2,] 33.57582  78.49556 296.995075\n[3,] 42.09671  87.16488 318.944488\n[4,] 50.70304  96.81962 341.141446\n[5,] 59.33484 102.07413   3.730076\n[6,] 67.89723  89.83472  25.626328\n[7,] 76.47041  74.80664  47.677726\n[8,] 84.95182  45.16493  69.593540\n\n\nThis generates the wrong thing (roughly, viridis) because the hue crosses 0\n\nsunmat <- cbind(seq(from = 85, to = 25, length.out = 8), \n                max_chroma(h = seq(from = 69, to = 275, length.out = 8), \n                           l = seq(from = 85, to = 25, length.out = 8), \n                           floor = TRUE),\n                seq(from = 69, to = 275, length.out = 8))\n\npgsun <- polarLUV(sunmat)\nswatchplot(hex(pgsun))\n\n\n\n\nCan I fix the zero-crossing? I’m sure there’s a polar coord package, but for now, add a 360 and take it off\n\nhvec <- seq(from = luvsun@coords[1, 3], to = 360+luvsun@coords[8,3], length.out = 8)\nhvec[hvec > 360] <- hvec[hvec>360]-360\n\nlvec <- seq(from = luvsun@coords[1, 1], to = luvsun@coords[8, 1], length.out = 8)\n\nThe max_chroma is intense, but not sure how else to choose the chromas if we’re trying to build a continuous ramp. Could just use n = 1000 or something to get pseudo-continuous\n\nsunmat <- cbind(lvec, \n                max_chroma(h = hvec, \n                           l = lvec, \n                           floor = TRUE),\n                hvec)\n\npgsun <- polarLUV(sunmat)\nswatchplot(hex(pgsun))\n\n\n\n\nSo, one option is just treating the built-in palettes as their endmembers like that and then doing it as I did before. But it does lose the actual built-in palettes, especially chroma or nonlinearity. Likely better to just use a large n for now and call it good."
  },
  {
    "objectID": "plotting/math_in_ggplot.html#using-latex2exp",
    "href": "plotting/math_in_ggplot.html#using-latex2exp",
    "title": "Math and greek in legends",
    "section": "Using latex2exp",
    "text": "Using latex2exp\n\nlibrary(ggplot2) \nlibrary(latex2exp)\n\nLet’s just try to do some things with that. Make the usual iris plot.\n\ntestplot <- ggplot(iris, aes(x = Sepal.Length, y = Petal.Width, color = Species)) +\n  geom_point()\ntestplot\n\n\n\n\nNow let’s add some math. I’d typically use labs for the x,y, and color, so try that. Spacing not great, but it works.\nBasically following the manual, it’s pretty self-explanatory.\nThe r says to use raw strings so don’t have to escape slashes.\n\ntestplot <- testplot + \n  labs(x = TeX(r'(Words and greek $\\Delta_1$)'),\n       y = TeX(r'($\\frac{1-\\alpha}{\\rho})'),\n       color = TeX(r'($\\left{ \\int_0^\\inf \\exp{\\eta x} dx \\right})'))\n\ntestplot\n\n\n\n\nCan I use amsmath in latex? Maybe, but not for linebreaks- this errors.\n\ntestplot <- testplot + \n  labs(x = TeX(r'(Words and greek $\\Delta_1$)'),\n       y = TeX(r'($\\frac{1-\\alpha}{\\rho}$)'),\n       color = TeX(r'($\\begin{split}\\left{ \\int_0^\\inf \\\\ \\exp{\\eta x} dx \\right}\\end{split}$)'))\n\ntestplot"
  },
  {
    "objectID": "plotting/tweaks_tricks.html#theming",
    "href": "plotting/tweaks_tricks.html#theming",
    "title": "Theming and saving",
    "section": "Theming",
    "text": "Theming\nI tend to establish a theme to set the basic plot look, including font sizes. I start with theme_bw() because the default ggplot grey background doesn’t look good in pubs. I used to set the sizes separately for each sort of text (commented out), but that is typically easier to just use the base_size argument and let ggplot handle the relative adjustments.\nCan also set theme differently for presentations, including doing things like setting font to match a ppt theme.\nTypically, very few fonts are loaded into R and available for use. See fonts.Rmd for figuring out how to work with that. The short answer is that we use showtext to load what we need (if anything). If this step is skipped, will default to the default font and throw a warning about “fontfamily not found” because we haven’t loaded the selected font yet.\nWe could load fonts by hand Using functions from showtext and sysfonts, and specify the text = element_text(family=\"Ink Free\") with a manual character vector. It’s way easier to automate though, and saves issues of loading the wrong font.\nFirst, load the function I wrote that simplifies finding the files and their names to load them. And tell R to use showtext to render fonts.\n\nprint(file.path('functions', 'loadfonts.R'))\n\n[1] \"functions/loadfonts.R\"\n\nsource(file.path('functions', 'loadfonts.R'))\nshowtext::showtext_auto()\n\nThen, load the font(s) we want\n\ntalkfont <- 'Ink Free'\npubfont <- 'Cambria'\nloadfonts(fontvec = c(talkfont, pubfont))\n# loadfonts()\n\nNote that we could also just loadfonts() with no arguments to read in ALL available fonts\nPass talkfont and pubfont to the themes.\n\ntalktheme <- theme_bw(base_size = 18) + \n  theme(strip.background = element_blank(),\n        plot.background = element_blank(),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        text = element_text(family=talkfont)) # Replace with fontname used in PPT\n\n# \n        # axis.text = element_text(size = 18),\n        # axis.title = element_text(size = 24),\n        # strip.text = element_text(size = 24),\n        # plot.title = element_text(size = 24))\n\npubtheme <- theme_bw(base_size = 10) + \n  theme(strip.background = element_blank(),\n        plot.background = element_blank(),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        text = element_text(family=pubfont))\n\nAs an example, let’s make a simple plot with iris, and then look at the themed versions.\n\nbaseiris <- ggplot(iris, aes(x = Sepal.Length, y = Petal.Width, color = Species)) +\n  geom_point()\nbaseiris\n\n\n\n\nNow, what does a publication version look like?\n\nbaseiris + pubtheme\n\n\n\n\nNote that further theme changes can happen later on, e.g. Note that it’s easy to get in trouble with the internal legend positions when it comes time to save- as the dimensions change on export vs whatever arbitrary size you have the Rstudio plot pane, what looks good will changes as well.\n\nbaseiris + pubtheme +\n  theme(legend.title = element_text(face = 'bold'),\n        legend.position = c(0.8,0.2))\n\n\n\n\nFor talks, we use talktheme. Terrible font, but easy to see that it’s been shifted from default.\n\nbaseiris + talktheme\n\n\n\n\nWe can update parts of the theme including the font while keeping the rest. Though if we haven’t loaded all fonts, will need to load the new ones now.\n\n# load new font\nloadfonts(fontvec = 'Elephant')\n\ntalktheme <- talktheme + \n  theme(text = element_text(family = 'Elephant')) # Replace with fontname used in PPT\n\nAnd to show that it worked, plot again.\n\nbaseiris + talktheme"
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Research",
    "section": "",
    "text": "Placeholder, research goes here in sections, needs pics and short blurbs"
  },
  {
    "objectID": "research.html#cv-google-scholar-etc",
    "href": "research.html#cv-google-scholar-etc",
    "title": "Research",
    "section": "CV, google scholar, etc",
    "text": "CV, google scholar, etc"
  },
  {
    "objectID": "RpyEnvs/managingprivate.html",
    "href": "RpyEnvs/managingprivate.html",
    "title": "Private data and website",
    "section": "",
    "text": "I’m getting set up to use github pages to host a website. But some content I (might) host needs to be private. A clear option is to simply mock-up data matching that private data, and that’s the way I’ll go. But because a large part of the content here will be sorting through issues, the initial sort-through will likely depend on figuring out what it is about the private data that needs to be mocked-up, and some portion of the testing will depend on that data. And I want all of that to be version controlled, but not shared publicly. In short, I need a private development location, and then go through, make a clean version based on mocked-up data, and publish that. So, how?\nThe first thing that came to mind is to just have a local-only branch that I keep private. I could have a private/ folder, where I do dev, with that folder ignored in the master .gitignore. And have a different .gitignore in another branch so development would be tracked in that other branch. Then, as things were ready to make public, I could just drop them over. However, because github requires the whole github pages repo to be public, I would never be able to push this branch. Sure, people would be unlikely to poke around in it, but it would all be there. And if I ever forgot the process, I would expose things. And I don’t want to lose a cloud-hosted version- only storing locally isn’t so great, even if it is backed up or dropboxed.\nI’m now leaning towards having a second, private repo for development, and then drag and drop into the github pages repo once the doc I’m working on is clean. That’s basically the same idea as the internal private/ folder, but as a whole different repo, and so could actually be held as a private repo on github. There are two main catches that I can see with this approach at the outset-\n\nThe actual development history of files won’t be available on the public repo. That’s kind of the point, but it is a bit annoying\nKeeping the two repos synced will be a pain. If I make a small change to a file that’s already public in the public repo, I’d need to get it back into the other. The obvious solution is to do everything in the private, and then move things over. But if I make a small change to a file that’s already moved to the public repo in the private repo, I need to make sure it moves.\n\nI think I’ve dealt with this issue before, but can’t remember the details. I had a repo as a fork of another that was upstream or something. Will need to sort that out. It’s essentially a repo-diff, but needing to check what should be diff (still private), vs. what shouldn’t be a diff (a change that needs to move over).\n\n\nIs there a better solution that allows building from somewhere other than github pages, and so could use a private repo? Netlify would work. And might be better anyway. But if the whole point is to make messy code public, then we want it on a public repo, right? And just hold the private stuff back/ do it elsewhere."
  },
  {
    "objectID": "RpyEnvs/python_setup.html",
    "href": "RpyEnvs/python_setup.html",
    "title": "Python setup",
    "section": "",
    "text": "I’m working on a Python project, and trying to figure out how to set up and get started. I’m used to R, where most simply, all I have to do is download R, Rstudio, and then start coding. R doesn’t need any environment manager to get going, but I do tend to use renv to manage packages, but that’s pretty lightweight and straightforward. And I can start coding without it.\nPython, on the other hand, is more opaque. In part it’s because I’m new to it, but a bit of googling suggests I’m not the only one. It’s likely also because there’s no one dedicated IDE/workflow that almost everyone uses, a la Rstudio (maybe that will change with the Rstudio–> Posit move?).\nSo, I’m going to work out getting setup to code in Python (I sorta did it before, but I’m trying a new way with fewer black boxes). And using this as a place to write notes/what I did as I go. That means this might end up being less a tutorial and more a series of pitfalls, but we’ll see how it goes.\n\n\nI’m trying to get set up to manage Python versions themselves with pyenv and packages with poetry. As far as I can tell, poetry does approximately similar things to renv (but more complicated because python). And I haven’t used something similar to pyenv to manage R versions themselves, but I am about to have to figure that out too because a lot of packages broke when I moved to R 4.2. Will probably try rig, and write another one of these. I’m assuming I’ll code primarily in VS Code, unless Posit suddenly runs python like R (without reticulate). Even then, remote work will all use VS Code for the time being. I’m loosely following https://briansunter.com/blog/python-setup-pyenv-poetry and https://www.adaltas.com/en/2021/06/09/pyrepo-project-initialization/, and doing all the actual setup in VS Code, not Rstudio.\nRealising after I wrote this that I probably could have actually done all of this inside quarto- I think I can run powershell/system code in code blocks?"
  },
  {
    "objectID": "RpyEnvs/python_setup.html#getting-started--systemwide-installations",
    "href": "RpyEnvs/python_setup.html#getting-started--systemwide-installations",
    "title": "Python setup",
    "section": "Getting started- systemwide installations",
    "text": "Getting started- systemwide installations\nBoth those websites are working on Unix and Mac, so while step 1 is install pyenv, we aren’t going to apt-get or brew install. In fact, the pyenvgithub says we need to use a windows fork. Things already getting nonstandard. Should I just run everything in Windows Subsystem for Linux? Maybe, but I’d like to just use windows if possible, as much as I like WSL.\n\npyenv\nGuess I’ll just start at Quick start. Going to use powershell directly rather than inside vs code here, because vs code likes to open in recent directories instead of globally, and I think I want pyenv system-wide.\nStep 1- install in powershell with Invoke-WebRequest -UseBasicParsing -Uri \"https://raw.githubusercontent.com/pyenv-win/pyenv-win/master/pyenv-win/install-pyenv-win.ps1\" -OutFile \"./install-pyenv-win.ps1\"; &\"./install-pyenv-win.ps1\"\nCan’t run scripts (new computer). Sends me to https:/go.microsoft.com/fwlink/?LinkID=135170.\n\nSetting the policy to just the running process. Will probably regret that when I next try to run a script, but for now I don’t really want universal unrestricted powershell scripts.\n\nPowershell script permissions\nAside- it starts to get really annoying because pyenv runs scripts, so will need to fix. Get an error when I try to change Scope to CurrentUser because of a group policy. Setting it to Set-ExecutionPolicy -ExecutionPolicy Unrestricted -Scope LocalMachine seems to work, despite apparently being a larger set than my User.\nIt says it wasn’t installed successfully, but when I try again it says it’s there. I guess push on?\n\nStep 2 was just to shut down and reopen powershell\nStep 3- Run pyenv --version. If you haven’t changed policy to something larger than Process, this will fail because of the ExecutionPolicy. Guess I need to turn it back on. I kept doing one-offs for a while until I got annoyed and then set it to LocalMachine (see above).\nStep 4, pyenv install -l lists a million python versions. Seems like a good thing. I’m going to need older versions in projects, but for now, let’s install the latest.\nStep 5- the install of python. There’s a 3.12.a1, which I’m assuming means alpha, so I’ll go with pyenv install 3.11.0, which is the most recent without the .a1.\nThe install seems to have worked.\nStep 6- set global pyenv global 3.11.0\nStep 7- check it worked pyenv version \nStep 8- check python with python -c \"import sys; print(sys.executable)\"\nworks, gives me the path, \\.pyenv\\pyenv-win\\versions\\3.11.0\\python.exe\nNow it says to validate by closing and reopening- do that. Now pyenv --version gives the version, while pyenv alone tells us the commands. They’re also all at the github page I’m following.\nThen try in a vs code terminal, also works. Note that using the git bash terminal instead of powershell bypasses the script permissions issue if it hasn’t been set larger than Process.\nNow, we have Python 3.11 as the global python version, but should be able to install other versions and use them in local projects. Assuming I’ll get there once I set up poetry.\n\n\n\npoetry\nOnce again, the websites I’m following have commands for mac/unix, so back to the main poetry page to sort this out on windows.\nAgain, powershell command on windows. Could I use the git bash in vs? Maybe? Just stick with powershell. (Invoke-WebRequest -Uri https://install.python-poetry.org -UseBasicParsing).Content | python -.\nThe instructions say that last bit should be py instead of python if python not installed from Microsoft Store, but had to use python anyway.\nseems to have worked- \nThe instructions then have an advanced section I’m skipping, but that install message above seems to match step 3, where we add Poetry to the PATH in order to run Poetry by just running poetry and not the full path.\nI could change it with powershell, but the instructions I found involved a bunch of regex. Instead, search for “Advanced System Settings”, then in the bottom right, click Environment Variables, then in the System Variables box, click on Path, then Edit button, then New. That creates a blank line, paste in the path from poetry install, or use the one from their website, %APPDATA%\\Python\\Scripts. OK out of all the system settings boxes.\nShut down powershell, then fire it back up and run poetry --version. If the path setting failed, it won’t be able to find poetry, if it worked, it’ll give the version number.\nThat worked for me once, but now isn’t working the next day. Actually, it works in powershell, but not vs code powershell. It wasn’t unpacking the %APPDATA% correctly - running (Get-ChildItem env:path).Value lists %APPDATA% instead of the expanded directory. I stuffed the full path as in the screenshot above in the PATH, restarted VS Code and it works. Interestingly though, I left the %APPDATA% version there too, and it’s now unpacked when I run (Get-ChildItem env:path).Value."
  },
  {
    "objectID": "RpyEnvs/python_setup.html#setting-up-a-project",
    "href": "RpyEnvs/python_setup.html#setting-up-a-project",
    "title": "Python setup",
    "section": "Setting up a project",
    "text": "Setting up a project\nLet’s first say we’re going to use a different-than-standard version of python, so install that with pyenv. For this test, let’s just use 3.8.9. Not really any particular reason. So, run pyenv install 3.8.9\nNow, pyenv versions (NO FLAGS- the “--” flag will give the version of pyenv) shwos two versions with an asterisk by global.\n\n\nCreate the project\nJust need a directory and cd inside it, I think. I’ll make it inside the directory with this qmd. mkdir pytesting, cd pytesting. Actually, this yields too much nesting. poetry builds a directory for the project, and another directory in that, so this just yields annoying levels of nesting. Call poetry new (see below) from the directory you want to contain the main project directory.\n\n\nSet the python version\nI think just pyenv local 3.8.9. That creates a .python-version file in the directory, which seems to be the idea.\n\n\nSet poetry\nAm I going to completely screw up my R project having this inside it? Guess we’ll find out.\npoetry new pytesting then creates another directory and returns “Created package pytesting in pytesting”. It builds the outer directory, so don’t make one first or the nesting gets silly.\nThat directory seems to be establishing a standard package structure and the lockfiles etc. Opening the .toml looks like it didn’t pick up the python version though- it’s using 3.11. Hmmm. Tried killing and restarting powershell and it’s still doing that. Not sure why it’s not picking up the local python.\nIf I move up a directory, the pyenv versions returns back to 3.11. So pyenv seems to be working, but poetry’s not picking it up. I guess I can change in manually, but that’s annoying.\nSeems to be a long-running known issue- recent posts here https://github.com/python-poetry/poetry/issues/651. Ignore for now, maybe fix manually if it becomes an issue. I tried the solution in the last post (poetry config virtualenvs.prefer-active-python true), and it didn’t fix it. Tried completely starting over a few times. No luck. Worry about that later. I guess that means the pyenv stuff might be useless for the moment- will need to use the version poetry thinks it has in the directory. It does look like can reinstall poetry, but that seems like a pain. (No one else seems to have issues with the config above).\nSo, I’ve just set the pyenv to the global for now, and moving ahead with poetry for the project. I guess I could change pyenv global each time I switch projects as an annoying workaround if it becomes an issue. An answer might be poetry env use , see https://python-poetry.org/docs/managing-environments/.\n\n\nUsing poetry for dependencies\nMuch like renv can install all dependencies from info in renv.lock, we could build the project with dependencies from pyproject.toml. Or, also like renv, as we’re developing a project, we can add iteratively. Let’s do that, since that’s what we’re doing.\nThere seems to be an intermediate step here though, running poetry install to initialise a virtual environment from the .toml. I assume this would install whatever’s in the toml, but we don’t have anything at present. That apparently creates a virtual environment somewhere globally (.cache/, according to https://www.adaltas.com/en/2021/06/09/pyrepo-project-initialization/).\nAnd now I have poetry.lock . According to the docs, this takes precedence over the .toml, though I doubt that’s true for python version itself. This is what gets committed to share the project.\nTyping poetry shell at the command line activates the environment. But how do we activate it for a VS code session?\nSeems to just be active once we open a .py file in that directory (e.g. if we open the file, then a powershell at that location, it appears with pyenv shell already going.\nTo test adding a dependency, i’ll try numpy. First, I can run simply python code- a = 1 etc. But import numpy as np fails (as expected)- ModuleNotFoundError: No module named ‘numpy’. So, click back to the powershell terminal, and try poetry add numpy. It resolves dependencies and writes a lock file.\nAnd yet, if I try import numpy as np, same error. The poetry show command lists it as installed.\nSo, it’s because VScode doesn’t know where to find the venvs. On a one-off basis, can use poetry env info --path to get the path, then in VS code select interpreter (ctrl-shift-p for the search thingy), then paste in that path. But that’s annoying.\nI’m trying getting to the search thing, then User settings, then adding C:\\Users\\galen\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ to the venv Folders. That seems to work, but it may just be remembering from last time.\nThe most robust option might be to not keep the venvs in .cache but instead local to the project, as described here. Looks like that’s done with poetry config virtualenvs.in-project true at the very outset, and then rebuilding the project (and it should persist for future projects).\nAnd that’s what we’re doing in the project I’m doing this for. So let’s do that. First, run poetry env list to get the name, then poetry env remove NAME to delete. But it failed, seemingly partway. So also go to AppData\\Local\\pypoetry\\Cache\\virtualenvs and delete the folder. Restart vs and now poetry env list doesn’t return anything.\nTo set the config, poetry config virtualenvs.in-project true . I believe that’s global (I ran it outside the project).\nNow rebuild from .toml in the project with poetry install. The .venv is there now, but VS still can’t find it.\nOK, shut everything down, and instead of opening VS again as usual, I opened it and then opened a new window, and now it works. It was somehow setting the root based on where VS happened to open, rather than based on where files were. That probably makes sense for a git repo with just python, but broke here. I assume we need to add the venv directory to the gitignore.\nJust did poetry add pandas and it works and I immediately have access to it in a python script.\n\n\nVS code note\nSometimes VS seems to find the poetry venv and use it, and other times (I think if it’s not at the head dir of the workspace?) it needs to be pointed at the python.exe. To do that, open the command palette, (ctrl-shift-p), select python interpreter, then .venv\\scripts\\python.exe wherever that venv is."
  },
  {
    "objectID": "RpyEnvs/python_updated_functions.html",
    "href": "RpyEnvs/python_updated_functions.html",
    "title": "Updating function defs",
    "section": "",
    "text": "As I develop, I often try a function, tweak it, try again, etc. In R, I can just run the function definition to have access, or source(filewithfunction.R). In python, I could tweak the function, but just trying to use them elsewhere (e.g. in a .qmd) wasn’t working, even if I re-ran import filename. Clearly, there are differences between import in python and source in R. After poking around a bit, it looks like python caches on first import, and so subsequent ones don’t refresh.\nWhat does seem to work is to run importlib.reload(filename). Obviously we wouldn’t put that in a script, but when using an interactive session, it’s really helpful. Not sure why this requires a whole separate package, but it works. See stackoverflow. It appears to be typical to just restart, but that is really prohibitive if the testing involves processing data that took a long time to create."
  },
  {
    "objectID": "RpyEnvs/quarto_website_github.html",
    "href": "RpyEnvs/quarto_website_github.html",
    "title": "Quarto website",
    "section": "",
    "text": "I want to use quarto to build a website hosted on github pages. I have a few goals for it, but step one is to figure out how to do it.\nI’ve already started a github pages repo, and had started putting things in it before I realised I was probably not working in the best way (and some things needed to be private). So before any commits, I moved the work out and want to just start clean and see how to do it. I’ll walk through the process here.\nI’ll start by following the quarto docs, but may diverge. Using the Rstudio version, but will likely use a bit of VS too for python."
  },
  {
    "objectID": "RpyEnvs/quarto_website_github.html#set-up-github-pages",
    "href": "RpyEnvs/quarto_website_github.html#set-up-github-pages",
    "title": "Quarto website",
    "section": "Set up github pages",
    "text": "Set up github pages\nI did this a while ago, will come back to it.\nClone the repo locally."
  },
  {
    "objectID": "RpyEnvs/quarto_website_github.html#start-as-a-website-project",
    "href": "RpyEnvs/quarto_website_github.html#start-as-a-website-project",
    "title": "Quarto website",
    "section": "Start as a website project",
    "text": "Start as a website project\nCould I have converted from a normal project? Probably. And I could only get to the ‘quarto website’ option if I made a new directory. So even though I already cloned the repo from github, I put the project in a new dir, and then will copy it into the repo (I guess?).\nI actually made it in a dir, then started a git repo in that dir and set its remote to hit the url of my github.io repo following the instructions on github for starting a local repo and pointing it to github.\nProject seems to work when I click render, though it renders in browser not in Viewer pane (which is actually nicer, just not what the docs say).\nI had my repo in dropbox, as that seems like it usually works fine for other repos and gives another layer of backup. But it was failing here with lots of errors about files being in use by other processes. Moved it to Documents and seems to work fine."
  },
  {
    "objectID": "RpyEnvs/quarto_website_github.html#setting-up-nav",
    "href": "RpyEnvs/quarto_website_github.html#setting-up-nav",
    "title": "Quarto website",
    "section": "Setting up nav",
    "text": "Setting up nav\nI’m not entirely sure what I want the structure to be, but likely a brief home page, navbar at top with things like ‘Research’, ‘About’, ‘Code examples’, etc. Lots of options here, I guess just cobble something together quickly.\nOne question I have is what happens when I start committing to git. Does it auto-publish? It looks like no, according to quarto, if I set up to render to docs and don’t push master. Or if I publish from a gh-pages branch though that’s not working on windows.\nThe .yaml seems to be where all the website structure goes- nav bars, search, etc.\nI think I’m going to end up with something fairly complex for nav, but for now, maybe try broad categories across the top, then specifics down the side. Add additional nesting later.\nSeems reasonably ok, with ability to have sections within contents in the sidebar (I think)."
  },
  {
    "objectID": "RpyEnvs/quarto_website_github.html#questions",
    "href": "RpyEnvs/quarto_website_github.html#questions",
    "title": "Quarto website",
    "section": "Questions",
    "text": "Questions\nIf I render a single file, does it render the whole website? seems like yes. If I want to render single pages (like to test them without having to re-render everything), can use the terminal quarto render filename.qmd or a subdir quarto render subdir/. The output ends up in the _site directory."
  },
  {
    "objectID": "RpyEnvs/quarto_website_github.html#pushing-to-github",
    "href": "RpyEnvs/quarto_website_github.html#pushing-to-github",
    "title": "Quarto website",
    "section": "Pushing to github",
    "text": "Pushing to github\nThe publishing the gh-pages branch seems the nicest, but there’s a bit warning not to do that on Windows. So, I guess I’ll do the render to docs way.\nadd output-dir: docs to the _quarto.yml and then create a .nojekyll file. Then quarto render to render to docs. I think I’ll also add a _quarto.yml.local with\nexecute:\n  cache: true\nto cache output and avoid long re-renders ( I hope). Seems to- re-clicking render was much faster.\nTo set to docs, go to repo, then settings –> Pages (on left) –> deploy from a branch, and choose the branch (likely Main) and /docs instead of /root.\nSo, I’ve been developing on dev, I guess I’ll merge main and see what happens."
  },
  {
    "objectID": "RpyEnvs/RandPython.html",
    "href": "RpyEnvs/RandPython.html",
    "title": "Using R and python together",
    "section": "",
    "text": "knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())"
  },
  {
    "objectID": "RpyEnvs/RandPython.html#the-issue",
    "href": "RpyEnvs/RandPython.html#the-issue",
    "title": "Using R and python together",
    "section": "The issue",
    "text": "The issue\nI have a project primarily in R, but needs some python. For the big python work, I’ll have a directory with a poetry environment and python code. But I’ve run into the issue that I want to run just one or two lines of python from R. The specific case is that I have python code for extracting river gauge data, and I’ve filtered some river gauges in R for something else, and rather than do the finding of the gauges again in python, I’d rather just do the extraction in R. I think that means I have to sort out {reticulate}, but also how to point reticulate at my python environment. The situation I have is a poetry project inside a directory with an Rproj (which probably needs to be split up, but it’s what I have now).\nMy python_setup sets up a very similar situation, so let’s see if I can use it."
  },
  {
    "objectID": "RpyEnvs/RandPython.html#set-up-reticulate-from-r",
    "href": "RpyEnvs/RandPython.html#set-up-reticulate-from-r",
    "title": "Using R and python together",
    "section": "Set up reticulate from R",
    "text": "Set up reticulate from R\nPoint reticulate at the venv. See stackoverflow. This seems to not be necessary if the .venv is in the outer project directory.\n\nreticulate::use_virtualenv(file.path('RpyEnvs', 'pytesting', '.venv'), required = TRUE)\n\nLoad the library. Interestingly, the python code chunks will run without loading the library, but I can’t access their values using py$pythonobject unless I load it.\n\n# library(reticulate)"
  },
  {
    "objectID": "RpyEnvs/RandPython.html#r",
    "href": "RpyEnvs/RandPython.html#r",
    "title": "Using R and python together",
    "section": "R",
    "text": "R\nFirst, let’s create some things in R.\n\na <- 1\nb <- 2"
  },
  {
    "objectID": "RpyEnvs/RandPython.html#python",
    "href": "RpyEnvs/RandPython.html#python",
    "title": "Using R and python together",
    "section": "Python",
    "text": "Python\nDoes not just inherit the values from R, but runs.\n\na = 1\nb = 2\na+b\n\n3\n\n\nDo I have access to packages? Yes.\n\nimport numpy as np\n\nx = np.arange(15, dtype=np.int64).reshape(3, 5)\nx[1:, ::2] = -99\nx\n\narray([[  0,   1,   2,   3,   4],\n       [-99,   6, -99,   8, -99],\n       [-99,  11, -99,  13, -99]], dtype=int64)\n\n\nDoes access to python objects persist? Yes\n\nx.max(axis=1)\n\narray([ 4,  8, 13], dtype=int64)"
  },
  {
    "objectID": "RpyEnvs/RandPython.html#moving-data-back-and-forth",
    "href": "RpyEnvs/RandPython.html#moving-data-back-and-forth",
    "title": "Using R and python together",
    "section": "Moving data back and forth",
    "text": "Moving data back and forth\n\nPython to R\nCan I access objects with R? Yes, but not quite directly. Have to use the py$pythonObject notation. But only if I’ve loaded library(reticulate) or specified with reticulate::py. That’s a pain, so probably almost always better to load the library. Even though the python chunks run fine without explictly loading it, I can’t seem to access py without loading it.\n\n# x\nreticulate::py$x\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]    0    1    2    3    4\n[2,]  -99    6  -99    8  -99\n[3,]  -99   11  -99   13  -99\n\n\n\n\nR to python\nSimilar to python objects being in py, R objects are in r, and are accessed with . instead of $.\n\nc <- 17\n\nInterestingly, the r. notation to get R into python does not need reticulate:: on it. Which I guess makes some sense- this block is actually running in python and python doesn’t know what reticulate is. But it does know what r. is, somehow. Pretty cool.\n\nr.c + b\n\n19.0"
  },
  {
    "objectID": "RpyEnvs/rig.html",
    "href": "RpyEnvs/rig.html",
    "title": "Managing R versions",
    "section": "",
    "text": "I’ve update to R 4.2, but have projects that were built with 3.x. Some new versions of packages for R 4.x don’t work in 3.x, so I would need to update packages, but I know doing that will break things, and I don’t have time to do a full update of the project.\nI use renv to manage the packages, but not currently anything to switch/manage R versions itself. In python, there’s pyenv to manage python versions. I’ve run across rig (https://github.com/r-lib/rig)."
  },
  {
    "objectID": "RpyEnvs/rig.html#install",
    "href": "RpyEnvs/rig.html#install",
    "title": "Managing R versions",
    "section": "Install",
    "text": "Install\nclick on windows installer. Restart terminal. Type rig list to see what R is available."
  },
  {
    "objectID": "RpyEnvs/rig.html#using-it",
    "href": "RpyEnvs/rig.html#using-it",
    "title": "Managing R versions",
    "section": "Using it",
    "text": "Using it\nGo to the project I want to run, and figure out what version of R it was using. Interesting- it says 4.0.2 so maybe I didn’t need to worry about this? Whoops. Still interesting, I guess. And, just to avoid any issues, I still think I might downgrade to that to run the project because I really just need things to work.\nSo, try rig add 4.0.2. Seems to have worked. Set the default to current, though.\nrig default 4.2.1.\n\nChoosing for a project\nWhat if I just open the project file by double clicking? There’s no obvious way to change the R version just by opening Rstudio- it uses the default.\nI think there’s probably a way to use the CLI to change the R version and then double click, but what seems to be easiest is cd path/to/repo and then rig rstudio renv.lock to open with the version in the lockfile.\nAnd do I keep using other R versions elsewhere? Seem to. For now, this should do what I need."
  },
  {
    "objectID": "RpyEnvs/rig.html#installing-rtools",
    "href": "RpyEnvs/rig.html#installing-rtools",
    "title": "Managing R versions",
    "section": "Installing rtools",
    "text": "Installing rtools\nWe need rtools to install packages with compiled components. R 4.2 has updated to Rtools 42 (from 40), and so using previous versions of R need older Rtools. The telltale is when trying to install a package, we get errors about ‘make’ not being found. The rig documents imply that rig system update-rtools40 should work, but I get “Error: the system cannot find the path specified”. I’m not sure what path that is, so hard to fix. So, I seem to be OK until I need something that needs ‘make’, and then I’m out of luck.\n\nThe solution\nTo install Rtools40, needed for R 4.0- 4.1, run rig add rtools40. Seems to be all it took, now I can compile. I assume there’s a similar command for even older Rtools if need to downgrade to R 3.x, but haven’t tried."
  },
  {
    "objectID": "RpyEnvs/R_py_shared_projects.html",
    "href": "RpyEnvs/R_py_shared_projects.html",
    "title": "R and python envs in same project",
    "section": "",
    "text": "Both renv and poetry want to set up project structures and work within them. And I want to do both in the same git repo because I’m using both for the same project. And have access to both everywhere within the project (ie I want to be able to use reticulate, but more importantly I want the different parts of the project to be able to have both py and R components.\nI’ve done a bit getting them to work in the same script, and setting up clean python environments with poetry. With the shared scripts, I did it with a subdirectory, and that sort of worked for testing, but won’t work for a project where they’re both used a fair amount and in both places.\n\n\nCan I just initiate them both in the base git directory? I know i can with renv, but does poetry let us stick a project in an existing repo? When I was sorting out poetry, I always made a new dir with poetry new dirname.\nIt looks like py code should be in the inner directory of the poetry structure. Let’s assume that. Which roughly matches R structure, where we’ll have code in an R/ dir if it’s a package or in some other dir structure. IE, if we can just get the environment management into the outer dir of the repo, and then all other code inside. I’m not sure though that I’ll want to split py from R at present. Think about that.\nSo, really, the question is whether I can poetry new and poetry install in a dir that already exists.\nMaybe poetry init instead of poetry new? Asks a bunch of questions.\nIt creates a pyproject.toml file, and then poetry install creates the poetry.lockand .venv, but the rest of the structure’s not there (tests dir, second level of the project dir). Will it work? Probably. Do we want that structure? Probably.\n\n\n\nSo, maybe better to poetry new somewhere else and drag over, then poetry install. Does that work? I copied over everything inside the outer dir, since I want the whole project to share the outer dir. It makes the lock and venv, but I get ‘dirname does not contain any element’. I’m guessing because I made a poetry env with a different name. Try using the same name, then again copying over the internals.\nThat seems to work. Now to build the env so everything actually works. But that’s about project details, so I’ll leave this here.\nThat seemed to have made vs code happy- it can find a venv in the workspace and use it. It didn’t do that automatically when the venv was in a subdir. (I had to command palette- select python interpreter)."
  },
  {
    "objectID": "setup/rstudio_themes.html",
    "href": "setup/rstudio_themes.html",
    "title": "Editing Rstudio themes",
    "section": "",
    "text": "I really don’t like how faint the selection colours are for all of the dark themes. When I do a ‘find’, I don’t want to hunt around for dark grey on black. So to fix that, I need to edit the theme.\n\n\nI went to this massive list of themes, clicked ‘gallery’, chose the one I wanted (just a simple edit of Tomorrow Night, will save a more complex hunt for another day). Then the pane in the middle lets us change all the colours. I clicked the ‘General’ tab, and changed the lineHighlight and selection to a nice blue. I also changed the comment colour to green, not sure if I like that or not.\n\nThen, go to the ‘Info’ tab and change the name before downloading. Otherwise Rstudio won’t find it under a new name.\nDownload. This saves as a .tmTheme file, which I think might just be able to be used directly (see new Posit documentation, but I was looking at something old and so used rstudioapi::convertTheme('setup/Tomorrow Night HL.tmTheme', outputLocation = 'setup') to create a .rstheme file.\nThen global options, add, and select the theme. I had to restart Rstudio a couple times for it to take. The edited theme is available in the git for this website."
  },
  {
    "objectID": "simmodelling/twoDautocorr.html",
    "href": "simmodelling/twoDautocorr.html",
    "title": "2d autocorrelation",
    "section": "",
    "text": "knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())"
  },
  {
    "objectID": "simmodelling/twoDautocorr.html#motivation",
    "href": "simmodelling/twoDautocorr.html#motivation",
    "title": "2d autocorrelation",
    "section": "Motivation",
    "text": "Motivation\nI often need to simulate processes that are autocorrelated in two dimensions. Sometimes that’s time and 1d space, sometimes 2d space. Clearly 3d is likely needed as well, and I’ll update this with that once I get to it.\nThis is code that builds on work I’ve done in a couple projects, both across matlab and R. I’m doing it here in R because that’s the most up to date and open-source, but the matlab translation is straightforward.\nWe want to be able to generate a set of values with given statistical properties- means, standard deviations, and correlations in both dimensions. For the moment, I’m developing this with a gaussian random variable, but extensions to other random variables that are transforms from gaussian are relatively straightforward by backcalculating the needed \\(\\mu\\) and \\(\\sigma\\). Care must be taken if the correlations need to also be defined on the final scale.\n\nFuture/elsewhere\nI’ve done the back-calculations for the lognormal to allow setting desired correlations, means, and variances on the lognormal scale, and will add it in here later as an example. Likewise, we might want to set the correlation length \\(\\tau\\) rather than the correlation \\(\\rho\\), and in that case we need to back-calculate \\(\\rho\\) from the desired \\(\\tau\\). I’ve done that as well and will add it in. Finally, I have written up the math to obtain the equations used in this function, and will add that later as well."
  },
  {
    "objectID": "simmodelling/twoDautocorr.html#process",
    "href": "simmodelling/twoDautocorr.html#process",
    "title": "2d autocorrelation",
    "section": "Process",
    "text": "Process\nThe goal is a U matrix that is 2d AC, on the normal scale\n\nSet up autocorrelation in the y dimension in U with a usual \\(y+1 = y*\\rho + a\\) formulation, where \\(a\\) is uncorrelated errors\nSet up autocorrelation in the x dimension\n\n\n\nthe errors here (\\(\\varepsilon\\) matrix) need to be correlated in the y dimension\nthese errors are thus generated by an AC process and so need their own set of errors (which are uncorrelated) for that AC\n\nVariances are set for all error matrices (\\(a\\), \\(\\varepsilon\\), and sub-errors (\\(z\\) matrix)) according to the relationships between normVar (the desired \\(\\sigma^2\\) of the final distribution) and the \\(\\rho_y\\) and \\(\\rho_x\\) (the desired correlations in both dimensions)."
  },
  {
    "objectID": "simmodelling/twoDautocorr.html#function",
    "href": "simmodelling/twoDautocorr.html#function",
    "title": "2d autocorrelation",
    "section": "Function",
    "text": "Function\nI usually do a bunch of demos, but here I’ve developed this and just want it available more easily. So I’ll lead with the function and then demonstrate it and a few extensions.\n\nac2d <- function(n_x, n_y, \n                 rho_y = 0, rho_x = 0, \n                 normVar = 1,\n                 printStats = FALSE,\n                 returnStats = FALSE) {\n  # n_x = number of sites along the x-dimension\n  # n_y = number of sites along the y-dimension\n  # rho_y = desired autocorr in the x direction\n  # rho_x = desired autocorr in the y direction\n  # normVar = desired variance of the underlying normal distribution\n  \n  # The goal is a U matrix that is 2d AC, on the normal scale\n  \n  # make the U matrix as rnorms to initialise\n  U <- matrix(rnorm(n_x*n_y)*sqrt(normVar), nrow = n_y)\n  \n  # Set up the errors for the y process alone\n  # generate the errors - set the SD of these (hence the sqrt around the\n  # variance)\n  a <- rnorm(n_y) * sqrt((normVar*(1-rho_y^2)))\n  \n  # Make the y ac for the U matrix\n  for (i in 1:(n_y-1)) {\n    U[i+1, ] <- (rho_y * U[i, ]) + a[i]\n  }\n  \n  # Set up for the x-autocorr, which needs to have errors autocorred in the y-dimension\n  \n  # first, generate a z error matrix- these are the errors for epsilon, which\n  # are in turn the errors for U(t,x).\n  # What should var(z) be theoretically?\n  varZ <- normVar*(1-rho_y^2)*(1-rho_x^2)\n  \n  # Make z, adjusting its standard deviation\n  # should have 'y' rows\n  z <- matrix(rnorm(n_x*n_y), nrow = n_y) * \n    (sqrt(normVar * (1-rho_y^2) * (1-rho_x^2)))\n  \n  # now let's generate an epsilon matrix\n  # These are the errors for x part of the 2d ac process. These errors are\n  # themselves autocorrelated in the y dimension.\n  vareps <- normVar * (1-rho_x^2)\n  eps <- matrix(rnorm(n_x*n_y), nrow = n_y) * sqrt(vareps)\n  \n  # Now, generate the eps matrix y-autocorrelated (that is, going down rows within each column)\n  # eps is already created, so just write into the rows\n  for (i in 1:(n_y-1)) {\n    eps[i+1, ] <- (rho_y * eps[i, ]) + z[i, ]\n  }\n  \n  # Now, make the U matrix x-autocorrelated\n  for (t in 1:(n_x-1)) {\n    U[ ,t+1] <- (rho_x * U[ ,t]) + eps[ ,t]\n    \n  }\n  \n  # Check the stats if asked\n  if (printStats | returnStats) {\n    # calc stats in both dimensions\n    acstats <- ac2dstats(U)\n    \n    if (printStats) {\n      print(paste0('Mean of all points is ', round(mean(c(U)), 3)))\n      print(paste0('Var of all points is ', round(var(c(U)), 3)))\n      print(paste0('Mean y AC is ', round(mean(acstats$ac_y), 3)))\n      print(paste0('Mean x AC is ', round(mean(acstats$ac_x), 3)))\n    }\n  }\n  \n  # usually don't want a list with the stats, and can always get later if needed, I suppose\n  if (returnStats) {\n    return(lst(U, acstats))\n  } else {\n    return(U)\n  }\n  \n}\n\nThat potentially calls another function to get the stats, which is here.\n\n# 2d ac stats function, useful for calling elsewhere\nac2dstats <- function(acmatrix) {\n  # Calculate the autocorrs in both dimensions\n  \n  # Conditionals on 0 variance are because ar throws an error if there's no variance. Could have set up a try, but this is clearer\n  # Using 1 as the ac in that case because with no variance each value is the same as previous and so perfectly correlated. NA would be another option.\n  \n  # Get the ac in x-dimension: do this for each y (row)\n  ac_x <- vector(mode = 'numeric', length = nrow(acmatrix)-1)\n  for (i in 1:(nrow(acmatrix)-1)) {\n    if (sd(acmatrix[i, ]) == 0) {\n      ac_x <- 1\n    } else {\n      ac_x[i] <- acf(acmatrix[i, ], lag.max = 1, type = 'correlation', plot = FALSE, demean = TRUE)$acf[2]\n    }\n    \n  } \n  \n  # Get the ac acorss the stream: do this for each x (column)\n  ac_y <- vector(mode = 'numeric', length = ncol(acmatrix)-1)\n  for (i in 1:(ncol(acmatrix)-1)) {\n    \n    if (sd(acmatrix[,i]) == 0) {\n      ac_y[i] <- 1\n    } else {\n      ac_y[i] <- acf(acmatrix[ ,i], lag.max = 1, type = 'correlation', plot = FALSE, demean = TRUE)$acf[2]\n    }\n    \n  } \n  \n  return(lst(ac_y, ac_x))\n}"
  },
  {
    "objectID": "simmodelling/twoDautocorr.html#testing",
    "href": "simmodelling/twoDautocorr.html#testing",
    "title": "2d autocorrelation",
    "section": "Testing",
    "text": "Testing\nA couple edge cases to make sure it doesn’t break. 0 and 1 correlations.\n\nacmatrix_0_1 <- ac2d(n_x = 1000, n_y = 500,\n        rho_x = 0, rho_y = 1,\n        normVar = 1, printStats = TRUE)\n\n[1] \"Mean of all points is 0.028\"\n[1] \"Var of all points is 0.976\"\n[1] \"Mean y AC is 1\"\n[1] \"Mean x AC is 0.043\"\n\n\n0 variance, but try to set autocorrelations- forces all points equal, which is right.\n\nacmatrix_0_1 <- ac2d(n_x = 1000, n_y = 500,\n        rho_x = 0.7, rho_y = 0.9,\n        normVar = 0, printStats = TRUE)\n\n[1] \"Mean of all points is 0\"\n[1] \"Var of all points is 0\"\n[1] \"Mean y AC is 1\"\n[1] \"Mean x AC is 1\""
  },
  {
    "objectID": "simmodelling/twoDautocorr.html#demonstration",
    "href": "simmodelling/twoDautocorr.html#demonstration",
    "title": "2d autocorrelation",
    "section": "Demonstration",
    "text": "Demonstration\nHow do we use that? Let’s say we want to create an environment that is 1000 x 500 sites, with \\(\\rho_y = 0.9\\) and \\(\\rho_x = 0.7\\), with the whole environment having a variance of 1 (for simplicity).\nSetting printstats = TRUE prints out the statistics and confirms the final matrix has been created with the desired correlations.\n\nacmatrix_7_9 <- ac2d(n_x = 1000, n_y = 500,\n        rho_x = 0.7, rho_y = 0.9,\n        normVar = 1, printStats = TRUE)\n\n[1] \"Mean of all points is 0.021\"\n[1] \"Var of all points is 0.993\"\n[1] \"Mean y AC is 0.89\"\n[1] \"Mean x AC is 0.698\"\n\n\nWe can plot that up, easiest is to use ggplot because that’s what I’m used to. First, make it a tibble\n\nactib_7_9 <- tibble::as_tibble(acmatrix_7_9) %>%\n  mutate(y = row_number()) %>%\n  pivot_longer(cols = starts_with('V')) %>%\n  mutate(x = as.numeric(str_remove(name, 'V'))) %>%\n  select(-name)\n\nWarning: The `x` argument of `as_tibble.matrix()` must have unique column names if\n`.name_repair` is omitted as of tibble 2.0.0.\nℹ Using compatibility `.name_repair`.\n\n\nPlot it two different ways. It’s a monster though, so cut it to just a 100x100 block.\nFirst, a contour\n\nggplot(filter(actib_7_9, x > 100 & x <= 200 & y > 300 & y < 400), aes(x = x, y = y, z = value)) +\n  geom_contour_filled()\n\n\n\n\nAnd a tiled version, which is more precisely the data.\n\nggplot(filter(actib_7_9, x > 100 & x <= 200 & y > 300 & y < 400), aes(x = x, y = y, fill = value)) + \n  geom_tile() +\n  viridis::scale_fill_viridis(option = 'viridis')"
  },
  {
    "objectID": "simmodelling/twoDautocorr.html#extensions",
    "href": "simmodelling/twoDautocorr.html#extensions",
    "title": "2d autocorrelation",
    "section": "Extensions",
    "text": "Extensions\n\n2 species\nA crude step toward 3d autocorr is to say we want 2d autocorr for two species (or really, just a second set of 2d autocorrelated values) with known correlation to the first set. I’ve done that, but it’s very task-specific and so not including here until I generalise a bit better.\n\n\nCross-correlation\nBy definition, the 2d autocorrelated matrices here have embedded nonzero cross-correlations at different lags (see analytical work for what they are once I put it in here). As a quick example, we can use ccf to get the cross correlation between two adjacent vectors along the x-dimension (columns), or the same along the y-dimension (rows).\nColumns\n\nccf(x = acmatrix_7_9[,100], y = acmatrix_7_9[,101], lag.max = 10, type = 'correlation')\n\n\n\n\nRows\n\nccf(x = acmatrix_7_9[100,], y = acmatrix_7_9[101,], lag.max = 10, type = 'correlation')"
  },
  {
    "objectID": "small_helpers/smallpieces.html",
    "href": "small_helpers/smallpieces.html",
    "title": "Small pieces",
    "section": "",
    "text": "This is mostly quick little code snippets to copy-paste and avoid re-writing. load tidyverse and get going.\n\nlibrary(tidyverse)\n\n\n\nI can’t figure out how to avoid this setup chunk. It’s leftover Rmarkdown format, and works fine in quarto too, even if it’s not documented. But converting from Rmarkdown to quarto with knitr::convert_chunk_header kills it, and it’s annoying to always have the header. It seems like setting the project to use the Project directory should do it, and it does for Run all, but not for render.\n\n```{r setup}\nknitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())\n```\n\nI thought it’d be easiest to set in the global options, but that doesn’t seem to persist to render.\n\n\n\n\n\nnewdir <- file.path('output', 'testdir')\nif (!dir.exists(newdir)) {dir.create(newdir, recursive = TRUE)}\n\n\n\n\nFunctions like duplicated give the second (and greater) values that match. e.g.\n\nx <- c(1,2,1,3,4,2)\nduplicated(x)\n\n[1] FALSE FALSE  TRUE FALSE FALSE  TRUE\n\n\nBut we often want to grab all values that are repeated- ie if everything matches in one column what’s going on in the others. do do that we can use group_by and filter to get those with > 1 row.\nIE, let’s compare cars with duplicated mpg values\n\nmtcars %>%\n  dplyr::group_by(mpg) %>%\n  dplyr::filter(n() > 1) %>%\n  dplyr::arrange(mpg) # makes the comparisons easier\n\n\n\n  \n\n\n\nWhy is that useful? We can see not only that these aren’t fully duplicated rows (which we also could have done with duplicated on the whole table), but also actually look at what differs easily.\n\n\n\nSometimes with long csvs, readr’s guess of col type based on the first thousand rows is wrong. But only for some cols. If we want to not have to specify all of them, we can use .default and only specify the offending col.\nFirst, save dummy data\n\ndumtib <- tibble(c1 = 1:3000, c2 = rep(letters, length.out = 3000), c3 = c(c1[1:2000], c2[2001:3000]))\n\nwrite_csv(dumtib, file = file.path(newdir, 'colspectest.csv'))\n\nIf we read in without the cols, it assumes c3 is numeric and we get errors. But it doesn’t. why not? It keeps getting me elsewhere, but now I can’t create the problem. FIgure this out later, I guess\n\nfilein <- read_csv(file.path(newdir, 'colspectest.csv'), guess_max = 100)\n\nRows: 3000 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): c2, c3\ndbl (1): c1\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nTell it the third col is character.\n\nfilein <- readr::read_csv(file.path(newdir, 'colspectest.csv'), col_types = cols(.default = \"?\", c3 = \"c\"))\n\n\n\n\nYes, we should be building as a library in this case, but it’s often easier at least initially to not deal with the overhead. If, for example, all functions are in the ‘functions’ directory,\n\n# Location-setting header\n# source everything in the functions folder. This really is turning into a package\nfunfiles <- list.files('functions')\nfor (s in 1:length(funfiles)) {\n  source(file.path('functions', funfiles[s])) \n}\n\n\n\n\nRender in quarto defaults to making dfs text, and so often we can’t see all the columns (or rows), or access them. setting the df-print option to paged allows them to work. The header should look like this (commented out because this isn’t a header)\n\n# title: \"TITLE\"\n# author: \"AUTHOR\"\n# format:\n#   html:\n#     df-print: paged\n\n\n\n\nconvert_chunk_headers is the main thing, but I want to apply it to a full directory. Let’s get the dir for here.\n\nallrmd <- list.files(rprojroot::find_rstudio_root_file(), pattern = '.Rmd', recursive = TRUE, full.names = TRUE)\n\nallrmd <- allrmd[!stringr::str_detect(allrmd, 'renv')]\n\nallqmd <- stringr::str_replace(allrmd, '.Rmd', '.qmd')\n\nCan I vectorize? No, but a loop works. Git commit first!\n\nfor (i in 1:length(allrmd)) {\n  knitr::convert_chunk_header(input = allrmd[i], output = allqmd[i])\n}\n\nNow, if you want to really go for it, delete the rmds. That makes git happier because then it can treat this as a rename and keep tracking the files.\nDangerous- make sure you’ve git-committed. I’m commenting out and eval: false ing this\n\n# file.remove(allrmd)"
  },
  {
    "objectID": "small_helpers/zip_downloading.html",
    "href": "small_helpers/zip_downloading.html",
    "title": "Download Zip helper",
    "section": "",
    "text": "When we download files from the internet, we often feed in a url, and it returns a zip, which we then want to unzip to access. There’s a fairly simple way to do that, but we can write a quicky function to do it and clean up the directory afterwards."
  },
  {
    "objectID": "small_helpers/zip_downloading.html#the-function",
    "href": "small_helpers/zip_downloading.html#the-function",
    "title": "Download Zip helper",
    "section": "The function",
    "text": "The function\nwe want to give it the dirname for the file(s), the datadir that contains our data, and the URL. Then it checks if it exists, and downloads, unzips, and cleans up.\n\nzip_load <- function(dirname, datadir, sourceurl,  \n                      existing_dirs = list.files(datadir)) {\n  print(existing_dirs)\n  if (!(dirname %in% existing_dirs)) {\n    \n    zippath <- file.path(datadir, paste0(dirname, '.zip'))\n    download.file(sourceurl, destfile = zippath)\n    \n    unzip(zippath, exdir = file.path(datadir, dirname))\n    \n    file.remove(zippath)\n  }\n}"
  },
  {
    "objectID": "small_helpers/zip_downloading.html#an-example",
    "href": "small_helpers/zip_downloading.html#an-example",
    "title": "Download Zip helper",
    "section": "An example",
    "text": "An example\nGet the Murray-Darling basin boundary\n\nzip_load('mdb_boundary', 'data', \"https://data.gov.au/data/dataset/4ede9aed-5620-47db-a72b-0b3aa0a3ced0/resource/8a6d889d-723b-492d-8c12-b8b0d1ba4b5a/download/sworkingadhocjobsj4430dataoutputsmdb_boundarymdb_boundary.zip\")\n\ncharacter(0)\n\n\nWarning in download.file(sourceurl, destfile = zippath): URL\nhttps://data.gov.au/data/dataset/4ede9aed-5620-47db-a72b-0b3aa0a3ced0/resource/8a6d889d-723b-492d-8c12-b8b0d1ba4b5a/download/sworkingadhocjobsj4430dataoutputsmdb_boundarymdb_boundary.zip:\ncannot open destfile 'data/mdb_boundary.zip', reason 'No such file or directory'\n\n\nWarning in download.file(sourceurl, destfile = zippath): download had nonzero\nexit status\n\n\nWarning in unzip(zippath, exdir = file.path(datadir, dirname)): error 1 in\nextracting from zip file\n\n\nWarning in file.remove(zippath): cannot remove file 'data/mdb_boundary.zip',\nreason 'No such file or directory'\n\n\n[1] FALSE\n\n\nI’ve saved this in functions/ so I have easy access to it everywhere."
  },
  {
    "objectID": "vicwater/vicwater_api_howtocall.html",
    "href": "vicwater/vicwater_api_howtocall.html",
    "title": "Vicwater api crude testing",
    "section": "",
    "text": "knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())"
  },
  {
    "objectID": "vicwater/vicwater_api_howtocall.html#access-victoria-water-data-through-api",
    "href": "vicwater/vicwater_api_howtocall.html#access-victoria-water-data-through-api",
    "title": "Vicwater api crude testing",
    "section": "Access Victoria water data through API",
    "text": "Access Victoria water data through API\nWe want to access victorian water data for a set of sites. That requires using the api at https://data.water.vic.gov.au/cgi/webservice.exe?[JSON_request] , but it’s poorly documented, and I’ve maybe done one API call ever. Time to figure this out. Will start by piggybacking on the mdba-gauge-getter python that gets water levels as a starting point and then try to get other data.\nFirst, how do we make an API request? Most tutorials use twitter or github, which are well-documented. But let’s try something similar.\npurrr conflicts with jsonlite::flatten, so don’t load tidyverse.\n\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.2.2\n\nlibrary(tibble)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(httr)\nlibrary(jsonlite)\n\n# Actually end up using\nlibrary(httr2)\n\nWarning: package 'httr2' was built under R version 4.2.2\n\n\nLooks like the first thing is the base url. The web says it’s this, and the mdba-gauge-getter uses the same, and then appends json_data\n\nvicurl <- \"https://data.water.vic.gov.au/cgi/webservice.exe?\"\n\nI guess I need to specify something to get. But there is no documentation I can find for what the parameters are. The gauge-getter has a few, so I guess start picking things apart.\n\nparams <- list(\"site_list\" = '232202')\n\n\nresponse <- GET(vicurl, query = params)\nresponse\n\nResponse [https://data.water.vic.gov.au/cgi/webservice.exe?site_list=232202]\n  Date: 2022-12-07 02:36\n  Status: 200\n  Content-Type: text/html\n  Size: 103 B\n\n\nFollowing the R api vignette,\n\nparsed <- fromJSON(content(response, 'text'), simplifyVector = FALSE)\n\nNo encoding supplied: defaulting to UTF-8.\n\nparsed\n\n$error_num\n[1] 120\n\n$error_msg\n[1] \"Missing top-level \\\"version\\\" item\\r\\nMissing top-level \\\"params\\\" item\"\n\n\nInteresting. It looked like it returned 200 (good) when I printed response and when I look at it in the View, but actually had errors. Where ARE these results?\nso, can we add those missing ‘top-level’ items? I see now that the gauge-getter has a two-level dict\n\nparams <- list(\"version\" = '2')\nresponse <- GET(vicurl, params = params)\nparsed <- fromJSON(content(response, 'text'), simplifyVector = FALSE)\nparsed\n\nTry the example. can’t get it to even be a character vector\n\n# demourl <- https://data.water.vic.gov.au/cgi/webservice.exe?{\"function\":\"get_db_info\",\"version\":\"3\",\"params\":{\"table_name\":\"site\",\"return_type\":\"hash\",\"filter_values\":{\"station\":\"221001\"}}}\n\n\nparams <- list(\"function\" = 'get_db_info',\n               \"version\" = \"3\")\nresponse <- GET(vicurl, query = params)\nparsed <- fromJSON(content(response, 'text'), simplifyVector = FALSE)\n\nNo encoding supplied: defaulting to UTF-8.\n\nparsed\n\n$error_num\n[1] 122\n\n$error_msg\n[1] \"Parameter error(s) for function get_db_info:Missing: table_name\"\n\n\nWell, that’s a start. at least I’m not getting the top-level errors. Can i just smash that whole demo into a single params list? without the sublists of ‘params’ and ‘filter_values’?\n\n# params <- list(\"function\" = 'get_db_info',\n#                \"version\" = \"3\",\n#                \"table_name\" = \"site\",\n#                \"station\" = \"221001\")\n# response <- GET(vicurl, query = params)\n# \n# # The parsed barfs\n# # parsed <- fromJSON(content(response, 'text'), simplifyVector = FALSE)\n# # parsed\n# \n# response\n\nWhat am I actually asking for here? GET is using modify_url\n\nmodify_url(vicurl, query = params)\n\n[1] \"https://data.water.vic.gov.au/cgi/webservice.exe?function=get_db_info&version=3\"\n\n\nSo that’s using the ’conventional parameter pairs’ option here, not the json . How do I generate some json so I can see if I’m matching the format? auto_unbox = TRUE is needed to not wrap the second values in brackets.\n\ntoJSON(params, auto_unbox = TRUE)\n\n{\"function\":\"get_db_info\",\"version\":\"3\"} \n\n\nOK, so that looks vaguely right, but not leveled. Can we do lists of lists?\n\nnestparams <- list(\"function\" = 'get_db_info',\n               \"version\" = \"3\",\n               \"params\" = list(\"table_name\" = \"site\",\n                               \"return_type\" = \"hash\",\n                               \"filter_values\" = list(\"station\" = \"221001\")))\ntoJSON(nestparams, auto_unbox = TRUE)\n\n{\"function\":\"get_db_info\",\"version\":\"3\",\"params\":{\"table_name\":\"site\",\"return_type\":\"hash\",\"filter_values\":{\"station\":\"221001\"}}} \n\n\nWhoa! that looks right. Now, let’s try it. It immediately fails to just use GET. try looking at modify_url to see why.\n\njsonbit <- toJSON(nestparams, auto_unbox = TRUE)\n\n\nmodify_url(vicurl, query = jsonbit)\n\n[1] \"https://data.water.vic.gov.au/cgi/webservice.exe?{\\\"function\\\":\\\"get_db_info\\\",\\\"version\\\":\\\"3\\\",\\\"params\\\":{\\\"table_name\\\":\\\"site\\\",\\\"return_type\\\":\\\"hash\\\",\\\"filter_values\\\":{\\\"station\\\":\\\"221001\\\"}}}\"\n\n\n\nmodify_url(vicurl, path = jsonbit)\n\n[1] \"https://data.water.vic.gov.au/{\\\"function\\\":\\\"get_db_info\\\",\\\"version\\\":\\\"3\\\",\\\"params\\\":{\\\"table_name\\\":\\\"site\\\",\\\"return_type\\\":\\\"hash\\\",\\\"filter_values\\\":{\\\"station\\\":\\\"221001\\\"}}}\"\n\n\nGetting a lot of slashes. does it matter? Maybe?\n\nmodify_url(vicurl, scheme = nestparams)\n\n[1] \"get_db_info://data.water.vic.gov.au/cgi/webservice.exe\"                                                                                    \n[2] \"3://data.water.vic.gov.au/cgi/webservice.exe\"                                                                                              \n[3] \"list(table_name = \\\"site\\\", return_type = \\\"hash\\\", filter_values = list(station = \\\"221001\\\"))://data.water.vic.gov.au/cgi/webservice.exe\"\n\n\nIs httpbin a way to test?\n\nbinurl <- \"http://httpbin.org/get\"\n\nbinr <- GET(binurl, query = jsonbit)\nbinr\n\nResponse [http://httpbin.org/get?{\"function\":\"get_db_info\",\"version\":\"3\",\"params\":{\"table_name\":\"site\",\"return_type\":\"hash\",\"filter_values\":{\"station\":\"221001\"}}}]\n  Date: 2022-12-07 02:36\n  Status: 200\n  Content-Type: application/json\n  Size: 689 B\n{\n  \"args\": {\n    \"{\\\"function\\\":\\\"get_db_info\\\",\\\"version\\\":\\\"3\\\",\\\"params\\\":{\\\"table_name...\n  }, \n  \"headers\": {\n    \"Accept\": \"application/json, text/xml, application/xml, */*\", \n    \"Accept-Encoding\": \"deflate, gzip\", \n    \"Host\": \"httpbin.org\", \n    \"User-Agent\": \"libcurl/7.64.1 r-curl/4.3.3 httr/1.4.4\", \n    \"X-Amzn-Trace-Id\": \"Root=1-638ffc12-7dab7950495d406217e5071c\"\n...\n\n\n\nparsedB <- fromJSON(content(binr, 'text'), simplifyVector = FALSE)\n\nNo encoding supplied: defaulting to UTF-8.\n\nparsedB\n\n$args\n$args$`{\"function\":\"get_db_info\",\"version\":\"3\",\"params\":{\"table_name\":\"site\",\"return_type\":\"hash\",\"filter_values\":{\"station\":\"221001\"}}}`\n[1] \"\"\n\n\n$headers\n$headers$Accept\n[1] \"application/json, text/xml, application/xml, */*\"\n\n$headers$`Accept-Encoding`\n[1] \"deflate, gzip\"\n\n$headers$Host\n[1] \"httpbin.org\"\n\n$headers$`User-Agent`\n[1] \"libcurl/7.64.1 r-curl/4.3.3 httr/1.4.4\"\n\n$headers$`X-Amzn-Trace-Id`\n[1] \"Root=1-638ffc12-7dab7950495d406217e5071c\"\n\n\n$origin\n[1] \"180.222.17.154\"\n\n$url\n[1] \"http://httpbin.org/get?{\\\"function\\\":\\\"get_db_info\\\",\\\"version\\\":\\\"3\\\",\\\"params\\\":{\\\"table_name\\\":\\\"site\\\",\\\"return_type\\\":\\\"hash\\\",\\\"filter_values\\\":{\\\"station\\\":\\\"221001\\\"}}}\"\n\n\nThat call looks right.\n\nresponse <- GET(vicurl, query = jsonbit, encode = 'json')\nresponse\n\nResponse [https://data.water.vic.gov.au/cgi/webservice.exe?{\"function\":\"get_db_info\",\"version\":\"3\",\"params\":{\"table_name\":\"site\",\"return_type\":\"hash\",\"filter_values\":{\"station\":\"221001\"}}}]\n  Date: 2022-12-07 02:36\n  Status: 200\n  Content-Type: text/html\n  Size: 99 B\n\n\n\nparsed <- fromJSON(content(response, 'text'), simplifyVector = FALSE)\n\nNo encoding supplied: defaulting to UTF-8.\n\nparsed\n\n$error_num\n[1] 120\n\n$error_msg\n[1] \"Request is not well-formed JSON\\r\\nInput request was not valid JSON\"\n\n\nI pasted it in to notebook++ and it’s exactly the same as the example. So, why isn’t it working?\n\nmodurl <- modify_url(vicurl, query = jsonbit)\nresponse <- GET(modurl)\nresponse\n\nResponse [https://data.water.vic.gov.au/cgi/webservice.exe?{\"function\":\"get_db_info\",\"version\":\"3\",\"params\":{\"table_name\":\"site\",\"return_type\":\"hash\",\"filter_values\":{\"station\":\"221001\"}}}]\n  Date: 2022-12-07 02:36\n  Status: 200\n  Content-Type: text/html\n  Size: 99 B\n\n\n\nparsed <- fromJSON(content(response, 'text'), simplifyVector = FALSE)\n\nNo encoding supplied: defaulting to UTF-8.\n\nparsed\n\n$error_num\n[1] 120\n\n$error_msg\n[1] \"Request is not well-formed JSON\\r\\nInput request was not valid JSON\""
  },
  {
    "objectID": "vicwater/vicwater_api_howtocall.html#httr2",
    "href": "vicwater/vicwater_api_howtocall.html#httr2",
    "title": "Vicwater api crude testing",
    "section": "httr2",
    "text": "httr2\nHmmm. I see Hadley has released a v2. And it has a req_body_json. See if that works\n\nlibrary(httr2)\n\nThe req_dry_run lets us see what it’s passing. THat looks right? I think?\n\nreq <- request(vicurl)\nreq %>% \n  req_body_json(nestparams) %>% \n  req_dry_run()\n\nPOST /cgi/webservice.exe? HTTP/1.1\nHost: data.water.vic.gov.au\nUser-Agent: httr2/0.2.2 r-curl/4.3.3 libcurl/7.64.1\nAccept: */*\nAccept-Encoding: deflate, gzip\nContent-Type: application/json\nContent-Length: 129\n\n{\"function\":\"get_db_info\",\"version\":\"3\",\"params\":{\"table_name\":\"site\",\"return_type\":\"hash\",\"filter_values\":{\"station\":\"221001\"}}}\n\n\n\nresp <- req %>% \n  req_body_json(nestparams) %>% \n  req_perform()\n\n\nresp %>% resp_raw()\n\nHTTP/1.1 200 OK\nDate: Wed, 07 Dec 2022 02:36:05 GMT\nContent-Type: text/html\nContent-Length: 972\nConnection: keep-alive\nContent-Encoding: gzip\nVary: Accept-Encoding\nServer: Microsoft-IIS/10.0\nContent: \nAccess-Control-Allow-Origin: *\n\n{\"error_num\":0,\"return\":{\"rows\":{\"221001\":{\"category20\":\"\",\"category19\":\"\",\"category18\":\"\",\"category17\":\"\",\"category16\":\"\",\"category15\":\"\",\"category14\":\"\",\"category13\":\"\",\"category12\":\"\",\"category11\":\"\",\"category10\":\"N\\/A\",\"active\":false,\"northing\":\"5887218.000\",\"timezone\":\"10.0\",\"shortname\":\"GENOA R @ ROCKTON\",\"datecreate\":18991230,\"elevdatum\":\"\",\"stname\":\"GENOA RIVER @ ROCKTON\",\"category9\":\"N\\/A\",\"category8\":\"G(S)\",\"category7\":\"G\",\"category6\":\"2WD\\/4WD\",\"category5\":\"10\",\"category4\":\"150\",\"category3\":\"GRAVEL\",\"category2\":\"V_70D3\",\"category1\":\"23\",\"elevacc\":\"1\",\"dbver47\":false,\"quarter\":\"Y\",\"section\":0,\"commence\":19930526,\"parent\":\"\",\"mapname\":\"MAFFRA\",\"meridian\":\"\",\"spare5\":\"\",\"spare4\":\"\",\"spare3\":\"\",\"spare2\":\"N\\/A\",\"spare1\":\"N\\/A\",\"posacc\":\"9\",\"timemod\":1642,\"region\":\"221\",\"grdatum\":\"UTM\",\"township\":\"\",\"longitude\":\"149.317296100\",\"comment\":\" \\r\\nTurn right from Monaro Highway onto Imlay road signposted 82 km to Eden.  Travel over low level bridge  to a sharp left bend in the road.  A pine plantation  will be directly on the right.  Turn down into plantation and travel approx. 100m2011\\/07\\/17 Virtual site entry generated by DSEVIRTUALSITE.HSC from details in 221001A\\r\\n\",\"lldatum\":\"WGS84\",\"station\":\"221001\",\"datemod\":20221117,\"timecreate\":0,\"orgcode\":\"DSE\",\"barcode\":\"Bombala\",\"zone\":55,\"elev\":\"429.000\",\"cease\":18991230,\"local_map\":\"CRAIGIE\",\"latitude\":\"-37.138654990\",\"range\":\"\",\"qquarter\":\"Y\",\"easting\":\"705825.000\",\"stntype\":\"VIR\"}}}}\n\n\nI thought it was json? but resp_body_json fails with defaults\n\nrj <- resp %>% resp_body_json(check_type = FALSE)\nrj\n\n$error_num\n[1] 0\n\n$return\n$return$rows\n$return$rows$`221001`\n$return$rows$`221001`$category20\n[1] \"\"\n\n$return$rows$`221001`$category19\n[1] \"\"\n\n$return$rows$`221001`$category18\n[1] \"\"\n\n$return$rows$`221001`$category17\n[1] \"\"\n\n$return$rows$`221001`$category16\n[1] \"\"\n\n$return$rows$`221001`$category15\n[1] \"\"\n\n$return$rows$`221001`$category14\n[1] \"\"\n\n$return$rows$`221001`$category13\n[1] \"\"\n\n$return$rows$`221001`$category12\n[1] \"\"\n\n$return$rows$`221001`$category11\n[1] \"\"\n\n$return$rows$`221001`$category10\n[1] \"N/A\"\n\n$return$rows$`221001`$active\n[1] FALSE\n\n$return$rows$`221001`$northing\n[1] \"5887218.000\"\n\n$return$rows$`221001`$timezone\n[1] \"10.0\"\n\n$return$rows$`221001`$shortname\n[1] \"GENOA R @ ROCKTON\"\n\n$return$rows$`221001`$datecreate\n[1] 18991230\n\n$return$rows$`221001`$elevdatum\n[1] \"\"\n\n$return$rows$`221001`$stname\n[1] \"GENOA RIVER @ ROCKTON\"\n\n$return$rows$`221001`$category9\n[1] \"N/A\"\n\n$return$rows$`221001`$category8\n[1] \"G(S)\"\n\n$return$rows$`221001`$category7\n[1] \"G\"\n\n$return$rows$`221001`$category6\n[1] \"2WD/4WD\"\n\n$return$rows$`221001`$category5\n[1] \"10\"\n\n$return$rows$`221001`$category4\n[1] \"150\"\n\n$return$rows$`221001`$category3\n[1] \"GRAVEL\"\n\n$return$rows$`221001`$category2\n[1] \"V_70D3\"\n\n$return$rows$`221001`$category1\n[1] \"23\"\n\n$return$rows$`221001`$elevacc\n[1] \"1\"\n\n$return$rows$`221001`$dbver47\n[1] FALSE\n\n$return$rows$`221001`$quarter\n[1] \"Y\"\n\n$return$rows$`221001`$section\n[1] 0\n\n$return$rows$`221001`$commence\n[1] 19930526\n\n$return$rows$`221001`$parent\n[1] \"\"\n\n$return$rows$`221001`$mapname\n[1] \"MAFFRA\"\n\n$return$rows$`221001`$meridian\n[1] \"\"\n\n$return$rows$`221001`$spare5\n[1] \"\"\n\n$return$rows$`221001`$spare4\n[1] \"\"\n\n$return$rows$`221001`$spare3\n[1] \"\"\n\n$return$rows$`221001`$spare2\n[1] \"N/A\"\n\n$return$rows$`221001`$spare1\n[1] \"N/A\"\n\n$return$rows$`221001`$posacc\n[1] \"9\"\n\n$return$rows$`221001`$timemod\n[1] 1642\n\n$return$rows$`221001`$region\n[1] \"221\"\n\n$return$rows$`221001`$grdatum\n[1] \"UTM\"\n\n$return$rows$`221001`$township\n[1] \"\"\n\n$return$rows$`221001`$longitude\n[1] \"149.317296100\"\n\n$return$rows$`221001`$comment\n[1] \" \\r\\nTurn right from Monaro Highway onto Imlay road signposted 82 km to Eden.  Travel over low level bridge  to a sharp left bend in the road.  A pine plantation  will be directly on the right.  Turn down into plantation and travel approx. 100m2011/07/17 Virtual site entry generated by DSEVIRTUALSITE.HSC from details in 221001A\\r\\n\"\n\n$return$rows$`221001`$lldatum\n[1] \"WGS84\"\n\n$return$rows$`221001`$station\n[1] \"221001\"\n\n$return$rows$`221001`$datemod\n[1] 20221117\n\n$return$rows$`221001`$timecreate\n[1] 0\n\n$return$rows$`221001`$orgcode\n[1] \"DSE\"\n\n$return$rows$`221001`$barcode\n[1] \"Bombala\"\n\n$return$rows$`221001`$zone\n[1] 55\n\n$return$rows$`221001`$elev\n[1] \"429.000\"\n\n$return$rows$`221001`$cease\n[1] 18991230\n\n$return$rows$`221001`$local_map\n[1] \"CRAIGIE\"\n\n$return$rows$`221001`$latitude\n[1] \"-37.138654990\"\n\n$return$rows$`221001`$range\n[1] \"\"\n\n$return$rows$`221001`$qquarter\n[1] \"Y\"\n\n$return$rows$`221001`$easting\n[1] \"705825.000\"\n\n$return$rows$`221001`$stntype\n[1] \"VIR\"\n\n\nIf I hack it together to check, first note that the resp_body is raw, as we see in the str of resp_raw and in resp_body_raw\n\nresp %>% resp_raw() %>% str()\n\nHTTP/1.1 200 OK\nDate: Wed, 07 Dec 2022 02:36:05 GMT\nContent-Type: text/html\nContent-Length: 972\nConnection: keep-alive\nContent-Encoding: gzip\nVary: Accept-Encoding\nServer: Microsoft-IIS/10.0\nContent: \nAccess-Control-Allow-Origin: *\n\n{\"error_num\":0,\"return\":{\"rows\":{\"221001\":{\"category20\":\"\",\"category19\":\"\",\"category18\":\"\",\"category17\":\"\",\"category16\":\"\",\"category15\":\"\",\"category14\":\"\",\"category13\":\"\",\"category12\":\"\",\"category11\":\"\",\"category10\":\"N\\/A\",\"active\":false,\"northing\":\"5887218.000\",\"timezone\":\"10.0\",\"shortname\":\"GENOA R @ ROCKTON\",\"datecreate\":18991230,\"elevdatum\":\"\",\"stname\":\"GENOA RIVER @ ROCKTON\",\"category9\":\"N\\/A\",\"category8\":\"G(S)\",\"category7\":\"G\",\"category6\":\"2WD\\/4WD\",\"category5\":\"10\",\"category4\":\"150\",\"category3\":\"GRAVEL\",\"category2\":\"V_70D3\",\"category1\":\"23\",\"elevacc\":\"1\",\"dbver47\":false,\"quarter\":\"Y\",\"section\":0,\"commence\":19930526,\"parent\":\"\",\"mapname\":\"MAFFRA\",\"meridian\":\"\",\"spare5\":\"\",\"spare4\":\"\",\"spare3\":\"\",\"spare2\":\"N\\/A\",\"spare1\":\"N\\/A\",\"posacc\":\"9\",\"timemod\":1642,\"region\":\"221\",\"grdatum\":\"UTM\",\"township\":\"\",\"longitude\":\"149.317296100\",\"comment\":\" \\r\\nTurn right from Monaro Highway onto Imlay road signposted 82 km to Eden.  Travel over low level bridge  to a sharp left bend in the road.  A pine plantation  will be directly on the right.  Turn down into plantation and travel approx. 100m2011\\/07\\/17 Virtual site entry generated by DSEVIRTUALSITE.HSC from details in 221001A\\r\\n\",\"lldatum\":\"WGS84\",\"station\":\"221001\",\"datemod\":20221117,\"timecreate\":0,\"orgcode\":\"DSE\",\"barcode\":\"Bombala\",\"zone\":55,\"elev\":\"429.000\",\"cease\":18991230,\"local_map\":\"CRAIGIE\",\"latitude\":\"-37.138654990\",\"range\":\"\",\"qquarter\":\"Y\",\"easting\":\"705825.000\",\"stntype\":\"VIR\"}}}}\nList of 5\n $ method     : chr \"POST\"\n $ url        : chr \"https://data.water.vic.gov.au/cgi/webservice.exe?\"\n $ status_code: int 200\n $ headers    :List of 9\n  ..$ Date                       : chr \"Wed, 07 Dec 2022 02:36:05 GMT\"\n  ..$ Content-Type               : chr \"text/html\"\n  ..$ Content-Length             : chr \"972\"\n  ..$ Connection                 : chr \"keep-alive\"\n  ..$ Content-Encoding           : chr \"gzip\"\n  ..$ Vary                       : chr \"Accept-Encoding\"\n  ..$ Server                     : chr \"Microsoft-IIS/10.0\"\n  ..$ Content                    : chr \"\"\n  ..$ Access-Control-Allow-Origin: chr \"*\"\n  ..- attr(*, \"class\")= chr \"httr2_headers\"\n $ body       : raw [1:1460] 7b 22 65 72 ...\n - attr(*, \"class\")= chr \"httr2_response\"\n\n\n\nresp %>% resp_body_raw()\n\n   [1] 7b 22 65 72 72 6f 72 5f 6e 75 6d 22 3a 30 2c 22 72 65 74 75 72 6e 22 3a\n  [25] 7b 22 72 6f 77 73 22 3a 7b 22 32 32 31 30 30 31 22 3a 7b 22 63 61 74 65\n  [49] 67 6f 72 79 32 30 22 3a 22 22 2c 22 63 61 74 65 67 6f 72 79 31 39 22 3a\n  [73] 22 22 2c 22 63 61 74 65 67 6f 72 79 31 38 22 3a 22 22 2c 22 63 61 74 65\n  [97] 67 6f 72 79 31 37 22 3a 22 22 2c 22 63 61 74 65 67 6f 72 79 31 36 22 3a\n [121] 22 22 2c 22 63 61 74 65 67 6f 72 79 31 35 22 3a 22 22 2c 22 63 61 74 65\n [145] 67 6f 72 79 31 34 22 3a 22 22 2c 22 63 61 74 65 67 6f 72 79 31 33 22 3a\n [169] 22 22 2c 22 63 61 74 65 67 6f 72 79 31 32 22 3a 22 22 2c 22 63 61 74 65\n [193] 67 6f 72 79 31 31 22 3a 22 22 2c 22 63 61 74 65 67 6f 72 79 31 30 22 3a\n [217] 22 4e 5c 2f 41 22 2c 22 61 63 74 69 76 65 22 3a 66 61 6c 73 65 2c 22 6e\n [241] 6f 72 74 68 69 6e 67 22 3a 22 35 38 38 37 32 31 38 2e 30 30 30 22 2c 22\n [265] 74 69 6d 65 7a 6f 6e 65 22 3a 22 31 30 2e 30 22 2c 22 73 68 6f 72 74 6e\n [289] 61 6d 65 22 3a 22 47 45 4e 4f 41 20 52 20 40 20 52 4f 43 4b 54 4f 4e 22\n [313] 2c 22 64 61 74 65 63 72 65 61 74 65 22 3a 31 38 39 39 31 32 33 30 2c 22\n [337] 65 6c 65 76 64 61 74 75 6d 22 3a 22 22 2c 22 73 74 6e 61 6d 65 22 3a 22\n [361] 47 45 4e 4f 41 20 52 49 56 45 52 20 40 20 52 4f 43 4b 54 4f 4e 22 2c 22\n [385] 63 61 74 65 67 6f 72 79 39 22 3a 22 4e 5c 2f 41 22 2c 22 63 61 74 65 67\n [409] 6f 72 79 38 22 3a 22 47 28 53 29 22 2c 22 63 61 74 65 67 6f 72 79 37 22\n [433] 3a 22 47 22 2c 22 63 61 74 65 67 6f 72 79 36 22 3a 22 32 57 44 5c 2f 34\n [457] 57 44 22 2c 22 63 61 74 65 67 6f 72 79 35 22 3a 22 31 30 22 2c 22 63 61\n [481] 74 65 67 6f 72 79 34 22 3a 22 31 35 30 22 2c 22 63 61 74 65 67 6f 72 79\n [505] 33 22 3a 22 47 52 41 56 45 4c 22 2c 22 63 61 74 65 67 6f 72 79 32 22 3a\n [529] 22 56 5f 37 30 44 33 22 2c 22 63 61 74 65 67 6f 72 79 31 22 3a 22 32 33\n [553] 22 2c 22 65 6c 65 76 61 63 63 22 3a 22 31 22 2c 22 64 62 76 65 72 34 37\n [577] 22 3a 66 61 6c 73 65 2c 22 71 75 61 72 74 65 72 22 3a 22 59 22 2c 22 73\n [601] 65 63 74 69 6f 6e 22 3a 30 2c 22 63 6f 6d 6d 65 6e 63 65 22 3a 31 39 39\n [625] 33 30 35 32 36 2c 22 70 61 72 65 6e 74 22 3a 22 22 2c 22 6d 61 70 6e 61\n [649] 6d 65 22 3a 22 4d 41 46 46 52 41 22 2c 22 6d 65 72 69 64 69 61 6e 22 3a\n [673] 22 22 2c 22 73 70 61 72 65 35 22 3a 22 22 2c 22 73 70 61 72 65 34 22 3a\n [697] 22 22 2c 22 73 70 61 72 65 33 22 3a 22 22 2c 22 73 70 61 72 65 32 22 3a\n [721] 22 4e 5c 2f 41 22 2c 22 73 70 61 72 65 31 22 3a 22 4e 5c 2f 41 22 2c 22\n [745] 70 6f 73 61 63 63 22 3a 22 39 22 2c 22 74 69 6d 65 6d 6f 64 22 3a 31 36\n [769] 34 32 2c 22 72 65 67 69 6f 6e 22 3a 22 32 32 31 22 2c 22 67 72 64 61 74\n [793] 75 6d 22 3a 22 55 54 4d 22 2c 22 74 6f 77 6e 73 68 69 70 22 3a 22 22 2c\n [817] 22 6c 6f 6e 67 69 74 75 64 65 22 3a 22 31 34 39 2e 33 31 37 32 39 36 31\n [841] 30 30 22 2c 22 63 6f 6d 6d 65 6e 74 22 3a 22 20 5c 72 5c 6e 54 75 72 6e\n [865] 20 72 69 67 68 74 20 66 72 6f 6d 20 4d 6f 6e 61 72 6f 20 48 69 67 68 77\n [889] 61 79 20 6f 6e 74 6f 20 49 6d 6c 61 79 20 72 6f 61 64 20 73 69 67 6e 70\n [913] 6f 73 74 65 64 20 38 32 20 6b 6d 20 74 6f 20 45 64 65 6e 2e 20 20 54 72\n [937] 61 76 65 6c 20 6f 76 65 72 20 6c 6f 77 20 6c 65 76 65 6c 20 62 72 69 64\n [961] 67 65 20 20 74 6f 20 61 20 73 68 61 72 70 20 6c 65 66 74 20 62 65 6e 64\n [985] 20 69 6e 20 74 68 65 20 72 6f 61 64 2e 20 20 41 20 70 69 6e 65 20 70 6c\n[1009] 61 6e 74 61 74 69 6f 6e 20 20 77 69 6c 6c 20 62 65 20 64 69 72 65 63 74\n[1033] 6c 79 20 6f 6e 20 74 68 65 20 72 69 67 68 74 2e 20 20 54 75 72 6e 20 64\n[1057] 6f 77 6e 20 69 6e 74 6f 20 70 6c 61 6e 74 61 74 69 6f 6e 20 61 6e 64 20\n[1081] 74 72 61 76 65 6c 20 61 70 70 72 6f 78 2e 20 31 30 30 6d 32 30 31 31 5c\n[1105] 2f 30 37 5c 2f 31 37 20 56 69 72 74 75 61 6c 20 73 69 74 65 20 65 6e 74\n[1129] 72 79 20 67 65 6e 65 72 61 74 65 64 20 62 79 20 44 53 45 56 49 52 54 55\n[1153] 41 4c 53 49 54 45 2e 48 53 43 20 66 72 6f 6d 20 64 65 74 61 69 6c 73 20\n[1177] 69 6e 20 32 32 31 30 30 31 41 5c 72 5c 6e 22 2c 22 6c 6c 64 61 74 75 6d\n[1201] 22 3a 22 57 47 53 38 34 22 2c 22 73 74 61 74 69 6f 6e 22 3a 22 32 32 31\n[1225] 30 30 31 22 2c 22 64 61 74 65 6d 6f 64 22 3a 32 30 32 32 31 31 31 37 2c\n[1249] 22 74 69 6d 65 63 72 65 61 74 65 22 3a 30 2c 22 6f 72 67 63 6f 64 65 22\n[1273] 3a 22 44 53 45 22 2c 22 62 61 72 63 6f 64 65 22 3a 22 42 6f 6d 62 61 6c\n[1297] 61 22 2c 22 7a 6f 6e 65 22 3a 35 35 2c 22 65 6c 65 76 22 3a 22 34 32 39\n[1321] 2e 30 30 30 22 2c 22 63 65 61 73 65 22 3a 31 38 39 39 31 32 33 30 2c 22\n[1345] 6c 6f 63 61 6c 5f 6d 61 70 22 3a 22 43 52 41 49 47 49 45 22 2c 22 6c 61\n[1369] 74 69 74 75 64 65 22 3a 22 2d 33 37 2e 31 33 38 36 35 34 39 39 30 22 2c\n[1393] 22 72 61 6e 67 65 22 3a 22 22 2c 22 71 71 75 61 72 74 65 72 22 3a 22 59\n[1417] 22 2c 22 65 61 73 74 69 6e 67 22 3a 22 37 30 35 38 32 35 2e 30 30 30 22\n[1441] 2c 22 73 74 6e 74 79 70 65 22 3a 22 56 49 52 22 7d 7d 7d 7d\n\n\nSo, if we get the raw, convert to char, then pass to JSON, it looks the same as what I’m getting out of resp_body_json.\n\nresp %>% resp_body_raw() %>% rawToChar() %>% fromJSON()\n\n$error_num\n[1] 0\n\n$return\n$return$rows\n$return$rows$`221001`\n$return$rows$`221001`$category20\n[1] \"\"\n\n$return$rows$`221001`$category19\n[1] \"\"\n\n$return$rows$`221001`$category18\n[1] \"\"\n\n$return$rows$`221001`$category17\n[1] \"\"\n\n$return$rows$`221001`$category16\n[1] \"\"\n\n$return$rows$`221001`$category15\n[1] \"\"\n\n$return$rows$`221001`$category14\n[1] \"\"\n\n$return$rows$`221001`$category13\n[1] \"\"\n\n$return$rows$`221001`$category12\n[1] \"\"\n\n$return$rows$`221001`$category11\n[1] \"\"\n\n$return$rows$`221001`$category10\n[1] \"N/A\"\n\n$return$rows$`221001`$active\n[1] FALSE\n\n$return$rows$`221001`$northing\n[1] \"5887218.000\"\n\n$return$rows$`221001`$timezone\n[1] \"10.0\"\n\n$return$rows$`221001`$shortname\n[1] \"GENOA R @ ROCKTON\"\n\n$return$rows$`221001`$datecreate\n[1] 18991230\n\n$return$rows$`221001`$elevdatum\n[1] \"\"\n\n$return$rows$`221001`$stname\n[1] \"GENOA RIVER @ ROCKTON\"\n\n$return$rows$`221001`$category9\n[1] \"N/A\"\n\n$return$rows$`221001`$category8\n[1] \"G(S)\"\n\n$return$rows$`221001`$category7\n[1] \"G\"\n\n$return$rows$`221001`$category6\n[1] \"2WD/4WD\"\n\n$return$rows$`221001`$category5\n[1] \"10\"\n\n$return$rows$`221001`$category4\n[1] \"150\"\n\n$return$rows$`221001`$category3\n[1] \"GRAVEL\"\n\n$return$rows$`221001`$category2\n[1] \"V_70D3\"\n\n$return$rows$`221001`$category1\n[1] \"23\"\n\n$return$rows$`221001`$elevacc\n[1] \"1\"\n\n$return$rows$`221001`$dbver47\n[1] FALSE\n\n$return$rows$`221001`$quarter\n[1] \"Y\"\n\n$return$rows$`221001`$section\n[1] 0\n\n$return$rows$`221001`$commence\n[1] 19930526\n\n$return$rows$`221001`$parent\n[1] \"\"\n\n$return$rows$`221001`$mapname\n[1] \"MAFFRA\"\n\n$return$rows$`221001`$meridian\n[1] \"\"\n\n$return$rows$`221001`$spare5\n[1] \"\"\n\n$return$rows$`221001`$spare4\n[1] \"\"\n\n$return$rows$`221001`$spare3\n[1] \"\"\n\n$return$rows$`221001`$spare2\n[1] \"N/A\"\n\n$return$rows$`221001`$spare1\n[1] \"N/A\"\n\n$return$rows$`221001`$posacc\n[1] \"9\"\n\n$return$rows$`221001`$timemod\n[1] 1642\n\n$return$rows$`221001`$region\n[1] \"221\"\n\n$return$rows$`221001`$grdatum\n[1] \"UTM\"\n\n$return$rows$`221001`$township\n[1] \"\"\n\n$return$rows$`221001`$longitude\n[1] \"149.317296100\"\n\n$return$rows$`221001`$comment\n[1] \" \\r\\nTurn right from Monaro Highway onto Imlay road signposted 82 km to Eden.  Travel over low level bridge  to a sharp left bend in the road.  A pine plantation  will be directly on the right.  Turn down into plantation and travel approx. 100m2011/07/17 Virtual site entry generated by DSEVIRTUALSITE.HSC from details in 221001A\\r\\n\"\n\n$return$rows$`221001`$lldatum\n[1] \"WGS84\"\n\n$return$rows$`221001`$station\n[1] \"221001\"\n\n$return$rows$`221001`$datemod\n[1] 20221117\n\n$return$rows$`221001`$timecreate\n[1] 0\n\n$return$rows$`221001`$orgcode\n[1] \"DSE\"\n\n$return$rows$`221001`$barcode\n[1] \"Bombala\"\n\n$return$rows$`221001`$zone\n[1] 55\n\n$return$rows$`221001`$elev\n[1] \"429.000\"\n\n$return$rows$`221001`$cease\n[1] 18991230\n\n$return$rows$`221001`$local_map\n[1] \"CRAIGIE\"\n\n$return$rows$`221001`$latitude\n[1] \"-37.138654990\"\n\n$return$rows$`221001`$range\n[1] \"\"\n\n$return$rows$`221001`$qquarter\n[1] \"Y\"\n\n$return$rows$`221001`$easting\n[1] \"705825.000\"\n\n$return$rows$`221001`$stntype\n[1] \"VIR\"\n\n\nNow can I clean that up? THere’s a lot of nesting but some of it is pointless?\n\nnames(rj)\n\n[1] \"error_num\" \"return\"   \n\n\nand we know error_num is a single int from the str above. And $return is length 1 with only rows and rows only has the gauge number. After that there’s actually some data.\n\nnames(rj$return)\n\n[1] \"rows\"\n\nnames(rj$return$rows)\n\n[1] \"221001\"\n\nnames(rj$return$rows$`221001`)\n\n [1] \"category20\" \"category19\" \"category18\" \"category17\" \"category16\"\n [6] \"category15\" \"category14\" \"category13\" \"category12\" \"category11\"\n[11] \"category10\" \"active\"     \"northing\"   \"timezone\"   \"shortname\" \n[16] \"datecreate\" \"elevdatum\"  \"stname\"     \"category9\"  \"category8\" \n[21] \"category7\"  \"category6\"  \"category5\"  \"category4\"  \"category3\" \n[26] \"category2\"  \"category1\"  \"elevacc\"    \"dbver47\"    \"quarter\"   \n[31] \"section\"    \"commence\"   \"parent\"     \"mapname\"    \"meridian\"  \n[36] \"spare5\"     \"spare4\"     \"spare3\"     \"spare2\"     \"spare1\"    \n[41] \"posacc\"     \"timemod\"    \"region\"     \"grdatum\"    \"township\"  \n[46] \"longitude\"  \"comment\"    \"lldatum\"    \"station\"    \"datemod\"   \n[51] \"timecreate\" \"orgcode\"    \"barcode\"    \"zone\"       \"elev\"      \n[56] \"cease\"      \"local_map\"  \"latitude\"   \"range\"      \"qquarter\"  \n[61] \"easting\"    \"stntype\"   \n\n\nNow, can we put that in a dataframe? Is each one length 1?\n\nactualdata <- rj$return$rows$`221001`\n\nall(purrr::map_int(actualdata, length) == 1)\n\n[1] TRUE\n\n\n\ntibout <- as_tibble(actualdata)\ntibout\n\n# A tibble: 1 × 62\n  category20 category19 catego…¹ categ…² categ…³ categ…⁴ categ…⁵ categ…⁶ categ…⁷\n  <chr>      <chr>      <chr>    <chr>   <chr>   <chr>   <chr>   <chr>   <chr>  \n1 \"\"         \"\"         \"\"       \"\"      \"\"      \"\"      \"\"      \"\"      \"\"     \n# … with 53 more variables: category11 <chr>, category10 <chr>, active <lgl>,\n#   northing <chr>, timezone <chr>, shortname <chr>, datecreate <int>,\n#   elevdatum <chr>, stname <chr>, category9 <chr>, category8 <chr>,\n#   category7 <chr>, category6 <chr>, category5 <chr>, category4 <chr>,\n#   category3 <chr>, category2 <chr>, category1 <chr>, elevacc <chr>,\n#   dbver47 <lgl>, quarter <chr>, section <int>, commence <int>, parent <chr>,\n#   mapname <chr>, meridian <chr>, spare5 <chr>, spare4 <chr>, spare3 <chr>, …\n\n\nand toss cols with no data\n\ntibout %>% select(where(~!all(. == '')))\n\n# A tibble: 1 × 44\n  catego…¹ active north…² timez…³ short…⁴ datec…⁵ stname categ…⁶ categ…⁷ categ…⁸\n  <chr>    <lgl>  <chr>   <chr>   <chr>     <int> <chr>  <chr>   <chr>   <chr>  \n1 N/A      FALSE  588721… 10.0    GENOA …  1.90e7 GENOA… N/A     G(S)    G      \n# … with 34 more variables: category6 <chr>, category5 <chr>, category4 <chr>,\n#   category3 <chr>, category2 <chr>, category1 <chr>, elevacc <chr>,\n#   dbver47 <lgl>, quarter <chr>, section <int>, commence <int>, mapname <chr>,\n#   spare2 <chr>, spare1 <chr>, posacc <chr>, timemod <int>, region <chr>,\n#   grdatum <chr>, longitude <chr>, comment <chr>, lldatum <chr>,\n#   station <chr>, datemod <int>, timecreate <int>, orgcode <chr>,\n#   barcode <chr>, zone <int>, elev <chr>, cease <int>, local_map <chr>, …\n\n\nCool, I have data and can do stuff with it. NOW, how do I get the data I actually want, vs the data that happens to be in the one demo on the website?"
  },
  {
    "objectID": "vicwater/vicwater_api_howtocall.html#querying-options",
    "href": "vicwater/vicwater_api_howtocall.html#querying-options",
    "title": "Vicwater api crude testing",
    "section": "Querying options",
    "text": "Querying options\nBefore we go get data, we need to figure out what we can ask for. First, sort out those functions.\n\nDatasources\nLet’s try get_datasources_by_site. Takes site_list params. Dunno what versions it works for? Tried 2, gave error says has to be 1. I assume the “A” datasource means archive here, since that’s what it means in QLD.\n\nds_s_params <- list(\"function\" = 'get_datasources_by_site',\n               \"version\" = \"1\",\n               \"params\" = list(\"site_list\" = \"233217\"))\n\n# req <- request(vicurl)\n\nreq %>% \n  req_body_json(ds_s_params) %>% \n  req_dry_run()\n\nPOST /cgi/webservice.exe? HTTP/1.1\nHost: data.water.vic.gov.au\nUser-Agent: httr2/0.2.2 r-curl/4.3.3 libcurl/7.64.1\nAccept: */*\nAccept-Encoding: deflate, gzip\nContent-Type: application/json\nContent-Length: 84\n\n{\"function\":\"get_datasources_by_site\",\"version\":\"1\",\"params\":{\"site_list\":\"233217\"}}\n\nresp_ds_s <- req %>% \n  req_body_json(ds_s_params) %>% \n  req_perform()\n\nrbody_ds_s <- resp_ds_s %>% resp_body_json(check_type = FALSE)\n\nstr(rbody_ds_s)\n\nList of 2\n $ error_num: int 0\n $ return   :List of 1\n  ..$ sites:List of 1\n  .. ..$ :List of 2\n  .. .. ..$ site       : chr \"233217\"\n  .. .. ..$ datasources:List of 3\n  .. .. .. ..$ : chr \"A\"\n  .. .. .. ..$ : chr \"TELEM\"\n  .. .. .. ..$ : chr \"TELEMCOPY\"\n\n\n\n\nSitelist\nOk, I could make that into a tibble easily enough. It tells me what that site has for datasources, how about another? Can I figure out how to use a sitelist? That’d be really nice, and applies in a lot of places. Cool. I had tried to do \"sitelist\" = c('site', 'site') , and that failed. But it works to have \"site, site\"\n\nds_s_params <- list(\"function\" = 'get_datasources_by_site',\n               \"version\" = \"1\",\n               \"params\" = list(\"site_list\" = \"233217, 405328\"))\n\n# req <- request(vicurl)\n\nreq %>% \n  req_body_json(ds_s_params) %>% \n  req_dry_run()\n\nPOST /cgi/webservice.exe? HTTP/1.1\nHost: data.water.vic.gov.au\nUser-Agent: httr2/0.2.2 r-curl/4.3.3 libcurl/7.64.1\nAccept: */*\nAccept-Encoding: deflate, gzip\nContent-Type: application/json\nContent-Length: 92\n\n{\"function\":\"get_datasources_by_site\",\"version\":\"1\",\"params\":{\"site_list\":\"233217, 405328\"}}\n\nresp_ds_s <- req %>% \n  req_body_json(ds_s_params) %>% \n  req_perform()\n\nrbody_ds_s <- resp_ds_s %>% resp_body_json(check_type = FALSE)\n\nstr(rbody_ds_s)\n\nList of 2\n $ error_num: int 0\n $ return   :List of 1\n  ..$ sites:List of 2\n  .. ..$ :List of 2\n  .. .. ..$ site       : chr \"233217\"\n  .. .. ..$ datasources:List of 3\n  .. .. .. ..$ : chr \"A\"\n  .. .. .. ..$ : chr \"TELEM\"\n  .. .. .. ..$ : chr \"TELEMCOPY\"\n  .. ..$ :List of 2\n  .. .. ..$ site       : chr \"405328\"\n  .. .. ..$ datasources:List of 3\n  .. .. .. ..$ : chr \"A\"\n  .. .. .. ..$ : chr \"TELEM\"\n  .. .. .. ..$ : chr \"TELEMCOPY\"\n\n\n\n\nVariables\nNow, for a given site, we want to know what variables are available. (and I also eventually want to know what all possible variables are, and what happens if we ask for variables that aren’t there). Let’s start with the same two sites. I’m\n\nv_s_params <- list(\"function\" = 'get_variable_list',\n               \"version\" = \"1\",\n               \"params\" = list(\"site_list\" = \"233217, 405328\",\n                               \"datasource\" = \"A\"))\n\nreq <- request(vicurl)\n\nreq %>% \n  req_body_json(v_s_params) %>% \n  req_dry_run()\n\nPOST /cgi/webservice.exe? HTTP/1.1\nHost: data.water.vic.gov.au\nUser-Agent: httr2/0.2.2 r-curl/4.3.3 libcurl/7.64.1\nAccept: */*\nAccept-Encoding: deflate, gzip\nContent-Type: application/json\nContent-Length: 103\n\n{\"function\":\"get_variable_list\",\"version\":\"1\",\"params\":{\"site_list\":\"233217, 405328\",\"datasource\":\"A\"}}\n\nresp_v_s <- req %>% \n  req_body_json(v_s_params) %>% \n  req_perform()\n\nrbody_v_s <- resp_v_s %>% resp_body_json(check_type = FALSE)\n\nstr(rbody_v_s)\n\nList of 2\n $ error_num: int 0\n $ return   :List of 1\n  ..$ sites:List of 2\n  .. ..$ :List of 3\n  .. .. ..$ site_details:List of 3\n  .. .. .. ..$ timezone  : chr \"10.0\"\n  .. .. .. ..$ short_name: chr \"BARWON @ GEELONG\"\n  .. .. .. ..$ name      : chr \"BARWON RIVER @ GEELONG\"\n  .. .. ..$ variables   :List of 6\n  .. .. .. ..$ :List of 6\n  .. .. .. .. ..$ period_end  : chr \"20221107070000\"\n  .. .. .. .. ..$ period_start: chr \"19610306171500\"\n  .. .. .. .. ..$ subdesc     : chr \"Available for release\"\n  .. .. .. .. ..$ variable    : chr \"100.00\"\n  .. .. .. .. ..$ units       : chr \"metres\"\n  .. .. .. .. ..$ name        : chr \"Stream Water Level (m)\"\n  .. .. .. ..$ :List of 6\n  .. .. .. .. ..$ period_end  : chr \"20221107070000\"\n  .. .. .. .. ..$ period_start: chr \"20100706123100\"\n  .. .. .. .. ..$ subdesc     : chr \"Available for release\"\n  .. .. .. .. ..$ variable    : chr \"210.00\"\n  .. .. .. .. ..$ units       : chr \"pH\"\n  .. .. .. .. ..$ name        : chr \"Acidity/Alkalinity (pH)\"\n  .. .. .. ..$ :List of 6\n  .. .. .. .. ..$ period_end  : chr \"20221107070000\"\n  .. .. .. .. ..$ period_start: chr \"20100706123100\"\n  .. .. .. .. ..$ subdesc     : chr \"Available for release\"\n  .. .. .. .. ..$ variable    : chr \"215.00\"\n  .. .. .. .. ..$ units       : chr \"ppm\"\n  .. .. .. .. ..$ name        : chr \"Dissolved Oxygen (ppm)\"\n  .. .. .. ..$ :List of 6\n  .. .. .. .. ..$ period_end  : chr \"20221107070000\"\n  .. .. .. .. ..$ period_start: chr \"20100706123100\"\n  .. .. .. .. ..$ subdesc     : chr \"Available for release\"\n  .. .. .. .. ..$ variable    : chr \"450.00\"\n  .. .. .. .. ..$ units       : chr \"Degrees celsius\"\n  .. .. .. .. ..$ name        : chr \"Water Temperature (°C)\"\n  .. .. .. ..$ :List of 6\n  .. .. .. .. ..$ period_end  : chr \"20221107070000\"\n  .. .. .. .. ..$ period_start: chr \"20100706123100\"\n  .. .. .. .. ..$ subdesc     : chr \"Available for release\"\n  .. .. .. .. ..$ variable    : chr \"810.00\"\n  .. .. .. .. ..$ units       : chr \"NTU\"\n  .. .. .. .. ..$ name        : chr \"Turbidity (NTU)\"\n  .. .. .. ..$ :List of 6\n  .. .. .. .. ..$ period_end  : chr \"20221107070000\"\n  .. .. .. .. ..$ period_start: chr \"20100706123100\"\n  .. .. .. .. ..$ subdesc     : chr \"Available for release\"\n  .. .. .. .. ..$ variable    : chr \"820.00\"\n  .. .. .. .. ..$ units       : chr \"µS/cm@25°C\"\n  .. .. .. .. ..$ name        : chr \"Conductivity (µS/cm)\"\n  .. .. ..$ site        : chr \"233217\"\n  .. ..$ :List of 3\n  .. .. ..$ site_details:List of 3\n  .. .. .. ..$ timezone  : chr \"10.0\"\n  .. .. .. ..$ short_name: chr \"STEAVENSON R @ FALLS\"\n  .. .. .. ..$ name      : chr \"STEAVENSON RIVER @ FALLS ROAD MARYSVILLE\"\n  .. .. ..$ variables   :List of 1\n  .. .. .. ..$ :List of 6\n  .. .. .. .. ..$ period_end  : chr \"20221111094500\"\n  .. .. .. .. ..$ period_start: chr \"20091119170800\"\n  .. .. .. .. ..$ subdesc     : chr \"Available for release\"\n  .. .. .. .. ..$ variable    : chr \"100.00\"\n  .. .. .. .. ..$ units       : chr \"metres\"\n  .. .. .. .. ..$ name        : chr \"Stream Water Level (m)\"\n  .. .. ..$ site        : chr \"405328\"\n\n\nSo, that gives me the number and name of each variable at each site. But it does not give derived variables (discharge being the main one)."
  },
  {
    "objectID": "vicwater/vicwater_api_howtocall.html#location-etc",
    "href": "vicwater/vicwater_api_howtocall.html#location-etc",
    "title": "Vicwater api crude testing",
    "section": "Location etc",
    "text": "Location etc\nSo, get_db_info seems like it should be useful, but kind of isn’t (see above). Maybe I’ll come back to that. It does let us do geofilters, but they seem both crude and complex. I think I’d probably rather do geofiltering myself and then turn that into a site_list. But might come back to this. The complex_filter might be useful if we can use it to choose sites based on something. But again, I’d probably do that myself? Again, come back to this maybe?\n\nCan we get a list of all sites and all variables?\nMaybe? Do we want to?"
  },
  {
    "objectID": "vicwater/vicwater_api_howtocall.html#getting-timeseries",
    "href": "vicwater/vicwater_api_howtocall.html#getting-timeseries",
    "title": "Vicwater api crude testing",
    "section": "Getting timeseries",
    "text": "Getting timeseries\nNow, let’s go back to get timeseries, now we know what the variables are. Just for the Barwon at first, and way fewer days. There’s a var_list option, or varfrom and varto. It’s unclear whether the from and to version is numerivally inclusive- ie if we have 100 and 10000, does it get everything? I’ll try with varto = 820, since that’s the highest number avail at the barwon. Gives cryptic error. Try 210? Also, why isn’t 141 available in teh lsit above? Again, cryptic “Assumed fail to reload varcon for 233217: 100.00-> 210.00, as we failed loading it last time”. does it work for 141? Yes.\n\nbparams <- list(\"function\" = 'get_ts_traces',\n               \"version\" = \"2\",\n               \"params\" = list(\"site_list\" = \"233217\",\n                               \"start_time\" = \"20200101000000\",\n                               \"varfrom\" = \"100\",\n                               \"interval\" = \"day\",\n                               \"varto\" = \"141\",\n                               \"datasource\" = \"A\", \n                               \"end_time\" = \"20200115000000\",\n                               \"data_type\" = \"mean\",\n                               \"multiplier\" = \"1\"))\n\nreq <- request(vicurl)\n\nreq %>% \n  req_body_json(bparams) %>% \n  req_dry_run()\n\nPOST /cgi/webservice.exe? HTTP/1.1\nHost: data.water.vic.gov.au\nUser-Agent: httr2/0.2.2 r-curl/4.3.3 libcurl/7.64.1\nAccept: */*\nAccept-Encoding: deflate, gzip\nContent-Type: application/json\nContent-Length: 232\n\n{\"function\":\"get_ts_traces\",\"version\":\"2\",\"params\":{\"site_list\":\"233217\",\"start_time\":\"20200101000000\",\"varfrom\":\"100\",\"interval\":\"day\",\"varto\":\"141\",\"datasource\":\"A\",\"end_time\":\"20200115000000\",\"data_type\":\"mean\",\"multiplier\":\"1\"}}\n\nrespb <- req %>% \n  req_body_json(bparams) %>% \n  req_perform()\n\nrbodyb <- respb %>% resp_body_json(check_type = FALSE)\n\nstr(rbodyb)\n\nList of 2\n $ error_num: int 0\n $ return   :List of 1\n  ..$ traces:List of 1\n  .. ..$ :List of 8\n  .. .. ..$ error_num      : int 0\n  .. .. ..$ compressed     : chr \"0\"\n  .. .. ..$ site_details   :List of 6\n  .. .. .. ..$ timezone  : chr \"10.0\"\n  .. .. .. ..$ short_name: chr \"BARWON @ GEELONG\"\n  .. .. .. ..$ longitude : chr \"144.346892190\"\n  .. .. .. ..$ name      : chr \"BARWON RIVER @ GEELONG\"\n  .. .. .. ..$ latitude  : chr \"-38.163605590\"\n  .. .. .. ..$ org_name  : chr \"Dept. Sustainability and Environment\"\n  .. .. ..$ quality_codes  :List of 1\n  .. .. .. ..$ 150: chr \"Rating extrapolated above 1.5x maximum flow gauged.\"\n  .. .. ..$ trace          :List of 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"15.93\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 150\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"14.11\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 150\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"11.23\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 150\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"8.81\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 150\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.52\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 150\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"6.75\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 150\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"6.09\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 150\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"4.13\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 150\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"2.48\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 150\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"6.88\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 150\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"12.64\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 150\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"9.87\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 150\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"8.42\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 150\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"6.45\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 150\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"9.74\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 150\n  .. .. ..$ varfrom_details:List of 6\n  .. .. .. ..$ short_name: chr \"Water Level (m)\"\n  .. .. .. ..$ precision : chr \"0.001000\"\n  .. .. .. ..$ subdesc   : chr \"Available for release\"\n  .. .. .. ..$ variable  : chr \"100.00\"\n  .. .. .. ..$ units     : chr \"metres\"\n  .. .. .. ..$ name      : chr \"Stream Water Level (m)\"\n  .. .. ..$ site           : chr \"233217\"\n  .. .. ..$ varto_details  :List of 6\n  .. .. .. ..$ short_name: chr \"Discharge (Ml/d)\"\n  .. .. .. ..$ precision : chr \"0.010000\"\n  .. .. .. ..$ subdesc   : chr \"Available for release\"\n  .. .. .. ..$ variable  : chr \"141.00\"\n  .. .. .. ..$ units     : chr \"megalitres/day\"\n  .. .. .. ..$ name      : chr \"Stream Discharge (Ml/d)\"\n\n\nDo the other vars work if we ask for them separately? Try pH (which failed above)\n\nbparams <- list(\"function\" = 'get_ts_traces',\n               \"version\" = \"2\",\n               \"params\" = list(\"site_list\" = \"233217\",\n                               \"start_time\" = \"20200101000000\",\n                               \"varfrom\" = \"210\",\n                               \"interval\" = \"day\",\n                               \"varto\" = \"210\",\n                               \"datasource\" = \"A\", \n                               \"end_time\" = \"20200115000000\",\n                               \"data_type\" = \"mean\",\n                               \"multiplier\" = \"1\"))\n\nreq <- request(vicurl)\n\nreq %>% \n  req_body_json(bparams) %>% \n  req_dry_run()\n\nPOST /cgi/webservice.exe? HTTP/1.1\nHost: data.water.vic.gov.au\nUser-Agent: httr2/0.2.2 r-curl/4.3.3 libcurl/7.64.1\nAccept: */*\nAccept-Encoding: deflate, gzip\nContent-Type: application/json\nContent-Length: 232\n\n{\"function\":\"get_ts_traces\",\"version\":\"2\",\"params\":{\"site_list\":\"233217\",\"start_time\":\"20200101000000\",\"varfrom\":\"210\",\"interval\":\"day\",\"varto\":\"210\",\"datasource\":\"A\",\"end_time\":\"20200115000000\",\"data_type\":\"mean\",\"multiplier\":\"1\"}}\n\nrespb <- req %>% \n  req_body_json(bparams) %>% \n  req_perform()\n\nrbodyb <- respb %>% resp_body_json(check_type = FALSE)\n\nstr(rbodyb)\n\nList of 2\n $ error_num: int 0\n $ return   :List of 1\n  ..$ traces:List of 1\n  .. ..$ :List of 8\n  .. .. ..$ error_num      : int 0\n  .. .. ..$ compressed     : chr \"0\"\n  .. .. ..$ site_details   :List of 6\n  .. .. .. ..$ timezone  : chr \"10.0\"\n  .. .. .. ..$ short_name: chr \"BARWON @ GEELONG\"\n  .. .. .. ..$ longitude : chr \"144.346892190\"\n  .. .. .. ..$ name      : chr \"BARWON RIVER @ GEELONG\"\n  .. .. .. ..$ latitude  : chr \"-38.163605590\"\n  .. .. .. ..$ org_name  : chr \"Dept. Sustainability and Environment\"\n  .. .. ..$ quality_codes  :List of 1\n  .. .. .. ..$ 2: chr \"Good quality data - minimal editing required. +/- 0mm - 10mm Drift correction\"\n  .. .. ..$ trace          :List of 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.80\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.82\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.94\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.90\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.71\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.59\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.52\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.64\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.95\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"8.11\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"8.01\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"8.14\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.85\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.92\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.79\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. ..$ varfrom_details:List of 6\n  .. .. .. ..$ short_name: chr \"Field pH\"\n  .. .. .. ..$ precision : chr \"0.010000\"\n  .. .. .. ..$ subdesc   : chr \"Available for release\"\n  .. .. .. ..$ variable  : chr \"210.00\"\n  .. .. .. ..$ units     : chr \"pH\"\n  .. .. .. ..$ name      : chr \"Acidity/Alkalinity (pH)\"\n  .. .. ..$ site           : chr \"233217\"\n  .. .. ..$ varto_details  :List of 6\n  .. .. .. ..$ short_name: chr \"Field pH\"\n  .. .. .. ..$ precision : chr \"0.010000\"\n  .. .. .. ..$ subdesc   : chr \"Available for release\"\n  .. .. .. ..$ variable  : chr \"210.00\"\n  .. .. .. ..$ units     : chr \"pH\"\n  .. .. .. ..$ name      : chr \"Acidity/Alkalinity (pH)\"\n\n\nInteresting. How about a var_list?\n\nbparams <- list(\"function\" = 'get_ts_traces',\n               \"version\" = \"2\",\n               \"params\" = list(\"site_list\" = \"233217\",\n                               \"start_time\" = \"20200101000000\",\n                               \"var_list\" = \"100,210\",\n                               \"interval\" = \"day\",\n                               \"datasource\" = \"A\", \n                               \"end_time\" = \"20200115000000\",\n                               \"data_type\" = \"mean\",\n                               \"multiplier\" = \"1\"))\n\nreq <- request(vicurl)\n\nreq %>% \n  req_body_json(bparams) %>% \n  req_dry_run()\n\nPOST /cgi/webservice.exe? HTTP/1.1\nHost: data.water.vic.gov.au\nUser-Agent: httr2/0.2.2 r-curl/4.3.3 libcurl/7.64.1\nAccept: */*\nAccept-Encoding: deflate, gzip\nContent-Type: application/json\nContent-Length: 223\n\n{\"function\":\"get_ts_traces\",\"version\":\"2\",\"params\":{\"site_list\":\"233217\",\"start_time\":\"20200101000000\",\"var_list\":\"100,210\",\"interval\":\"day\",\"datasource\":\"A\",\"end_time\":\"20200115000000\",\"data_type\":\"mean\",\"multiplier\":\"1\"}}\n\nrespb <- req %>% \n  req_body_json(bparams) %>% \n  req_perform()\n\nrbodyb <- respb %>% resp_body_json(check_type = FALSE)\n\nstr(rbodyb)\n\nList of 2\n $ error_num: int 0\n $ return   :List of 1\n  ..$ traces:List of 2\n  .. ..$ :List of 8\n  .. .. ..$ error_num      : int 0\n  .. .. ..$ compressed     : chr \"0\"\n  .. .. ..$ site_details   :List of 6\n  .. .. .. ..$ timezone  : chr \"10.0\"\n  .. .. .. ..$ short_name: chr \"BARWON @ GEELONG\"\n  .. .. .. ..$ longitude : chr \"144.346892190\"\n  .. .. .. ..$ name      : chr \"BARWON RIVER @ GEELONG\"\n  .. .. .. ..$ latitude  : chr \"-38.163605590\"\n  .. .. .. ..$ org_name  : chr \"Dept. Sustainability and Environment\"\n  .. .. ..$ quality_codes  :List of 2\n  .. .. .. ..$ 2 : chr \"Good quality data - minimal editing required. +/- 0mm - 10mm Drift correction\"\n  .. .. .. ..$ 15: chr \"Minor editing. +/-11mm - 20mm drift correction\"\n  .. .. ..$ trace          :List of 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.838\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.834\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.827\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.821\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.816\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.814\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.811\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.802\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.791\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.805\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.831\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.824\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.820\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.812\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.817\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. ..$ varfrom_details:List of 6\n  .. .. .. ..$ short_name: chr \"Water Level (m)\"\n  .. .. .. ..$ precision : chr \"0.001000\"\n  .. .. .. ..$ subdesc   : chr \"Available for release\"\n  .. .. .. ..$ variable  : chr \"100.00\"\n  .. .. .. ..$ units     : chr \"metres\"\n  .. .. .. ..$ name      : chr \"Stream Water Level (m)\"\n  .. .. ..$ site           : chr \"233217\"\n  .. .. ..$ varto_details  :List of 6\n  .. .. .. ..$ short_name: chr \"Water Level (m)\"\n  .. .. .. ..$ precision : chr \"0.001000\"\n  .. .. .. ..$ subdesc   : chr \"Available for release\"\n  .. .. .. ..$ variable  : chr \"100.00\"\n  .. .. .. ..$ units     : chr \"metres\"\n  .. .. .. ..$ name      : chr \"Stream Water Level (m)\"\n  .. ..$ :List of 8\n  .. .. ..$ error_num      : int 0\n  .. .. ..$ compressed     : chr \"0\"\n  .. .. ..$ site_details   :List of 6\n  .. .. .. ..$ timezone  : chr \"10.0\"\n  .. .. .. ..$ short_name: chr \"BARWON @ GEELONG\"\n  .. .. .. ..$ longitude : chr \"144.346892190\"\n  .. .. .. ..$ name      : chr \"BARWON RIVER @ GEELONG\"\n  .. .. .. ..$ latitude  : chr \"-38.163605590\"\n  .. .. .. ..$ org_name  : chr \"Dept. Sustainability and Environment\"\n  .. .. ..$ quality_codes  :List of 1\n  .. .. .. ..$ 2: chr \"Good quality data - minimal editing required. +/- 0mm - 10mm Drift correction\"\n  .. .. ..$ trace          :List of 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.80\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.82\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.94\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.90\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.71\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.59\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.52\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.64\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.95\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"8.11\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"8.01\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"8.14\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.85\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.92\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.79\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. ..$ varfrom_details:List of 6\n  .. .. .. ..$ short_name: chr \"Field pH\"\n  .. .. .. ..$ precision : chr \"0.010000\"\n  .. .. .. ..$ subdesc   : chr \"Available for release\"\n  .. .. .. ..$ variable  : chr \"210.00\"\n  .. .. .. ..$ units     : chr \"pH\"\n  .. .. .. ..$ name      : chr \"Acidity/Alkalinity (pH)\"\n  .. .. ..$ site           : chr \"233217\"\n  .. .. ..$ varto_details  :List of 6\n  .. .. .. ..$ short_name: chr \"Field pH\"\n  .. .. .. ..$ precision : chr \"0.010000\"\n  .. .. .. ..$ subdesc   : chr \"Available for release\"\n  .. .. .. ..$ variable  : chr \"210.00\"\n  .. .. .. ..$ units     : chr \"pH\"\n  .. .. .. ..$ name      : chr \"Acidity/Alkalinity (pH)\"\n\n\nThat works, seems to set the varfrom and varto to each value in the list. I wonder if things like 141 are done in the from/to way because they are derived from 100. But how do we find them when they don’t appear in the get_variable_list? Can I include them in var_list? Hmm. No. what’s going on? see table 3 in qld doc- they are derived, and it gives numbers. Is there a get_available_varcons or similar?\n\nbparams <- list(\"function\" = 'get_ts_traces',\n               \"version\" = \"2\",\n               \"params\" = list(\"site_list\" = \"233217\",\n                               \"start_time\" = \"20200101000000\",\n                               \"var_list\" = \"100,141,210\",\n                               \"interval\" = \"day\",\n                               \"datasource\" = \"A\",\n                               \"end_time\" = \"20200115000000\",\n                               \"data_type\" = \"mean\",\n                               \"multiplier\" = \"1\"))\n\nreq <- request(vicurl)\n\nreq %>% \n  req_body_json(bparams) %>% \n  req_dry_run()\n\nPOST /cgi/webservice.exe? HTTP/1.1\nHost: data.water.vic.gov.au\nUser-Agent: httr2/0.2.2 r-curl/4.3.3 libcurl/7.64.1\nAccept: */*\nAccept-Encoding: deflate, gzip\nContent-Type: application/json\nContent-Length: 227\n\n{\"function\":\"get_ts_traces\",\"version\":\"2\",\"params\":{\"site_list\":\"233217\",\"start_time\":\"20200101000000\",\"var_list\":\"100,141,210\",\"interval\":\"day\",\"datasource\":\"A\",\"end_time\":\"20200115000000\",\"data_type\":\"mean\",\"multiplier\":\"1\"}}\n\nrespb <- req %>% \n  req_body_json(bparams) %>% \n  req_perform()\n\nrbodyb <- respb %>% resp_body_json(check_type = FALSE)\n\nstr(rbodyb)\n\nList of 2\n $ error_num: int 0\n $ return   :List of 1\n  ..$ traces:List of 2\n  .. ..$ :List of 8\n  .. .. ..$ error_num      : int 0\n  .. .. ..$ compressed     : chr \"0\"\n  .. .. ..$ site_details   :List of 6\n  .. .. .. ..$ timezone  : chr \"10.0\"\n  .. .. .. ..$ short_name: chr \"BARWON @ GEELONG\"\n  .. .. .. ..$ longitude : chr \"144.346892190\"\n  .. .. .. ..$ name      : chr \"BARWON RIVER @ GEELONG\"\n  .. .. .. ..$ latitude  : chr \"-38.163605590\"\n  .. .. .. ..$ org_name  : chr \"Dept. Sustainability and Environment\"\n  .. .. ..$ quality_codes  :List of 2\n  .. .. .. ..$ 2 : chr \"Good quality data - minimal editing required. +/- 0mm - 10mm Drift correction\"\n  .. .. .. ..$ 15: chr \"Minor editing. +/-11mm - 20mm drift correction\"\n  .. .. ..$ trace          :List of 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.838\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.834\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.827\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.821\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.816\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.814\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.811\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.802\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.791\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.805\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.831\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.824\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.820\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.812\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.817\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. ..$ varfrom_details:List of 6\n  .. .. .. ..$ short_name: chr \"Water Level (m)\"\n  .. .. .. ..$ precision : chr \"0.001000\"\n  .. .. .. ..$ subdesc   : chr \"Available for release\"\n  .. .. .. ..$ variable  : chr \"100.00\"\n  .. .. .. ..$ units     : chr \"metres\"\n  .. .. .. ..$ name      : chr \"Stream Water Level (m)\"\n  .. .. ..$ site           : chr \"233217\"\n  .. .. ..$ varto_details  :List of 6\n  .. .. .. ..$ short_name: chr \"Water Level (m)\"\n  .. .. .. ..$ precision : chr \"0.001000\"\n  .. .. .. ..$ subdesc   : chr \"Available for release\"\n  .. .. .. ..$ variable  : chr \"100.00\"\n  .. .. .. ..$ units     : chr \"metres\"\n  .. .. .. ..$ name      : chr \"Stream Water Level (m)\"\n  .. ..$ :List of 8\n  .. .. ..$ error_num      : int 0\n  .. .. ..$ compressed     : chr \"0\"\n  .. .. ..$ site_details   :List of 6\n  .. .. .. ..$ timezone  : chr \"10.0\"\n  .. .. .. ..$ short_name: chr \"BARWON @ GEELONG\"\n  .. .. .. ..$ longitude : chr \"144.346892190\"\n  .. .. .. ..$ name      : chr \"BARWON RIVER @ GEELONG\"\n  .. .. .. ..$ latitude  : chr \"-38.163605590\"\n  .. .. .. ..$ org_name  : chr \"Dept. Sustainability and Environment\"\n  .. .. ..$ quality_codes  :List of 1\n  .. .. .. ..$ 2: chr \"Good quality data - minimal editing required. +/- 0mm - 10mm Drift correction\"\n  .. .. ..$ trace          :List of 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.80\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.82\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.94\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.90\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.71\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.59\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.52\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.64\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.95\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"8.11\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"8.01\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"8.14\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.85\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.92\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.79\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. ..$ varfrom_details:List of 6\n  .. .. .. ..$ short_name: chr \"Field pH\"\n  .. .. .. ..$ precision : chr \"0.010000\"\n  .. .. .. ..$ subdesc   : chr \"Available for release\"\n  .. .. .. ..$ variable  : chr \"210.00\"\n  .. .. .. ..$ units     : chr \"pH\"\n  .. .. .. ..$ name      : chr \"Acidity/Alkalinity (pH)\"\n  .. .. ..$ site           : chr \"233217\"\n  .. .. ..$ varto_details  :List of 6\n  .. .. .. ..$ short_name: chr \"Field pH\"\n  .. .. .. ..$ precision : chr \"0.010000\"\n  .. .. .. ..$ subdesc   : chr \"Available for release\"\n  .. .. .. ..$ variable  : chr \"210.00\"\n  .. .. .. ..$ units     : chr \"pH\"\n  .. .. .. ..$ name      : chr \"Acidity/Alkalinity (pH)\"\n\n\nHow about asking for variables that don’t exist- ie can we just ask for all of them, and it just gives us whatever’s available? The other site (Steavenson, 405328) only has variable 100, so ask for some others. Just gives 100.\n\nsparams <- list(\"function\" = 'get_ts_traces',\n               \"version\" = \"2\",\n               \"params\" = list(\"site_list\" = \"405328\",\n                               \"start_time\" = \"20200101000000\",\n                               \"var_list\" = \"100,210\",\n                               \"interval\" = \"day\",\n                               \"datasource\" = \"A\", \n                               \"end_time\" = \"20200115000000\",\n                               \"data_type\" = \"mean\",\n                               \"multiplier\" = \"1\"))\n\nreq <- request(vicurl)\n\nreq %>% \n  req_body_json(sparams) %>% \n  req_dry_run()\n\nPOST /cgi/webservice.exe? HTTP/1.1\nHost: data.water.vic.gov.au\nUser-Agent: httr2/0.2.2 r-curl/4.3.3 libcurl/7.64.1\nAccept: */*\nAccept-Encoding: deflate, gzip\nContent-Type: application/json\nContent-Length: 223\n\n{\"function\":\"get_ts_traces\",\"version\":\"2\",\"params\":{\"site_list\":\"405328\",\"start_time\":\"20200101000000\",\"var_list\":\"100,210\",\"interval\":\"day\",\"datasource\":\"A\",\"end_time\":\"20200115000000\",\"data_type\":\"mean\",\"multiplier\":\"1\"}}\n\nresps <- req %>% \n  req_body_json(sparams) %>% \n  req_perform()\n\nrbodys <- resps %>% resp_body_json(check_type = FALSE)\n\nstr(rbodys)\n\nList of 2\n $ error_num: int 0\n $ return   :List of 1\n  ..$ traces:List of 1\n  .. ..$ :List of 8\n  .. .. ..$ error_num      : int 0\n  .. .. ..$ compressed     : chr \"0\"\n  .. .. ..$ site_details   :List of 6\n  .. .. .. ..$ timezone  : chr \"10.0\"\n  .. .. .. ..$ short_name: chr \"STEAVENSON R @ FALLS\"\n  .. .. .. ..$ longitude : chr \"145.773503100\"\n  .. .. .. ..$ name      : chr \"STEAVENSON RIVER @ FALLS ROAD MARYSVILLE\"\n  .. .. .. ..$ latitude  : chr \"-37.525797590\"\n  .. .. .. ..$ org_name  : chr \"Victorian Rural Water Corporation\"\n  .. .. ..$ quality_codes  :List of 1\n  .. .. .. ..$ 2: chr \"Good quality data - minimal editing required. +/- 0mm - 10mm Drift correction\"\n  .. .. ..$ trace          :List of 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.741\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.738\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.736\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.734\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.741\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.755\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.745\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.739\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.735\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.745\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.759\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.745\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.742\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.740\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.757\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. ..$ varfrom_details:List of 6\n  .. .. .. ..$ short_name: chr \"Water Level (m)\"\n  .. .. .. ..$ precision : chr \"0.001000\"\n  .. .. .. ..$ subdesc   : chr \"Available for release\"\n  .. .. .. ..$ variable  : chr \"100.00\"\n  .. .. .. ..$ units     : chr \"metres\"\n  .. .. .. ..$ name      : chr \"Stream Water Level (m)\"\n  .. .. ..$ site           : chr \"405328\"\n  .. .. ..$ varto_details  :List of 6\n  .. .. .. ..$ short_name: chr \"Water Level (m)\"\n  .. .. .. ..$ precision : chr \"0.001000\"\n  .. .. .. ..$ subdesc   : chr \"Available for release\"\n  .. .. .. ..$ variable  : chr \"100.00\"\n  .. .. .. ..$ units     : chr \"metres\"\n  .. .. .. ..$ name      : chr \"Stream Water Level (m)\"\n\n\n\nCan we get derived (141, etc) with varlist\nIt looks like it’s really just 140 (cumecs) and 141 (ML/d) we’d want, if Vic matches QLD. There are a couple other varcons, but they’re about groundwater.\nLet’s see what get_varcon gives us. I can’t get this not to error, and the examples online have square brackets mixed in the json. I think some combo of c and list might do it but not worth it.\n\nvc_params <- list(\"function\" = 'get_varcon',\n               \"version\" = \"2\",\n               \"params\" = list(\"varcons\" = list(\"varfrom\" = \"100\",\n                               \"varto\" = \"141\",\n                               \"site_list\" = \"233217, 405328\",\n                               \"datasource\" = \"A\",\n                               \"requests\" = list(\"qf1\" = \"1\", \n                                                 \"t1\" = \"20200101000000\",\n                                                 \"t2\" = \"20200131000000\"))))\n\nreq <- request(vicurl)\n\nreq %>% \n  req_body_json(vc_params) %>% \n  req_dry_run()\n\nPOST /cgi/webservice.exe? HTTP/1.1\nHost: data.water.vic.gov.au\nUser-Agent: httr2/0.2.2 r-curl/4.3.3 libcurl/7.64.1\nAccept: */*\nAccept-Encoding: deflate, gzip\nContent-Type: application/json\nContent-Length: 205\n\n{\"function\":\"get_varcon\",\"version\":\"2\",\"params\":{\"varcons\":{\"varfrom\":\"100\",\"varto\":\"141\",\"site_list\":\"233217, 405328\",\"datasource\":\"A\",\"requests\":{\"qf1\":\"1\",\"t1\":\"20200101000000\",\"t2\":\"20200131000000\"}}}}\n\nresp_vc <- req %>% \n  req_body_json(vc_params) %>% \n  req_perform()\n\nrbody_vc <- resp_vc %>% resp_body_json(check_type = FALSE)\n\nstr(rbody_vc)\n\nList of 3\n $ error_num: int 124\n $ error_msg: chr \"Access violation at address 005203ED in module 'webservice.exe'. Read of address 00000008\"\n $ return   :List of 1\n  ..$ varcons: list()\n\n\nThis isn’t worth it. If we ask for 141 or 140, just do another round with varfrom and varto. Or always get 100, 140, 141, then only sometimes get the others if asked?"
  },
  {
    "objectID": "vicwater/vicwater_api_howtocall.html#geolocation",
    "href": "vicwater/vicwater_api_howtocall.html#geolocation",
    "title": "Vicwater api crude testing",
    "section": "Geolocation",
    "text": "Geolocation\nSo, get_db_info seems to have a way to get sites by radius or bounding box.. And the flipside is we might want to get sites within a polygon, and so need their locations, which should be available as geoJSON. Try to figure both those out.\nI think get_site_geojson is going to be simpler. start there. Not sure why the site_list can’t have a c(), but the fields has to use it. Works though, gives a feature list. I think those are readable by sf, so that’s good. Not sure what the fields even are though. The help says “Any field that is part of the site table”. So I guess we need to sort that out. On to get_db_info.\n\ng_j_params <- list(\"function\" = 'get_site_geojson',\n               \"version\" = \"2\",\n               \"params\" = list(\"site_list\" = \"233217, 405328\",\n                               \"get_elev\" = \"1\",\n                               \"fields\" = c(\"zone\",\"region\")))\n\nreq <- request(vicurl)\n\nreq %>% \n  req_body_json(g_j_params) %>% \n  req_dry_run()\n\nPOST /cgi/webservice.exe? HTTP/1.1\nHost: data.water.vic.gov.au\nUser-Agent: httr2/0.2.2 r-curl/4.3.3 libcurl/7.64.1\nAccept: */*\nAccept-Encoding: deflate, gzip\nContent-Type: application/json\nContent-Length: 127\n\n{\"function\":\"get_site_geojson\",\"version\":\"2\",\"params\":{\"site_list\":\"233217, 405328\",\"get_elev\":\"1\",\"fields\":[\"zone\",\"region\"]}}\n\nresp_g_j <- req %>% \n  req_body_json(g_j_params) %>% \n  req_perform()\n\nrbody_g_j <- resp_g_j %>% resp_body_json(check_type = FALSE)\n\nstr(rbody_g_j)\n\nList of 2\n $ error_num: int 0\n $ return   :List of 2\n  ..$ features:List of 2\n  .. ..$ :List of 4\n  .. .. ..$ properties:List of 2\n  .. .. .. ..$ region: chr \"233\"\n  .. .. .. ..$ zone  : int 55\n  .. .. ..$ geometry  :List of 2\n  .. .. .. ..$ coordinates:List of 3\n  .. .. .. .. ..$ : num 144\n  .. .. .. .. ..$ : num -38.2\n  .. .. .. .. ..$ : int 0\n  .. .. .. ..$ type       : chr \"Point\"\n  .. .. ..$ id        : chr \"233217\"\n  .. .. ..$ type      : chr \"Feature\"\n  .. ..$ :List of 4\n  .. .. ..$ properties:List of 2\n  .. .. .. ..$ region: chr \"405\"\n  .. .. .. ..$ zone  : int 55\n  .. .. ..$ geometry  :List of 2\n  .. .. .. ..$ coordinates:List of 3\n  .. .. .. .. ..$ : num 146\n  .. .. .. .. ..$ : num -37.5\n  .. .. .. .. ..$ : int 0\n  .. .. .. ..$ type       : chr \"Point\"\n  .. .. ..$ id        : chr \"405328\"\n  .. .. ..$ type      : chr \"Feature\"\n  ..$ type    : chr \"FeatureCollection\""
  },
  {
    "objectID": "vicwater/vicwater_api_howtocall.html#db-info",
    "href": "vicwater/vicwater_api_howtocall.html#db-info",
    "title": "Vicwater api crude testing",
    "section": "DB info",
    "text": "DB info\nI was using get_db_info to test above, so let’s just go back to that as a start and think a bit more about what we want. look at the barown. Cannot feed it a list of sites for fitler_values. It does give lat/long/northing, etc, so could use this instead of geoJSON, but geoJSON probably better if we want geo. Using return_type = hash is not noticably different than return_type = array. All examples use hash, so I guess keep using that moving forward. I think we can filter on lots of things in this list, both here and in the geojson.\n\ndbparams <- list(\"function\" = 'get_db_info',\n               \"version\" = \"3\",\n               \"params\" = list(\"table_name\" = \"site\",\n                               \"return_type\" = \"array\",\n                               \"filter_values\" = list(\"station\" = \"233217\")))\n\nreq <- request(vicurl)\n\nreq %>% \n  req_body_json(dbparams) %>% \n  req_dry_run()\n\nPOST /cgi/webservice.exe? HTTP/1.1\nHost: data.water.vic.gov.au\nUser-Agent: httr2/0.2.2 r-curl/4.3.3 libcurl/7.64.1\nAccept: */*\nAccept-Encoding: deflate, gzip\nContent-Type: application/json\nContent-Length: 130\n\n{\"function\":\"get_db_info\",\"version\":\"3\",\"params\":{\"table_name\":\"site\",\"return_type\":\"array\",\"filter_values\":{\"station\":\"233217\"}}}\n\nrespdb <- req %>% \n  req_body_json(dbparams) %>% \n  req_perform()\n\nrbodydb <- respdb %>% resp_body_json(check_type = FALSE)\n\nstr(rbodydb)\n\nList of 2\n $ error_num: int 0\n $ return   :List of 1\n  ..$ rows:List of 1\n  .. ..$ :List of 62\n  .. .. ..$ category20: chr \"\"\n  .. .. ..$ category19: chr \"\"\n  .. .. ..$ category18: chr \"\"\n  .. .. ..$ category17: chr \"\"\n  .. .. ..$ category16: chr \"\"\n  .. .. ..$ category15: chr \"\"\n  .. .. ..$ category14: chr \"\"\n  .. .. ..$ category13: chr \"\"\n  .. .. ..$ category12: chr \"\"\n  .. .. ..$ category11: chr \"\"\n  .. .. ..$ category10: chr \"THIESS\"\n  .. .. ..$ active    : logi TRUE\n  .. .. ..$ northing  : chr \"5772691.000\"\n  .. .. ..$ timezone  : chr \"10.0\"\n  .. .. ..$ shortname : chr \"BARWON @ GEELONG\"\n  .. .. ..$ datecreate: int 18991230\n  .. .. ..$ elevdatum : chr \"\"\n  .. .. ..$ stname    : chr \"BARWON RIVER @ GEELONG\"\n  .. .. ..$ category9 : chr \"N/A\"\n  .. .. ..$ category8 : chr \"G\"\n  .. .. ..$ category7 : chr \"G\"\n  .. .. ..$ category6 : chr \"2WD\"\n  .. .. ..$ category5 : chr \"0\"\n  .. .. ..$ category4 : chr \"150\"\n  .. .. ..$ category3 : chr \"SEALED\"\n  .. .. ..$ category2 : chr \"V_93G4\"\n  .. .. ..$ category1 : chr \"0\"\n  .. .. ..$ elevacc   : chr \"1\"\n  .. .. ..$ dbver47   : logi FALSE\n  .. .. ..$ quarter   : chr \"Y\"\n  .. .. ..$ section   : int 0\n  .. .. ..$ commence  : int 19601118\n  .. .. ..$ parent    : chr \"\"\n  .. .. ..$ mapname   : chr \"GEE/SW\"\n  .. .. ..$ meridian  : chr \"\"\n  .. .. ..$ spare5    : chr \"\"\n  .. .. ..$ spare4    : chr \"\"\n  .. .. ..$ spare3    : chr \"\"\n  .. .. ..$ spare2    : chr \"\"\n  .. .. ..$ spare1    : chr \"BW\"\n  .. .. ..$ posacc    : chr \"9\"\n  .. .. ..$ timemod   : int 1359\n  .. .. ..$ region    : chr \"233\"\n  .. .. ..$ grdatum   : chr \"UTM\"\n  .. .. ..$ township  : chr \"\"\n  .. .. ..$ longitude : chr \"144.346892190\"\n  .. .. ..$ comment   : chr \"\\r\\n\\r\\n\\r\\nBarwon Water flood monitoring stationFrom the intersection of the Fyans St and La Trobe Terrace, he\"| __truncated__\n  .. .. ..$ lldatum   : chr \"WGS84\"\n  .. .. ..$ station   : chr \"233217\"\n  .. .. ..$ datemod   : int 20220513\n  .. .. ..$ timecreate: int 0\n  .. .. ..$ orgcode   : chr \"DSE\"\n  .. .. ..$ barcode   : chr \"Geelong\"\n  .. .. ..$ zone      : int 55\n  .. .. ..$ elev      : chr \"0.000\"\n  .. .. ..$ cease     : int 18991230\n  .. .. ..$ local_map : chr \"GEELONG\"\n  .. .. ..$ latitude  : chr \"-38.163605590\"\n  .. .. ..$ range     : chr \"\"\n  .. .. ..$ qquarter  : chr \"Y\"\n  .. .. ..$ easting   : chr \"267562.000\"\n  .. .. ..$ stntype   : chr \"VIR\"\n\n\n\nGeofiltering the db to select sites\nOK, so there are lots of ways to filter (sitename, date, name, etc). Some of those like Name or region or active might be useful, but for now let’s try the geo filters (boudning box and radius).\nTry circle (lat, long, radius in degrees)- use the Barwon lat/long.\nKeeps crashing with timeouts. is it just too much to ask for? Or is the json not right?\n\n# dbparams <- list(\"function\" = 'get_db_info',\n#                \"version\" = \"3\",\n#                \"params\" = list(\"table_name\" = \"site\",\n#                                \"return_type\" = \"hash\",\n#                                \"geo_filter\" = list(\"circle\" = c(\"-38.16\", \"144.35\", \"0.25\"))))\n# \n# req <- request(vicurl)\n# \n# req %>% \n#   req_body_json(dbparams) %>% \n#   req_dry_run()\n# \n# respdb <- req %>% \n#   req_body_json(dbparams) %>% \n#   req_perform()\n# \n# rbodydb <- respdb %>% resp_body_json(check_type = FALSE)\n# \n# str(rbodydb)\n\nLet’s try one of the other geofilters. Otherwise this will work better to write my own if I can et the geojson of all the sites.\nUgh. the rectangle (and region) need nested square brackets. I can make one with c(),\n\ndbparams <- list(\"function\" = 'get_db_info',\n               \"version\" = \"3\",\n               \"params\" = list(\"table_name\" = \"site\",\n                               \"return_type\" = \"hash\",\n                               \"geo_filter\" = list(\"rectangle\" = \n                                                     c(c(\"-38.126\", \"144.282\"),\n                                                       c(\"-38.223\", \"144.406\")))))\n\nreq <- request(vicurl)\n\nreq %>% \n  req_body_json(dbparams) %>% \n  req_dry_run()\n\nPOST /cgi/webservice.exe? HTTP/1.1\nHost: data.water.vic.gov.au\nUser-Agent: httr2/0.2.2 r-curl/4.3.3 libcurl/7.64.1\nAccept: */*\nAccept-Encoding: deflate, gzip\nContent-Type: application/json\nContent-Length: 161\n\n{\"function\":\"get_db_info\",\"version\":\"3\",\"params\":{\"table_name\":\"site\",\"return_type\":\"hash\",\"geo_filter\":{\"rectangle\":[\"-38.126\",\"144.282\",\"-38.223\",\"144.406\"]}}}\n\n# \n# respdb <- req %>% \n#   req_body_json(dbparams) %>% \n#   req_perform()\n# \n# rbodydb <- respdb %>% resp_body_json(check_type = FALSE)\n# \n# str(rbodydb)\n\nthe locations of all guages it’d be\nOK, generating the json for these geo selections is horrible. If I can pull faster to do it myself.\nCan I get a complete gaugelist, nad then pull geojson?"
  },
  {
    "objectID": "vicwater/vicwater_api_howtocall.html#get-all-gauges",
    "href": "vicwater/vicwater_api_howtocall.html#get-all-gauges",
    "title": "Vicwater api crude testing",
    "section": "Get all gauges",
    "text": "Get all gauges\nWhat’s the best way? with get_db_info? With get_sites_by_datasource? The latter would assume we know all datasources. We probably do just want those in ‘A’ but not positive.\nSo, how about db_info, but maybe not all columns? Tempted to get lat/long or easting/northing.\nTakes a while, but it does run. 189,464 sites??? Yikes. WHY? Clearly i need to filter on something.\n\ndbparams <- list(\"function\" = 'get_db_info',\n               \"version\" = \"3\",\n               \"params\" = list(\"table_name\" = \"site\",\n                               \"return_type\" = \"array\",\n                               \"field_list\" = c(\"station\", \"stname\", \"shortname\")))\n\nreq <- request(vicurl)\n\nreq %>% \n  req_body_json(dbparams) %>% \n  req_dry_run()\n\nPOST /cgi/webservice.exe? HTTP/1.1\nHost: data.water.vic.gov.au\nUser-Agent: httr2/0.2.2 r-curl/4.3.3 libcurl/7.64.1\nAccept: */*\nAccept-Encoding: deflate, gzip\nContent-Type: application/json\nContent-Length: 139\n\n{\"function\":\"get_db_info\",\"version\":\"3\",\"params\":{\"table_name\":\"site\",\"return_type\":\"array\",\"field_list\":[\"station\",\"stname\",\"shortname\"]}}\n\nrespdb <- req %>% \n  req_body_json(dbparams) %>% \n  req_perform()\n\nrbodydb <- respdb %>% resp_body_json(check_type = FALSE)\n\nstr(rbodydb)\n\nList of 2\n $ error_num: int 0\n $ return   :List of 1\n  ..$ rows:List of 189491\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"0\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"044079\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"044387\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"045407\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"045621\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"045652\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"045717\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"092825\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"097421\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"097962\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100000\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100001\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100002\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100003\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100004\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100005\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100006\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100007\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100008\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100009\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100010\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100011\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100012\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100013\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100014\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100015\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100016\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100017\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100018\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100019\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100020\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100021\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100022\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100023\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100024\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100025\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100026\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100028\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100029\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100030\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100031\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100032\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100033\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100034\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100035\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100036\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100037\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100038\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100039\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100040\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100041\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100042\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100043\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100044\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100045\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100046\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100047\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100048\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100049\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100050\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100051\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100054\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100055\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100056\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100057\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100058\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100059\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100060\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100061\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100062\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100063\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100064\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100065\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100066\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100067\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100068\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100069\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100070\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100071\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100072\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100073\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100074\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100075\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100076\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100077\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100078\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100079\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100080\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100081\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100082\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100083\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100084\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100085\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100086\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100087\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100088\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100089\"\n  .. ..$ :List of 3\n  .. .. ..$ shortname: chr \"\"\n  .. .. ..$ stname   : chr \"\"\n  .. .. ..$ station  : chr \"100090\"\n  .. .. [list output truncated]\n\n\nwhat are the variables at some of those sites? Can we figure out what’s up that way? I have a feeling some are groundewater, but there’s no obvious field for that.\n\nv_s_params <- list(\"function\" = 'get_variable_list',\n               \"version\" = \"1\",\n               \"params\" = list(\"site_list\" = \"100089, 100079\",\n                               \"datasource\" = \"A\"))\n\nreq <- request(vicurl)\n\nreq %>% \n  req_body_json(v_s_params) %>% \n  req_dry_run()\n\nPOST /cgi/webservice.exe? HTTP/1.1\nHost: data.water.vic.gov.au\nUser-Agent: httr2/0.2.2 r-curl/4.3.3 libcurl/7.64.1\nAccept: */*\nAccept-Encoding: deflate, gzip\nContent-Type: application/json\nContent-Length: 103\n\n{\"function\":\"get_variable_list\",\"version\":\"1\",\"params\":{\"site_list\":\"100089, 100079\",\"datasource\":\"A\"}}\n\nresp_v_s <- req %>% \n  req_body_json(v_s_params) %>% \n  req_perform()\n\nrbody_v_s <- resp_v_s %>% resp_body_json(check_type = FALSE)\n\nstr(rbody_v_s)\n\nList of 2\n $ error_num: int 0\n $ return   :List of 1\n  ..$ sites:List of 2\n  .. ..$ :List of 3\n  .. .. ..$ site_details:List of 3\n  .. .. .. ..$ timezone  : chr \"10.0\"\n  .. .. .. ..$ short_name: chr \"\"\n  .. .. .. ..$ name      : chr \"\"\n  .. .. ..$ variables   : list()\n  .. .. ..$ site        : chr \"100089\"\n  .. ..$ :List of 3\n  .. .. ..$ site_details:List of 3\n  .. .. .. ..$ timezone  : chr \"10.0\"\n  .. .. .. ..$ short_name: chr \"\"\n  .. .. .. ..$ name      : chr \"\"\n  .. .. ..$ variables   : list()\n  .. .. ..$ site        : chr \"100079\"\n\n\nUhhh, those have no variables? WHat’s going on here?"
  },
  {
    "objectID": "vicwater/vicwater_testing.html",
    "href": "vicwater/vicwater_testing.html",
    "title": "Testing VicWater API",
    "section": "",
    "text": "# knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())"
  },
  {
    "objectID": "vicwater/vicwater_testing.html#access-victoria-water-data-through-api",
    "href": "vicwater/vicwater_testing.html#access-victoria-water-data-through-api",
    "title": "Testing VicWater API",
    "section": "Access Victoria water data through API",
    "text": "Access Victoria water data through API\nThis document is my testing and development of functions to include in the {vicwater} package. Basically, it’s where I interactively sorted through how to hit the API functions, the formats of the lists, and how to unpack the returned lists. It is a work in progress, since that package is under development.\nWe want to access victorian water data for a set of sites. That requires using the api at https://data.water.vic.gov.au/cgi/webservice.exe?[JSON_request] , but it’s poorly documented. I think I got it mostly figured out in a testing document, but there’s a lot of extra testing in there that needs to be skipped over and cleaned up. My plan is to make this a package, but it needs more development. I’m moving further testing here so I can get to the point a bit quicker.\nLibraries. Do I still need jsonlite now that I’ve moved ot httr2?\n\nlibrary(tidyr)\nlibrary(tibble)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(stringr)\n\nWarning: package 'stringr' was built under R version 4.2.2\n\nlibrary(httr2)\n\nWarning: package 'httr2' was built under R version 4.2.2\n\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.2.2"
  },
  {
    "objectID": "vicwater/vicwater_testing.html#set-up-params",
    "href": "vicwater/vicwater_testing.html#set-up-params",
    "title": "Testing VicWater API",
    "section": "Set up params",
    "text": "Set up params\n\nURL\nThe base url that everything gets attached to is: and we use httr2::request to start building the request.\n\nvicurl <- \"https://data.water.vic.gov.au/cgi/webservice.exe?\"\nreqvic <- request(vicurl)\n\n\n\nSite lists\nI want to test with one, two, and several sites in a site list. I had tried to do \"sitelist\" = c('site', 'site') , and that failed. But it works to have \"site, site\"\nThe upper steavenson is 405328, Barwon is 233217 (and has Temp), Taggerty 405331 only ran 2010-2013, And the Marysville golf course 405837 (only rainfall). That hits some things we want to make sure we pick up- no longer running gauges, gauges with only rain, gauges with lots of variables, etc.\nI only make one site_list here with multiple, but can do the str_c inside the calls usually.\n\nbarwon <- '233217'\nsteavenson <- '405328'\ntaggerty <- '405331'\ngolf <- '405837'\n\nallsites <- str_c(barwon, steavenson, taggerty, golf, sep = \", \")"
  },
  {
    "objectID": "vicwater/vicwater_testing.html#api-functions",
    "href": "vicwater/vicwater_testing.html#api-functions",
    "title": "Testing VicWater API",
    "section": "API functions",
    "text": "API functions\nAnd how to call each- including multiple values.\nI finally found a couple sources of documentation that will hopefully be helpful: https://kisters.com.au/doco/hydllp.htm and https://water-monitoring.information.qld.gov.au/wini/Documents/RDMW_API_doco.pdf.\nThe first thing to do is to figure out what basic information is there, so we can ask for it. What we really want is get_ts_traces, but it has a lot of parameters (see Kisters docs). Some are relatively straightforward to meaning, though how to get them to be correct JSON can be tricky (e.g. site_list, while others are opaque, e.g. varfrom, varto, datasource, either to their meaning or what the options are we can ask for. We can try to figure that out with some querying of the other functions.\n\nDatasources\nCan we figure out what datasource means by asking for some by site?\nversion has to be 1.\n\nds_s_params <- list(\"function\" = 'get_datasources_by_site',\n               \"version\" = \"1\",\n               \"params\" = list(\"site_list\" = allsites))\n\nreqvic %>% \n  req_body_json(ds_s_params) %>% \n  req_dry_run()\n\nPOST /cgi/webservice.exe? HTTP/1.1\nHost: data.water.vic.gov.au\nUser-Agent: httr2/0.2.2 r-curl/4.3.3 libcurl/7.64.1\nAccept: */*\nAccept-Encoding: deflate, gzip\nContent-Type: application/json\nContent-Length: 108\n\n{\"function\":\"get_datasources_by_site\",\"version\":\"1\",\"params\":{\"site_list\":\"233217, 405328, 405331, 405837\"}}\n\nresp_ds_s <- reqvic %>% \n  req_body_json(ds_s_params) %>% \n  req_perform()\n\nrbody_ds_s <- resp_ds_s %>% resp_body_json(check_type = FALSE)\n\nstr(rbody_ds_s)\n\nList of 2\n $ error_num: int 0\n $ return   :List of 1\n  ..$ sites:List of 4\n  .. ..$ :List of 2\n  .. .. ..$ site       : chr \"233217\"\n  .. .. ..$ datasources:List of 3\n  .. .. .. ..$ : chr \"A\"\n  .. .. .. ..$ : chr \"TELEM\"\n  .. .. .. ..$ : chr \"TELEMCOPY\"\n  .. ..$ :List of 2\n  .. .. ..$ site       : chr \"405328\"\n  .. .. ..$ datasources:List of 3\n  .. .. .. ..$ : chr \"A\"\n  .. .. .. ..$ : chr \"TELEM\"\n  .. .. .. ..$ : chr \"TELEMCOPY\"\n  .. ..$ :List of 2\n  .. .. ..$ site       : chr \"405331\"\n  .. .. ..$ datasources:List of 2\n  .. .. .. ..$ : chr \"A\"\n  .. .. .. ..$ : chr \"TELEM\"\n  .. ..$ :List of 2\n  .. .. ..$ site       : chr \"405837\"\n  .. .. ..$ datasources:List of 3\n  .. .. .. ..$ : chr \"A\"\n  .. .. .. ..$ : chr \"TELEM\"\n  .. .. .. ..$ : chr \"TELEMCOPY\"\n\n\nI’ll need to sort out how to unpack that list later, but for now, let’s just look at it and see that all of them have options A and TELEM, and a couple have TELEMCOPY.\nAccording to the QLD pdf, the datasource distinguishes things like Archive and Telemetry. That’s similar in Vic, though QLD also had codes for back-filled holes, which don’t seem to be here (at least at these sites).\nSeems like it will be safest to ask for ‘A’ or ‘TELEM’.\nAnd the different variables can be in a var_list or varto and varfrom (though not always- see below). The numbers are for different variables, but again, no guarantee they’re the same in Vic.\n\nunpacking the list\nI might as well do this and build the function. Should be able to do it with unnest, and then maybe drop dumb columns? Nope, some of the lists unpack into lists of mixed type. But unnest_wider and unnest_longer might be the trick. Will need to test with single sites in case the structure changes.\nFor the function, we probably want to just print the error value or something, and not return it in the df. Or if it errors, return that, if it doesn’t, just give df. That’s probably best.\n\na <- as_tibble(rbody_ds_s[2]) %>% # the [2] drops the error column\n  unnest_longer(col = where(is.list)) %>% # error and a `return` list\n  unnest_wider(col = where(is.list)) %>% # error, site, and a `datasources` list\n  unnest_longer(col = where(is.list)) # fully unpacked into a long df\na\n\n# A tibble: 11 × 2\n   site   datasources\n   <chr>  <chr>      \n 1 233217 A          \n 2 233217 TELEM      \n 3 233217 TELEMCOPY  \n 4 405328 A          \n 5 405328 TELEM      \n 6 405328 TELEMCOPY  \n 7 405331 A          \n 8 405331 TELEM      \n 9 405837 A          \n10 405837 TELEM      \n11 405837 TELEMCOPY  \n\n\nMight actually be better as a table or pivot_wider? Depends what the point is? Pivot wider is kind of a pain, use table? But table actually unpacks longer when I as_tibble or as.data.frame it. Which is annoying.\n\nb <- table(a$site, a$datasources)\nb\n\n        \n         A TELEM TELEMCOPY\n  233217 1     1         1\n  405328 1     1         1\n  405331 1     1         0\n  405837 1     1         1\n\n\nI think just return the long tibble, and do the table as a plot or explicitly a table or something. Which orientation makes most sense? Not sure. Probably gauges on x? But plots of actual data will have gauges on y, time on x, so maybe stay consistent.\n\nc <- b %>% \n  as_tibble(.name_repair = 'unique') %>% \n  rename(gauge = `...1`, datasource = `...2`)\n\nNew names:\n• `` -> `...1`\n• `` -> `...2`\n\nc %>% \n  mutate(n = as.logical(n)) %>% \nggplot2::ggplot(ggplot2::aes(x = datasource, y = gauge, fill = n)) + \n  ggplot2::geom_tile(colour=\"white\", size=0.25) +\n  ggplot2::scale_fill_discrete(type = c('firebrick', 'dodgerblue')) +\n  ggplot2::labs(fill = NULL) +\n  ggplot2::coord_equal()\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nCan I just build that plot from a? Yes, but would be just as annoying. maybe.\n\nallopts <- a %>%\n  expand(site, datasources)\n\na2 <- a %>% \n  mutate(indata = TRUE) %>% \n  dplyr::right_join(allopts) %>% \n  mutate(indata = ifelse(is.na(indata), FALSE, indata))\n\nJoining, by = c(\"site\", \"datasources\")\n\n  ggplot(a2, aes(x = datasources, y = site, fill = indata)) + \n  ggplot2::geom_tile(colour=\"white\", linewidth=0.25) +\n  ggplot2::scale_fill_discrete(type = c('firebrick', 'dodgerblue')) +\n  ggplot2::labs(fill = NULL) +\n  ggplot2::coord_equal()\n\n\n\n\nGood enough for this one- turn that into a function in a package.\n\n\n\nTest from the package\nI’m using devtools::load_all() to load the package repo in here for interactive testing and poking.\nObviously, hard paths are a bad idea, but I’m going to do it here since I typically do relative within repos, and these are across repos. Still, temporary and hacky.\n\ndevtools::load_all('C:/Users/Galen/Documents/vicwater')\n\nℹ Loading vicwater\n\n\n\nreturntib <- get_datasources_by_site(vicurl, allsites)\n\n\nreturntib\n\n# A tibble: 11 × 2\n   site   datasource\n   <chr>  <chr>     \n 1 233217 A         \n 2 233217 TELEM     \n 3 233217 TELEMCOPY \n 4 405328 A         \n 5 405328 TELEM     \n 6 405328 TELEMCOPY \n 7 405331 A         \n 8 405331 TELEM     \n 9 405837 A         \n10 405837 TELEM     \n11 405837 TELEMCOPY \n\nplot_datasources_by_site(returntib)\n\nJoining, by = c(\"site\", \"datasource\")\n\n\n\n\n\n\n\nSites by datasource\nHaven’t written this one before, might blow things up. But if we want a list of sites, it might be better than the way I did this before of just asking for everything in the db, lots of which had no data.\nAnd now we know the datasource options. I think? I suppose it’s possible there’s another type I’m not aware of.\nFor some weird reason, sitelists should be \"site, site, site\", while the datasources should be c('source', 'source'). The latter yields JSON array ['source', 'source'], while the former yields JSON 'site', 'site'\nThis works. The list truncates, but it did work.\n\nds_wanted <- c('A', 'TELEM')\ns_ds_params <- list(\"function\" = 'get_sites_by_datasource',\n               \"version\" = \"1\",\n               \"params\" = list(\"datasources\" = ds_wanted))\n\nreqvic %>% \n  req_body_json(s_ds_params) %>% \n  req_dry_run()\n\nPOST /cgi/webservice.exe? HTTP/1.1\nHost: data.water.vic.gov.au\nUser-Agent: httr2/0.2.2 r-curl/4.3.3 libcurl/7.64.1\nAccept: */*\nAccept-Encoding: deflate, gzip\nContent-Type: application/json\nContent-Length: 91\n\n{\"function\":\"get_sites_by_datasource\",\"version\":\"1\",\"params\":{\"datasources\":[\"A\",\"TELEM\"]}}\n\nresp_s_ds <- reqvic %>% \n  req_body_json(s_ds_params) %>% \n  req_perform()\n\nrbody_s_ds <- resp_s_ds %>% resp_body_json(check_type = FALSE)\n\nstr(rbody_s_ds)\n\nList of 2\n $ error_num: int 0\n $ return   :List of 1\n  ..$ datasources:List of 2\n  .. ..$ :List of 2\n  .. .. ..$ datasource: chr \"A\"\n  .. .. ..$ sites     :List of 4044\n  .. .. .. ..$ : chr \"100023\"\n  .. .. .. ..$ : chr \"100500\"\n  .. .. .. ..$ : chr \"100503\"\n  .. .. .. ..$ : chr \"100504\"\n  .. .. .. ..$ : chr \"101708\"\n  .. .. .. ..$ : chr \"102621\"\n  .. .. .. ..$ : chr \"102827\"\n  .. .. .. ..$ : chr \"102828\"\n  .. .. .. ..$ : chr \"102829\"\n  .. .. .. ..$ : chr \"102830\"\n  .. .. .. ..$ : chr \"102831\"\n  .. .. .. ..$ : chr \"103811\"\n  .. .. .. ..$ : chr \"104929\"\n  .. .. .. ..$ : chr \"104930\"\n  .. .. .. ..$ : chr \"105134\"\n  .. .. .. ..$ : chr \"105222\"\n  .. .. .. ..$ : chr \"105287\"\n  .. .. .. ..$ : chr \"105317\"\n  .. .. .. ..$ : chr \"105480\"\n  .. .. .. ..$ : chr \"105484\"\n  .. .. .. ..$ : chr \"105936\"\n  .. .. .. ..$ : chr \"107631\"\n  .. .. .. ..$ : chr \"107970\"\n  .. .. .. ..$ : chr \"107971\"\n  .. .. .. ..$ : chr \"108201\"\n  .. .. .. ..$ : chr \"108203\"\n  .. .. .. ..$ : chr \"108319\"\n  .. .. .. ..$ : chr \"108320\"\n  .. .. .. ..$ : chr \"108321\"\n  .. .. .. ..$ : chr \"108898\"\n  .. .. .. ..$ : chr \"108899\"\n  .. .. .. ..$ : chr \"108917\"\n  .. .. .. ..$ : chr \"108944\"\n  .. .. .. ..$ : chr \"109133\"\n  .. .. .. ..$ : chr \"109461\"\n  .. .. .. ..$ : chr \"109462\"\n  .. .. .. ..$ : chr \"109644\"\n  .. .. .. ..$ : chr \"109645\"\n  .. .. .. ..$ : chr \"109769\"\n  .. .. .. ..$ : chr \"109770\"\n  .. .. .. ..$ : chr \"109778\"\n  .. .. .. ..$ : chr \"109779\"\n  .. .. .. ..$ : chr \"110151\"\n  .. .. .. ..$ : chr \"110152\"\n  .. .. .. ..$ : chr \"110153\"\n  .. .. .. ..$ : chr \"110171\"\n  .. .. .. ..$ : chr \"110186\"\n  .. .. .. ..$ : chr \"110464\"\n  .. .. .. ..$ : chr \"110721\"\n  .. .. .. ..$ : chr \"110724\"\n  .. .. .. ..$ : chr \"110731\"\n  .. .. .. ..$ : chr \"110739\"\n  .. .. .. ..$ : chr \"110745\"\n  .. .. .. ..$ : chr \"110943\"\n  .. .. .. ..$ : chr \"110978\"\n  .. .. .. ..$ : chr \"111543\"\n  .. .. .. ..$ : chr \"111549\"\n  .. .. .. ..$ : chr \"111551\"\n  .. .. .. ..$ : chr \"111691\"\n  .. .. .. ..$ : chr \"111692\"\n  .. .. .. ..$ : chr \"112182\"\n  .. .. .. ..$ : chr \"112235\"\n  .. .. .. ..$ : chr \"112236\"\n  .. .. .. ..$ : chr \"112237\"\n  .. .. .. ..$ : chr \"112459\"\n  .. .. .. ..$ : chr \"112708\"\n  .. .. .. ..$ : chr \"112803\"\n  .. .. .. ..$ : chr \"112804\"\n  .. .. .. ..$ : chr \"113004\"\n  .. .. .. ..$ : chr \"113124\"\n  .. .. .. ..$ : chr \"113125\"\n  .. .. .. ..$ : chr \"113467\"\n  .. .. .. ..$ : chr \"113694\"\n  .. .. .. ..$ : chr \"113695\"\n  .. .. .. ..$ : chr \"113705\"\n  .. .. .. ..$ : chr \"113706\"\n  .. .. .. ..$ : chr \"114158\"\n  .. .. .. ..$ : chr \"114169\"\n  .. .. .. ..$ : chr \"115732\"\n  .. .. .. ..$ : chr \"115872\"\n  .. .. .. ..$ : chr \"116382\"\n  .. .. .. ..$ : chr \"116459\"\n  .. .. .. ..$ : chr \"116460\"\n  .. .. .. ..$ : chr \"116802\"\n  .. .. .. ..$ : chr \"116803\"\n  .. .. .. ..$ : chr \"119329\"\n  .. .. .. ..$ : chr \"119330\"\n  .. .. .. ..$ : chr \"119337\"\n  .. .. .. ..$ : chr \"119338\"\n  .. .. .. ..$ : chr \"119339\"\n  .. .. .. ..$ : chr \"119340\"\n  .. .. .. ..$ : chr \"119341\"\n  .. .. .. ..$ : chr \"119342\"\n  .. .. .. ..$ : chr \"119347\"\n  .. .. .. ..$ : chr \"119348\"\n  .. .. .. ..$ : chr \"119366\"\n  .. .. .. ..$ : chr \"119367\"\n  .. .. .. ..$ : chr \"119377\"\n  .. .. .. ..$ : chr \"120248\"\n  .. .. .. .. [list output truncated]\n  .. ..$ :List of 2\n  .. .. ..$ datasource: chr \"TELEM\"\n  .. .. ..$ sites     :List of 2093\n  .. .. .. ..$ : chr \"100023\"\n  .. .. .. ..$ : chr \"100500\"\n  .. .. .. ..$ : chr \"100503\"\n  .. .. .. ..$ : chr \"100504\"\n  .. .. .. ..$ : chr \"100731\"\n  .. .. .. ..$ : chr \"101708\"\n  .. .. .. ..$ : chr \"102621\"\n  .. .. .. ..$ : chr \"102827\"\n  .. .. .. ..$ : chr \"102828\"\n  .. .. .. ..$ : chr \"102829\"\n  .. .. .. ..$ : chr \"102830\"\n  .. .. .. ..$ : chr \"102831\"\n  .. .. .. ..$ : chr \"103811\"\n  .. .. .. ..$ : chr \"104929\"\n  .. .. .. ..$ : chr \"104930\"\n  .. .. .. ..$ : chr \"105134\"\n  .. .. .. ..$ : chr \"105222\"\n  .. .. .. ..$ : chr \"105484\"\n  .. .. .. ..$ : chr \"105936\"\n  .. .. .. ..$ : chr \"107631\"\n  .. .. .. ..$ : chr \"107970\"\n  .. .. .. ..$ : chr \"108201\"\n  .. .. .. ..$ : chr \"108203\"\n  .. .. .. ..$ : chr \"108319\"\n  .. .. .. ..$ : chr \"108320\"\n  .. .. .. ..$ : chr \"108321\"\n  .. .. .. ..$ : chr \"108944\"\n  .. .. .. ..$ : chr \"109133\"\n  .. .. .. ..$ : chr \"109462\"\n  .. .. .. ..$ : chr \"109644\"\n  .. .. .. ..$ : chr \"109645\"\n  .. .. .. ..$ : chr \"109769\"\n  .. .. .. ..$ : chr \"109770\"\n  .. .. .. ..$ : chr \"110151\"\n  .. .. .. ..$ : chr \"110152\"\n  .. .. .. ..$ : chr \"110153\"\n  .. .. .. ..$ : chr \"110171\"\n  .. .. .. ..$ : chr \"110186\"\n  .. .. .. ..$ : chr \"110464\"\n  .. .. .. ..$ : chr \"110721\"\n  .. .. .. ..$ : chr \"110724\"\n  .. .. .. ..$ : chr \"110731\"\n  .. .. .. ..$ : chr \"110739\"\n  .. .. .. ..$ : chr \"110745\"\n  .. .. .. ..$ : chr \"110943\"\n  .. .. .. ..$ : chr \"110978\"\n  .. .. .. ..$ : chr \"111543\"\n  .. .. .. ..$ : chr \"111549\"\n  .. .. .. ..$ : chr \"111551\"\n  .. .. .. ..$ : chr \"111691\"\n  .. .. .. ..$ : chr \"111692\"\n  .. .. .. ..$ : chr \"112182\"\n  .. .. .. ..$ : chr \"112185\"\n  .. .. .. ..$ : chr \"112235\"\n  .. .. .. ..$ : chr \"112236\"\n  .. .. .. ..$ : chr \"112237\"\n  .. .. .. ..$ : chr \"112459\"\n  .. .. .. ..$ : chr \"112708\"\n  .. .. .. ..$ : chr \"112803\"\n  .. .. .. ..$ : chr \"112804\"\n  .. .. .. ..$ : chr \"113004\"\n  .. .. .. ..$ : chr \"113124\"\n  .. .. .. ..$ : chr \"113125\"\n  .. .. .. ..$ : chr \"113467\"\n  .. .. .. ..$ : chr \"113694\"\n  .. .. .. ..$ : chr \"113695\"\n  .. .. .. ..$ : chr \"113705\"\n  .. .. .. ..$ : chr \"113706\"\n  .. .. .. ..$ : chr \"114158\"\n  .. .. .. ..$ : chr \"114169\"\n  .. .. .. ..$ : chr \"114975\"\n  .. .. .. ..$ : chr \"115732\"\n  .. .. .. ..$ : chr \"116382\"\n  .. .. .. ..$ : chr \"116802\"\n  .. .. .. ..$ : chr \"116803\"\n  .. .. .. ..$ : chr \"119329\"\n  .. .. .. ..$ : chr \"119337\"\n  .. .. .. ..$ : chr \"119340\"\n  .. .. .. ..$ : chr \"119341\"\n  .. .. .. ..$ : chr \"119342\"\n  .. .. .. ..$ : chr \"119347\"\n  .. .. .. ..$ : chr \"119348\"\n  .. .. .. ..$ : chr \"119366\"\n  .. .. .. ..$ : chr \"119367\"\n  .. .. .. ..$ : chr \"119377\"\n  .. .. .. ..$ : chr \"120248\"\n  .. .. .. ..$ : chr \"121019\"\n  .. .. .. ..$ : chr \"122152\"\n  .. .. .. ..$ : chr \"123140\"\n  .. .. .. ..$ : chr \"126975\"\n  .. .. .. ..$ : chr \"129744\"\n  .. .. .. ..$ : chr \"129746\"\n  .. .. .. ..$ : chr \"134949\"\n  .. .. .. ..$ : chr \"137194\"\n  .. .. .. ..$ : chr \"137195\"\n  .. .. .. ..$ : chr \"137197\"\n  .. .. .. ..$ : chr \"137198\"\n  .. .. .. ..$ : chr \"137199\"\n  .. .. .. ..$ : chr \"137200\"\n  .. .. .. .. [list output truncated]\n\n\nCan I tibble that up?\n\ns <- as_tibble(rbody_s_ds[2]) %>% # the [2] drops the error column\n  unnest_longer(col = where(is.list)) %>% # a `return` list\n  unnest_wider(col = where(is.list)) %>% # sites, and a `datasource` list\n  unnest_longer(col = where(is.list)) # fully unpacked into a long df\ns\n\n# A tibble: 6,137 × 2\n   datasource sites \n   <chr>      <chr> \n 1 A          100023\n 2 A          100500\n 3 A          100503\n 4 A          100504\n 5 A          101708\n 6 A          102621\n 7 A          102827\n 8 A          102828\n 9 A          102829\n10 A          102830\n# … with 6,127 more rows\n\n\nWhat are the number of sites in each?\n\ns %>% group_by(datasource) %>% summarise(n = n())\n\n# A tibble: 2 × 2\n  datasource     n\n  <chr>      <int>\n1 A           4044\n2 TELEM       2093\n\n\nWay more in Archive. Are there any in Telem that aren’t in A?\n\ntsites <- s %>% \n  filter(datasource == 'TELEM') %>% \n  select(sites) %>% \n  pull()\n\nasites <- s %>% \n  filter(datasource == 'A') %>% \n  select(sites) %>% \n  pull()\n\nall(tsites %in% asites)\n\n[1] FALSE\n\nsum(!(tsites %in% asites))\n\n[1] 96\n\n\nsee if I can blow up ggplot. Oof the plurals\n\ns <- s %>% \n  rename(site = sites, datasources = datasource)\n\nUnreadable. Not surprisingly.\n\nplot_datasources_by_site(s) + coord_flip()\n\nyikes.\n\n\nTest package version\n\ndevtools::load_all('C:/Users/Galen/Documents/vicwater')\n\nℹ Loading vicwater\n\nsxd <- get_sites_by_datasource(datasources = c('A', 'TELEM'))\n\n\nsxd\n\n# A tibble: 6,172 × 2\n   datasource site  \n   <chr>      <chr> \n 1 A          100023\n 2 A          100500\n 3 A          100503\n 4 A          100504\n 5 A          101708\n 6 A          102621\n 7 A          102827\n 8 A          102828\n 9 A          102829\n10 A          102830\n# … with 6,162 more rows\n\n\nPlot still needs work.\n\nplot_datasources_by_site(sxd) + coord_flip()\n\nJoining, by = c(\"datasource\", \"site\")"
  },
  {
    "objectID": "vicwater/vicwater_testing.html#variables",
    "href": "vicwater/vicwater_testing.html#variables",
    "title": "Testing VicWater API",
    "section": "Variables",
    "text": "Variables\nor do I go straight for get_ts_ and then back this back out? Or get_db_info?\nI think I’m going to want to use get_variable_list both in get_ts_traces and to generate a set of possible variables.\nI’d like to get all sites, then make a master list of datasources and variables. But I need to get this usable for get_ts_traces, I think.\n\nGet_variable_list\nFeeding this a c(datasource, datasource) makes it return only some of the results, but throws no errors. So do one at a time.\n\nv_s_params <- list(\"function\" = 'get_variable_list',\n               \"version\" = \"1\",\n               \"params\" = list(\"site_list\" = allsites,\n                               \"datasource\" = \"A\"))\n\nreq <- request(vicurl)\n\nreq %>% \n  req_body_json(v_s_params) %>% \n  req_dry_run()\n\nPOST /cgi/webservice.exe? HTTP/1.1\nHost: data.water.vic.gov.au\nUser-Agent: httr2/0.2.2 r-curl/4.3.3 libcurl/7.64.1\nAccept: */*\nAccept-Encoding: deflate, gzip\nContent-Type: application/json\nContent-Length: 119\n\n{\"function\":\"get_variable_list\",\"version\":\"1\",\"params\":{\"site_list\":\"233217, 405328, 405331, 405837\",\"datasource\":\"A\"}}\n\nresp_v_s <- req %>% \n  req_body_json(v_s_params) %>% \n  req_perform()\n\nrbody_v_s <- resp_v_s %>% resp_body_json(check_type = FALSE)\n\nstr(rbody_v_s)\n\nList of 2\n $ error_num: int 0\n $ return   :List of 1\n  ..$ sites:List of 4\n  .. ..$ :List of 3\n  .. .. ..$ site_details:List of 3\n  .. .. .. ..$ timezone  : chr \"10.0\"\n  .. .. .. ..$ short_name: chr \"BARWON @ GEELONG\"\n  .. .. .. ..$ name      : chr \"BARWON RIVER @ GEELONG\"\n  .. .. ..$ variables   :List of 6\n  .. .. .. ..$ :List of 6\n  .. .. .. .. ..$ period_end  : chr \"20221107070000\"\n  .. .. .. .. ..$ period_start: chr \"19610306171500\"\n  .. .. .. .. ..$ subdesc     : chr \"Available for release\"\n  .. .. .. .. ..$ variable    : chr \"100.00\"\n  .. .. .. .. ..$ units       : chr \"metres\"\n  .. .. .. .. ..$ name        : chr \"Stream Water Level (m)\"\n  .. .. .. ..$ :List of 6\n  .. .. .. .. ..$ period_end  : chr \"20221107070000\"\n  .. .. .. .. ..$ period_start: chr \"20100706123100\"\n  .. .. .. .. ..$ subdesc     : chr \"Available for release\"\n  .. .. .. .. ..$ variable    : chr \"210.00\"\n  .. .. .. .. ..$ units       : chr \"pH\"\n  .. .. .. .. ..$ name        : chr \"Acidity/Alkalinity (pH)\"\n  .. .. .. ..$ :List of 6\n  .. .. .. .. ..$ period_end  : chr \"20221107070000\"\n  .. .. .. .. ..$ period_start: chr \"20100706123100\"\n  .. .. .. .. ..$ subdesc     : chr \"Available for release\"\n  .. .. .. .. ..$ variable    : chr \"215.00\"\n  .. .. .. .. ..$ units       : chr \"ppm\"\n  .. .. .. .. ..$ name        : chr \"Dissolved Oxygen (ppm)\"\n  .. .. .. ..$ :List of 6\n  .. .. .. .. ..$ period_end  : chr \"20221107070000\"\n  .. .. .. .. ..$ period_start: chr \"20100706123100\"\n  .. .. .. .. ..$ subdesc     : chr \"Available for release\"\n  .. .. .. .. ..$ variable    : chr \"450.00\"\n  .. .. .. .. ..$ units       : chr \"Degrees celsius\"\n  .. .. .. .. ..$ name        : chr \"Water Temperature (°C)\"\n  .. .. .. ..$ :List of 6\n  .. .. .. .. ..$ period_end  : chr \"20221107070000\"\n  .. .. .. .. ..$ period_start: chr \"20100706123100\"\n  .. .. .. .. ..$ subdesc     : chr \"Available for release\"\n  .. .. .. .. ..$ variable    : chr \"810.00\"\n  .. .. .. .. ..$ units       : chr \"NTU\"\n  .. .. .. .. ..$ name        : chr \"Turbidity (NTU)\"\n  .. .. .. ..$ :List of 6\n  .. .. .. .. ..$ period_end  : chr \"20221107070000\"\n  .. .. .. .. ..$ period_start: chr \"20100706123100\"\n  .. .. .. .. ..$ subdesc     : chr \"Available for release\"\n  .. .. .. .. ..$ variable    : chr \"820.00\"\n  .. .. .. .. ..$ units       : chr \"µS/cm@25°C\"\n  .. .. .. .. ..$ name        : chr \"Conductivity (µS/cm)\"\n  .. .. ..$ site        : chr \"233217\"\n  .. ..$ :List of 3\n  .. .. ..$ site_details:List of 3\n  .. .. .. ..$ timezone  : chr \"10.0\"\n  .. .. .. ..$ short_name: chr \"STEAVENSON R @ FALLS\"\n  .. .. .. ..$ name      : chr \"STEAVENSON RIVER @ FALLS ROAD MARYSVILLE\"\n  .. .. ..$ variables   :List of 1\n  .. .. .. ..$ :List of 6\n  .. .. .. .. ..$ period_end  : chr \"20221202090000\"\n  .. .. .. .. ..$ period_start: chr \"20091119170800\"\n  .. .. .. .. ..$ subdesc     : chr \"Available for release\"\n  .. .. .. .. ..$ variable    : chr \"100.00\"\n  .. .. .. .. ..$ units       : chr \"metres\"\n  .. .. .. .. ..$ name        : chr \"Stream Water Level (m)\"\n  .. .. ..$ site        : chr \"405328\"\n  .. ..$ :List of 3\n  .. .. ..$ site_details:List of 3\n  .. .. .. ..$ timezone  : chr \"10.0\"\n  .. .. .. ..$ short_name: chr \"TAGGERTY R LADY TALT\"\n  .. .. .. ..$ name      : chr \"TAGGERTY RV @ LADY TALBOT DRIVE NEAR MARYSVILLE\"\n  .. .. ..$ variables   :List of 4\n  .. .. .. ..$ :List of 6\n  .. .. .. .. ..$ period_end  : chr \"20130211110700\"\n  .. .. .. .. ..$ period_start: chr \"20100729122000\"\n  .. .. .. .. ..$ subdesc     : chr \"Available for release\"\n  .. .. .. .. ..$ variable    : chr \"100.00\"\n  .. .. .. .. ..$ units       : chr \"metres\"\n  .. .. .. .. ..$ name        : chr \"Stream Water Level (m)\"\n  .. .. .. ..$ :List of 6\n  .. .. .. .. ..$ period_end  : chr \"20130211110700\"\n  .. .. .. .. ..$ period_start: chr \"20100729122000\"\n  .. .. .. .. ..$ subdesc     : chr \"Available for release\"\n  .. .. .. .. ..$ variable    : chr \"450.00\"\n  .. .. .. .. ..$ units       : chr \"Degrees celsius\"\n  .. .. .. .. ..$ name        : chr \"Water Temperature (°C)\"\n  .. .. .. ..$ :List of 6\n  .. .. .. .. ..$ period_end  : chr \"20130211110700\"\n  .. .. .. .. ..$ period_start: chr \"20100729122000\"\n  .. .. .. .. ..$ subdesc     : chr \"Available for release\"\n  .. .. .. .. ..$ variable    : chr \"810.00\"\n  .. .. .. .. ..$ units       : chr \"NTU\"\n  .. .. .. .. ..$ name        : chr \"Turbidity (NTU)\"\n  .. .. .. ..$ :List of 6\n  .. .. .. .. ..$ period_end  : chr \"20130211110700\"\n  .. .. .. .. ..$ period_start: chr \"20100729122000\"\n  .. .. .. .. ..$ subdesc     : chr \"Available for release\"\n  .. .. .. .. ..$ variable    : chr \"820.00\"\n  .. .. .. .. ..$ units       : chr \"µS/cm@25°C\"\n  .. .. .. .. ..$ name        : chr \"Conductivity (µS/cm)\"\n  .. .. ..$ site        : chr \"405331\"\n  .. ..$ :List of 3\n  .. .. ..$ site_details:List of 3\n  .. .. .. ..$ timezone  : chr \"10.0\"\n  .. .. .. ..$ short_name: chr \"R.G. MARYSVILLE\"\n  .. .. .. ..$ name      : chr \"RAINGAUGE @ MARYSVILLE GOLF CLUB\"\n  .. .. ..$ variables   :List of 1\n  .. .. .. ..$ :List of 6\n  .. .. .. .. ..$ period_end  : chr \"20221202081730\"\n  .. .. .. .. ..$ period_start: chr \"20010621142700\"\n  .. .. .. .. ..$ subdesc     : chr \"Available for release\"\n  .. .. .. .. ..$ variable    : chr \"10.00\"\n  .. .. .. .. ..$ units       : chr \"mm\"\n  .. .. .. .. ..$ name        : chr \"Rainfall (mm)\"\n  .. .. ..$ site        : chr \"405837\"\n\n\nUnpack that\n\ns <- as_tibble(rbody_v_s[2]) %>% # the [2] drops the error column\n  unnest_longer(col = where(is.list)) %>% # a `return` list\n  unnest_wider(col = where(is.list)) %>% # sites, and a `datasource` list\n  unnest_wider(col = site_details) %>% # site details in new cols\n  unnest_longer(col = variables) %>% # one line per variable, details of variables in a list\n  rename(long_name = name) %>% # variables have names too, avoid conflicts\n  unnest_wider(col = variables) %>% # columns for each attribute of the variables\n  rename(var_name = name)\ns\n\n# A tibble: 12 × 10\n   timezone short_…¹ long_…² perio…³ perio…⁴ subdesc varia…⁵ units var_n…⁶ site \n   <chr>    <chr>    <chr>   <chr>   <chr>   <chr>   <chr>   <chr> <chr>   <chr>\n 1 10.0     BARWON … BARWON… 202211… 196103… Availa… 100.00  metr… Stream… 2332…\n 2 10.0     BARWON … BARWON… 202211… 201007… Availa… 210.00  pH    Acidit… 2332…\n 3 10.0     BARWON … BARWON… 202211… 201007… Availa… 215.00  ppm   Dissol… 2332…\n 4 10.0     BARWON … BARWON… 202211… 201007… Availa… 450.00  Degr… Water … 2332…\n 5 10.0     BARWON … BARWON… 202211… 201007… Availa… 810.00  NTU   Turbid… 2332…\n 6 10.0     BARWON … BARWON… 202211… 201007… Availa… 820.00  µS/c… Conduc… 2332…\n 7 10.0     STEAVEN… STEAVE… 202212… 200911… Availa… 100.00  metr… Stream… 4053…\n 8 10.0     TAGGERT… TAGGER… 201302… 201007… Availa… 100.00  metr… Stream… 4053…\n 9 10.0     TAGGERT… TAGGER… 201302… 201007… Availa… 450.00  Degr… Water … 4053…\n10 10.0     TAGGERT… TAGGER… 201302… 201007… Availa… 810.00  NTU   Turbid… 4053…\n11 10.0     TAGGERT… TAGGER… 201302… 201007… Availa… 820.00  µS/c… Conduc… 4053…\n12 10.0     R.G. MA… RAINGA… 202212… 200106… Availa… 10.00   mm    Rainfa… 4058…\n# … with abbreviated variable names ¹​short_name, ²​long_name, ³​period_end,\n#   ⁴​period_start, ⁵​variable, ⁶​var_name\n\n\n\n\nTest package version\n\ndevtools::load_all('C:/Users/Galen/Documents/vicwater')\n\nℹ Loading vicwater\n\nvl <- get_variable_list(site_list = allsites, datasource = 'A')\n\n\nvl\n\n# A tibble: 12 × 11\n   site   short_…¹ long_…² varia…³ units var_n…⁴ perio…⁵ perio…⁶ subdesc datas…⁷\n   <chr>  <chr>    <chr>   <chr>   <chr> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 233217 BARWON … BARWON… 100.00  metr… Stream… 196103… 202211… Availa… A      \n 2 233217 BARWON … BARWON… 210.00  pH    Acidit… 201007… 202211… Availa… A      \n 3 233217 BARWON … BARWON… 215.00  ppm   Dissol… 201007… 202211… Availa… A      \n 4 233217 BARWON … BARWON… 450.00  Degr… Water … 201007… 202211… Availa… A      \n 5 233217 BARWON … BARWON… 810.00  NTU   Turbid… 201007… 202211… Availa… A      \n 6 233217 BARWON … BARWON… 820.00  µS/c… Conduc… 201007… 202211… Availa… A      \n 7 405328 STEAVEN… STEAVE… 100.00  metr… Stream… 200911… 202212… Availa… A      \n 8 405331 TAGGERT… TAGGER… 100.00  metr… Stream… 201007… 201302… Availa… A      \n 9 405331 TAGGERT… TAGGER… 450.00  Degr… Water … 201007… 201302… Availa… A      \n10 405331 TAGGERT… TAGGER… 810.00  NTU   Turbid… 201007… 201302… Availa… A      \n11 405331 TAGGERT… TAGGER… 820.00  µS/c… Conduc… 201007… 201302… Availa… A      \n12 405837 R.G. MA… RAINGA… 10.00   mm    Rainfa… 200106… 202212… Availa… A      \n# … with 1 more variable: timezone <chr>, and abbreviated variable names\n#   ¹​short_name, ²​long_name, ³​variable, ⁴​var_name, ⁵​period_start, ⁶​period_end,\n#   ⁷​datasource\n\n\nTry with two datasources\n\nv2 <- get_variable_list(site_list = allsites, datasource = c('A', 'TELEM'))\n\n\nv2\n\n# A tibble: 27 × 11\n   site   short_…¹ long_…² varia…³ units var_n…⁴ perio…⁵ perio…⁶ subdesc datas…⁷\n   <chr>  <chr>    <chr>   <chr>   <chr> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 233217 BARWON … BARWON… 100.00  metr… Stream… 196103… 202211… Availa… A      \n 2 233217 BARWON … BARWON… 210.00  pH    Acidit… 201007… 202211… Availa… A      \n 3 233217 BARWON … BARWON… 215.00  ppm   Dissol… 201007… 202211… Availa… A      \n 4 233217 BARWON … BARWON… 450.00  Degr… Water … 201007… 202211… Availa… A      \n 5 233217 BARWON … BARWON… 810.00  NTU   Turbid… 201007… 202211… Availa… A      \n 6 233217 BARWON … BARWON… 820.00  µS/c… Conduc… 201007… 202211… Availa… A      \n 7 405328 STEAVEN… STEAVE… 100.00  metr… Stream… 200911… 202212… Availa… A      \n 8 405331 TAGGERT… TAGGER… 100.00  metr… Stream… 201007… 201302… Availa… A      \n 9 405331 TAGGERT… TAGGER… 450.00  Degr… Water … 201007… 201302… Availa… A      \n10 405331 TAGGERT… TAGGER… 810.00  NTU   Turbid… 201007… 201302… Availa… A      \n# … with 17 more rows, 1 more variable: timezone <chr>, and abbreviated\n#   variable names ¹​short_name, ²​long_name, ³​variable, ⁴​var_name,\n#   ⁵​period_start, ⁶​period_end, ⁷​datasource\n\n\nI think now go to get_ts_traces, and then go back and write some helpers that can call get_datasources and get_variable and geo-locate, and use them to allow passing things like variables = ‘all’"
  },
  {
    "objectID": "vicwater/vicwater_testing.html#get-traces",
    "href": "vicwater/vicwater_testing.html#get-traces",
    "title": "Testing VicWater API",
    "section": "get traces",
    "text": "get traces\nThe basic format is this, will need to do some testing.\n\nb1params <- list(\"function\" = 'get_ts_traces',\n               \"version\" = \"2\",\n               \"params\" = list(\"site_list\" = barwon,\n                               \"start_time\" = \"20200101000000\",\n                               \"var_list\" = \"100\",\n                               \"interval\" = \"day\",\n                               \"datasource\" = \"A\", \n                               \"end_time\" = \"20200115000000\",\n                               \"data_type\" = \"mean\",\n                               \"multiplier\" = \"1\"))\n\nreq <- request(vicurl)\n\nreq %>% \n  req_body_json(b1params) %>% \n  req_dry_run()\n\nPOST /cgi/webservice.exe? HTTP/1.1\nHost: data.water.vic.gov.au\nUser-Agent: httr2/0.2.2 r-curl/4.3.3 libcurl/7.64.1\nAccept: */*\nAccept-Encoding: deflate, gzip\nContent-Type: application/json\nContent-Length: 219\n\n{\"function\":\"get_ts_traces\",\"version\":\"2\",\"params\":{\"site_list\":\"233217\",\"start_time\":\"20200101000000\",\"var_list\":\"100\",\"interval\":\"day\",\"datasource\":\"A\",\"end_time\":\"20200115000000\",\"data_type\":\"mean\",\"multiplier\":\"1\"}}\n\nrespb1 <- req %>% \n  req_body_json(b1params) %>% \n  req_perform()\n\nrbodyb1 <- respb1 %>% resp_body_json(check_type = FALSE)\n\nstr(rbodyb1)\n\nList of 2\n $ error_num: int 0\n $ return   :List of 1\n  ..$ traces:List of 1\n  .. ..$ :List of 8\n  .. .. ..$ error_num      : int 0\n  .. .. ..$ compressed     : chr \"0\"\n  .. .. ..$ site_details   :List of 6\n  .. .. .. ..$ timezone  : chr \"10.0\"\n  .. .. .. ..$ short_name: chr \"BARWON @ GEELONG\"\n  .. .. .. ..$ longitude : chr \"144.346892190\"\n  .. .. .. ..$ name      : chr \"BARWON RIVER @ GEELONG\"\n  .. .. .. ..$ latitude  : chr \"-38.163605590\"\n  .. .. .. ..$ org_name  : chr \"Dept. Sustainability and Environment\"\n  .. .. ..$ quality_codes  :List of 2\n  .. .. .. ..$ 2 : chr \"Good quality data - minimal editing required. +/- 0mm - 10mm Drift correction\"\n  .. .. .. ..$ 15: chr \"Minor editing. +/-11mm - 20mm drift correction\"\n  .. .. ..$ trace          :List of 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.838\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.834\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.827\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.821\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.816\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.814\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.811\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.802\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.791\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.805\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.831\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.824\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.820\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.812\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.817\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. ..$ varfrom_details:List of 6\n  .. .. .. ..$ short_name: chr \"Water Level (m)\"\n  .. .. .. ..$ precision : chr \"0.001000\"\n  .. .. .. ..$ subdesc   : chr \"Available for release\"\n  .. .. .. ..$ variable  : chr \"100.00\"\n  .. .. .. ..$ units     : chr \"metres\"\n  .. .. .. ..$ name      : chr \"Stream Water Level (m)\"\n  .. .. ..$ site           : chr \"233217\"\n  .. .. ..$ varto_details  :List of 6\n  .. .. .. ..$ short_name: chr \"Water Level (m)\"\n  .. .. .. ..$ precision : chr \"0.001000\"\n  .. .. .. ..$ subdesc   : chr \"Available for release\"\n  .. .. .. ..$ variable  : chr \"100.00\"\n  .. .. .. ..$ units     : chr \"metres\"\n  .. .. .. ..$ name      : chr \"Stream Water Level (m)\"\n\n\nand with two params\n\nb2params <- list(\"function\" = 'get_ts_traces',\n               \"version\" = \"2\",\n               \"params\" = list(\"site_list\" = barwon,\n                               \"start_time\" = \"20200101000000\",\n                               \"var_list\" = \"100,210\",\n                               \"interval\" = \"day\",\n                               \"datasource\" = \"A\", \n                               \"end_time\" = \"20200115000000\",\n                               \"data_type\" = \"mean\",\n                               \"multiplier\" = \"1\"))\n\nreq <- request(vicurl)\n\nreq %>% \n  req_body_json(b2params) %>% \n  req_dry_run()\n\nPOST /cgi/webservice.exe? HTTP/1.1\nHost: data.water.vic.gov.au\nUser-Agent: httr2/0.2.2 r-curl/4.3.3 libcurl/7.64.1\nAccept: */*\nAccept-Encoding: deflate, gzip\nContent-Type: application/json\nContent-Length: 223\n\n{\"function\":\"get_ts_traces\",\"version\":\"2\",\"params\":{\"site_list\":\"233217\",\"start_time\":\"20200101000000\",\"var_list\":\"100,210\",\"interval\":\"day\",\"datasource\":\"A\",\"end_time\":\"20200115000000\",\"data_type\":\"mean\",\"multiplier\":\"1\"}}\n\nrespb2 <- req %>% \n  req_body_json(b2params) %>% \n  req_perform()\n\nrbodyb2 <- respb2 %>% resp_body_json(check_type = FALSE)\n\nstr(rbodyb2)\n\nList of 2\n $ error_num: int 0\n $ return   :List of 1\n  ..$ traces:List of 2\n  .. ..$ :List of 8\n  .. .. ..$ error_num      : int 0\n  .. .. ..$ compressed     : chr \"0\"\n  .. .. ..$ site_details   :List of 6\n  .. .. .. ..$ timezone  : chr \"10.0\"\n  .. .. .. ..$ short_name: chr \"BARWON @ GEELONG\"\n  .. .. .. ..$ longitude : chr \"144.346892190\"\n  .. .. .. ..$ name      : chr \"BARWON RIVER @ GEELONG\"\n  .. .. .. ..$ latitude  : chr \"-38.163605590\"\n  .. .. .. ..$ org_name  : chr \"Dept. Sustainability and Environment\"\n  .. .. ..$ quality_codes  :List of 2\n  .. .. .. ..$ 2 : chr \"Good quality data - minimal editing required. +/- 0mm - 10mm Drift correction\"\n  .. .. .. ..$ 15: chr \"Minor editing. +/-11mm - 20mm drift correction\"\n  .. .. ..$ trace          :List of 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.838\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.834\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.827\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.821\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.816\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.814\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.811\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.802\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.791\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.805\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.831\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.824\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.820\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.812\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.817\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. ..$ varfrom_details:List of 6\n  .. .. .. ..$ short_name: chr \"Water Level (m)\"\n  .. .. .. ..$ precision : chr \"0.001000\"\n  .. .. .. ..$ subdesc   : chr \"Available for release\"\n  .. .. .. ..$ variable  : chr \"100.00\"\n  .. .. .. ..$ units     : chr \"metres\"\n  .. .. .. ..$ name      : chr \"Stream Water Level (m)\"\n  .. .. ..$ site           : chr \"233217\"\n  .. .. ..$ varto_details  :List of 6\n  .. .. .. ..$ short_name: chr \"Water Level (m)\"\n  .. .. .. ..$ precision : chr \"0.001000\"\n  .. .. .. ..$ subdesc   : chr \"Available for release\"\n  .. .. .. ..$ variable  : chr \"100.00\"\n  .. .. .. ..$ units     : chr \"metres\"\n  .. .. .. ..$ name      : chr \"Stream Water Level (m)\"\n  .. ..$ :List of 8\n  .. .. ..$ error_num      : int 0\n  .. .. ..$ compressed     : chr \"0\"\n  .. .. ..$ site_details   :List of 6\n  .. .. .. ..$ timezone  : chr \"10.0\"\n  .. .. .. ..$ short_name: chr \"BARWON @ GEELONG\"\n  .. .. .. ..$ longitude : chr \"144.346892190\"\n  .. .. .. ..$ name      : chr \"BARWON RIVER @ GEELONG\"\n  .. .. .. ..$ latitude  : chr \"-38.163605590\"\n  .. .. .. ..$ org_name  : chr \"Dept. Sustainability and Environment\"\n  .. .. ..$ quality_codes  :List of 1\n  .. .. .. ..$ 2: chr \"Good quality data - minimal editing required. +/- 0mm - 10mm Drift correction\"\n  .. .. ..$ trace          :List of 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.80\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.82\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.94\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.90\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.71\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.59\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.52\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.64\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.95\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"8.11\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"8.01\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"8.14\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.85\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.92\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.79\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. ..$ varfrom_details:List of 6\n  .. .. .. ..$ short_name: chr \"Field pH\"\n  .. .. .. ..$ precision : chr \"0.010000\"\n  .. .. .. ..$ subdesc   : chr \"Available for release\"\n  .. .. .. ..$ variable  : chr \"210.00\"\n  .. .. .. ..$ units     : chr \"pH\"\n  .. .. .. ..$ name      : chr \"Acidity/Alkalinity (pH)\"\n  .. .. ..$ site           : chr \"233217\"\n  .. .. ..$ varto_details  :List of 6\n  .. .. .. ..$ short_name: chr \"Field pH\"\n  .. .. .. ..$ precision : chr \"0.010000\"\n  .. .. .. ..$ subdesc   : chr \"Available for release\"\n  .. .. .. ..$ variable  : chr \"210.00\"\n  .. .. .. ..$ units     : chr \"pH\"\n  .. .. .. ..$ name      : chr \"Acidity/Alkalinity (pH)\"\n\n\nTwo params, two sites (one site only has one var, but not an error, I hope)\n\nb22params <- list(\"function\" = 'get_ts_traces',\n               \"version\" = \"2\",\n               \"params\" = list(\"site_list\" = str_c(barwon, steavenson, sep = \", \"),\n                               \"start_time\" = \"20200101000000\",\n                               \"var_list\" = \"100,210\",\n                               \"interval\" = \"day\",\n                               \"datasource\" = \"A\", \n                               \"end_time\" = \"20200115000000\",\n                               \"data_type\" = \"mean\",\n                               \"multiplier\" = \"1\"))\n\nreq <- request(vicurl)\n\nreq %>% \n  req_body_json(b22params) %>% \n  req_dry_run()\n\nPOST /cgi/webservice.exe? HTTP/1.1\nHost: data.water.vic.gov.au\nUser-Agent: httr2/0.2.2 r-curl/4.3.3 libcurl/7.64.1\nAccept: */*\nAccept-Encoding: deflate, gzip\nContent-Type: application/json\nContent-Length: 231\n\n{\"function\":\"get_ts_traces\",\"version\":\"2\",\"params\":{\"site_list\":\"233217, 405328\",\"start_time\":\"20200101000000\",\"var_list\":\"100,210\",\"interval\":\"day\",\"datasource\":\"A\",\"end_time\":\"20200115000000\",\"data_type\":\"mean\",\"multiplier\":\"1\"}}\n\nrespb22 <- req %>% \n  req_body_json(b22params) %>% \n  req_perform()\n\nrbodyb22 <- respb22 %>% resp_body_json(check_type = FALSE)\n\nstr(rbodyb22)\n\nList of 2\n $ error_num: int 0\n $ return   :List of 1\n  ..$ traces:List of 3\n  .. ..$ :List of 8\n  .. .. ..$ error_num      : int 0\n  .. .. ..$ compressed     : chr \"0\"\n  .. .. ..$ site_details   :List of 6\n  .. .. .. ..$ timezone  : chr \"10.0\"\n  .. .. .. ..$ short_name: chr \"BARWON @ GEELONG\"\n  .. .. .. ..$ longitude : chr \"144.346892190\"\n  .. .. .. ..$ name      : chr \"BARWON RIVER @ GEELONG\"\n  .. .. .. ..$ latitude  : chr \"-38.163605590\"\n  .. .. .. ..$ org_name  : chr \"Dept. Sustainability and Environment\"\n  .. .. ..$ quality_codes  :List of 2\n  .. .. .. ..$ 2 : chr \"Good quality data - minimal editing required. +/- 0mm - 10mm Drift correction\"\n  .. .. .. ..$ 15: chr \"Minor editing. +/-11mm - 20mm drift correction\"\n  .. .. ..$ trace          :List of 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.838\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.834\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.827\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.821\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.816\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.814\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.811\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.802\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.791\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.805\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.831\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.824\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.820\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.812\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.817\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. ..$ varfrom_details:List of 6\n  .. .. .. ..$ short_name: chr \"Water Level (m)\"\n  .. .. .. ..$ precision : chr \"0.001000\"\n  .. .. .. ..$ subdesc   : chr \"Available for release\"\n  .. .. .. ..$ variable  : chr \"100.00\"\n  .. .. .. ..$ units     : chr \"metres\"\n  .. .. .. ..$ name      : chr \"Stream Water Level (m)\"\n  .. .. ..$ site           : chr \"233217\"\n  .. .. ..$ varto_details  :List of 6\n  .. .. .. ..$ short_name: chr \"Water Level (m)\"\n  .. .. .. ..$ precision : chr \"0.001000\"\n  .. .. .. ..$ subdesc   : chr \"Available for release\"\n  .. .. .. ..$ variable  : chr \"100.00\"\n  .. .. .. ..$ units     : chr \"metres\"\n  .. .. .. ..$ name      : chr \"Stream Water Level (m)\"\n  .. ..$ :List of 8\n  .. .. ..$ error_num      : int 0\n  .. .. ..$ compressed     : chr \"0\"\n  .. .. ..$ site_details   :List of 6\n  .. .. .. ..$ timezone  : chr \"10.0\"\n  .. .. .. ..$ short_name: chr \"BARWON @ GEELONG\"\n  .. .. .. ..$ longitude : chr \"144.346892190\"\n  .. .. .. ..$ name      : chr \"BARWON RIVER @ GEELONG\"\n  .. .. .. ..$ latitude  : chr \"-38.163605590\"\n  .. .. .. ..$ org_name  : chr \"Dept. Sustainability and Environment\"\n  .. .. ..$ quality_codes  :List of 1\n  .. .. .. ..$ 2: chr \"Good quality data - minimal editing required. +/- 0mm - 10mm Drift correction\"\n  .. .. ..$ trace          :List of 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.80\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.82\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.94\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.90\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.71\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.59\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.52\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.64\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.95\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"8.11\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"8.01\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"8.14\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.85\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.92\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"7.79\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. ..$ varfrom_details:List of 6\n  .. .. .. ..$ short_name: chr \"Field pH\"\n  .. .. .. ..$ precision : chr \"0.010000\"\n  .. .. .. ..$ subdesc   : chr \"Available for release\"\n  .. .. .. ..$ variable  : chr \"210.00\"\n  .. .. .. ..$ units     : chr \"pH\"\n  .. .. .. ..$ name      : chr \"Acidity/Alkalinity (pH)\"\n  .. .. ..$ site           : chr \"233217\"\n  .. .. ..$ varto_details  :List of 6\n  .. .. .. ..$ short_name: chr \"Field pH\"\n  .. .. .. ..$ precision : chr \"0.010000\"\n  .. .. .. ..$ subdesc   : chr \"Available for release\"\n  .. .. .. ..$ variable  : chr \"210.00\"\n  .. .. .. ..$ units     : chr \"pH\"\n  .. .. .. ..$ name      : chr \"Acidity/Alkalinity (pH)\"\n  .. ..$ :List of 8\n  .. .. ..$ error_num      : int 0\n  .. .. ..$ compressed     : chr \"0\"\n  .. .. ..$ site_details   :List of 6\n  .. .. .. ..$ timezone  : chr \"10.0\"\n  .. .. .. ..$ short_name: chr \"STEAVENSON R @ FALLS\"\n  .. .. .. ..$ longitude : chr \"145.773503100\"\n  .. .. .. ..$ name      : chr \"STEAVENSON RIVER @ FALLS ROAD MARYSVILLE\"\n  .. .. .. ..$ latitude  : chr \"-37.525797590\"\n  .. .. .. ..$ org_name  : chr \"Victorian Rural Water Corporation\"\n  .. .. ..$ quality_codes  :List of 1\n  .. .. .. ..$ 2: chr \"Good quality data - minimal editing required. +/- 0mm - 10mm Drift correction\"\n  .. .. ..$ trace          :List of 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.741\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.738\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.736\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.734\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.741\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.755\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.745\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.739\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.735\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.745\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.759\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.745\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.742\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.740\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.757\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. ..$ varfrom_details:List of 6\n  .. .. .. ..$ short_name: chr \"Water Level (m)\"\n  .. .. .. ..$ precision : chr \"0.001000\"\n  .. .. .. ..$ subdesc   : chr \"Available for release\"\n  .. .. .. ..$ variable  : chr \"100.00\"\n  .. .. .. ..$ units     : chr \"metres\"\n  .. .. .. ..$ name      : chr \"Stream Water Level (m)\"\n  .. .. ..$ site           : chr \"405328\"\n  .. .. ..$ varto_details  :List of 6\n  .. .. .. ..$ short_name: chr \"Water Level (m)\"\n  .. .. .. ..$ precision : chr \"0.001000\"\n  .. .. .. ..$ subdesc   : chr \"Available for release\"\n  .. .. .. ..$ variable  : chr \"100.00\"\n  .. .. .. ..$ units     : chr \"metres\"\n  .. .. .. ..$ name      : chr \"Stream Water Level (m)\"\n\n\nI wasn’t able to get discharge (140, 141) from a varlist. Double check\n\nbparamsd <- list(\"function\" = 'get_ts_traces',\n               \"version\" = \"2\",\n               \"params\" = list(\"site_list\" = barwon,\n                               \"start_time\" = \"20200101000000\",\n                               \"var_list\" = \"100,140\",\n                               \"interval\" = \"day\",\n                               \"datasource\" = \"A\", \n                               \"end_time\" = \"20200115000000\",\n                               \"data_type\" = \"mean\",\n                               \"multiplier\" = \"1\"))\n\nreq <- request(vicurl)\n\nreq %>% \n  req_body_json(bparamsd) %>% \n  req_dry_run()\n\nPOST /cgi/webservice.exe? HTTP/1.1\nHost: data.water.vic.gov.au\nUser-Agent: httr2/0.2.2 r-curl/4.3.3 libcurl/7.64.1\nAccept: */*\nAccept-Encoding: deflate, gzip\nContent-Type: application/json\nContent-Length: 223\n\n{\"function\":\"get_ts_traces\",\"version\":\"2\",\"params\":{\"site_list\":\"233217\",\"start_time\":\"20200101000000\",\"var_list\":\"100,140\",\"interval\":\"day\",\"datasource\":\"A\",\"end_time\":\"20200115000000\",\"data_type\":\"mean\",\"multiplier\":\"1\"}}\n\nrespbd <- req %>% \n  req_body_json(bparamsd) %>% \n  req_perform()\n\nrbodybd <- respbd %>% resp_body_json(check_type = FALSE)\n\nstr(rbodybd)\n\nList of 2\n $ error_num: int 0\n $ return   :List of 1\n  ..$ traces:List of 1\n  .. ..$ :List of 8\n  .. .. ..$ error_num      : int 0\n  .. .. ..$ compressed     : chr \"0\"\n  .. .. ..$ site_details   :List of 6\n  .. .. .. ..$ timezone  : chr \"10.0\"\n  .. .. .. ..$ short_name: chr \"BARWON @ GEELONG\"\n  .. .. .. ..$ longitude : chr \"144.346892190\"\n  .. .. .. ..$ name      : chr \"BARWON RIVER @ GEELONG\"\n  .. .. .. ..$ latitude  : chr \"-38.163605590\"\n  .. .. .. ..$ org_name  : chr \"Dept. Sustainability and Environment\"\n  .. .. ..$ quality_codes  :List of 2\n  .. .. .. ..$ 2 : chr \"Good quality data - minimal editing required. +/- 0mm - 10mm Drift correction\"\n  .. .. .. ..$ 15: chr \"Minor editing. +/-11mm - 20mm drift correction\"\n  .. .. ..$ trace          :List of 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.838\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.834\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.827\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.821\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.816\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.814\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.811\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.802\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.791\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.805\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.831\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.824\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.820\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.812\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.817\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. ..$ varfrom_details:List of 6\n  .. .. .. ..$ short_name: chr \"Water Level (m)\"\n  .. .. .. ..$ precision : chr \"0.001000\"\n  .. .. .. ..$ subdesc   : chr \"Available for release\"\n  .. .. .. ..$ variable  : chr \"100.00\"\n  .. .. .. ..$ units     : chr \"metres\"\n  .. .. .. ..$ name      : chr \"Stream Water Level (m)\"\n  .. .. ..$ site           : chr \"233217\"\n  .. .. ..$ varto_details  :List of 6\n  .. .. .. ..$ short_name: chr \"Water Level (m)\"\n  .. .. .. ..$ precision : chr \"0.001000\"\n  .. .. .. ..$ subdesc   : chr \"Available for release\"\n  .. .. .. ..$ variable  : chr \"100.00\"\n  .. .. .. ..$ units     : chr \"metres\"\n  .. .. .. ..$ name      : chr \"Stream Water Level (m)\"\n\n\nKisters has an example of asking for 140.01? Try that? No, just do the varfrom/varto method for discharge and stage.\n\nbparams <- list(\"function\" = 'get_ts_traces',\n               \"version\" = \"2\",\n               \"params\" = list(\"site_list\" = barwon,\n                               \"start_time\" = \"20200101000000\",\n                               \"var_list\" = \"100,140.01\",\n                               \"interval\" = \"day\",\n                               \"datasource\" = \"A\", \n                               \"end_time\" = \"20200115000000\",\n                               \"data_type\" = \"mean\",\n                               \"multiplier\" = \"1\"))\n\nreq <- request(vicurl)\n\nreq %>% \n  req_body_json(bparams) %>% \n  req_dry_run()\n\nPOST /cgi/webservice.exe? HTTP/1.1\nHost: data.water.vic.gov.au\nUser-Agent: httr2/0.2.2 r-curl/4.3.3 libcurl/7.64.1\nAccept: */*\nAccept-Encoding: deflate, gzip\nContent-Type: application/json\nContent-Length: 226\n\n{\"function\":\"get_ts_traces\",\"version\":\"2\",\"params\":{\"site_list\":\"233217\",\"start_time\":\"20200101000000\",\"var_list\":\"100,140.01\",\"interval\":\"day\",\"datasource\":\"A\",\"end_time\":\"20200115000000\",\"data_type\":\"mean\",\"multiplier\":\"1\"}}\n\nrespb <- req %>% \n  req_body_json(bparams) %>% \n  req_perform()\n\nrbodyb <- respb %>% resp_body_json(check_type = FALSE)\n\nstr(rbodyb)\n\nList of 2\n $ error_num: int 0\n $ return   :List of 1\n  ..$ traces:List of 1\n  .. ..$ :List of 8\n  .. .. ..$ error_num      : int 0\n  .. .. ..$ compressed     : chr \"0\"\n  .. .. ..$ site_details   :List of 6\n  .. .. .. ..$ timezone  : chr \"10.0\"\n  .. .. .. ..$ short_name: chr \"BARWON @ GEELONG\"\n  .. .. .. ..$ longitude : chr \"144.346892190\"\n  .. .. .. ..$ name      : chr \"BARWON RIVER @ GEELONG\"\n  .. .. .. ..$ latitude  : chr \"-38.163605590\"\n  .. .. .. ..$ org_name  : chr \"Dept. Sustainability and Environment\"\n  .. .. ..$ quality_codes  :List of 2\n  .. .. .. ..$ 2 : chr \"Good quality data - minimal editing required. +/- 0mm - 10mm Drift correction\"\n  .. .. .. ..$ 15: chr \"Minor editing. +/-11mm - 20mm drift correction\"\n  .. .. ..$ trace          :List of 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.838\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.834\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.827\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.821\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.816\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.814\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.811\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.802\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.791\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.805\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.831\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.824\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.820\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.812\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.817\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 2\n  .. .. ..$ varfrom_details:List of 6\n  .. .. .. ..$ short_name: chr \"Water Level (m)\"\n  .. .. .. ..$ precision : chr \"0.001000\"\n  .. .. .. ..$ subdesc   : chr \"Available for release\"\n  .. .. .. ..$ variable  : chr \"100.00\"\n  .. .. .. ..$ units     : chr \"metres\"\n  .. .. .. ..$ name      : chr \"Stream Water Level (m)\"\n  .. .. ..$ site           : chr \"233217\"\n  .. .. ..$ varto_details  :List of 6\n  .. .. .. ..$ short_name: chr \"Water Level (m)\"\n  .. .. .. ..$ precision : chr \"0.001000\"\n  .. .. .. ..$ subdesc   : chr \"Available for release\"\n  .. .. .. ..$ variable  : chr \"100.00\"\n  .. .. .. ..$ units     : chr \"metres\"\n  .. .. .. ..$ name      : chr \"Stream Water Level (m)\"\n\n\nvarfrom-varto check. Does it give us both, or do we have to ask for the from separately`?\n\nbparamsft <- list(\"function\" = 'get_ts_traces',\n               \"version\" = \"2\",\n               \"params\" = list(\"site_list\" = barwon,\n                               \"start_time\" = \"20200101000000\",\n                               \"varfrom\" = \"100\",\n                               \"varto\" = \"140\", \n                               \"interval\" = \"day\",\n                               \"datasource\" = \"A\", \n                               \"end_time\" = \"20200115000000\",\n                               \"data_type\" = \"mean\",\n                               \"multiplier\" = \"1\"))\n\nreq <- request(vicurl)\n\nreq %>% \n  req_body_json(bparamsft) %>% \n  req_dry_run()\n\nPOST /cgi/webservice.exe? HTTP/1.1\nHost: data.water.vic.gov.au\nUser-Agent: httr2/0.2.2 r-curl/4.3.3 libcurl/7.64.1\nAccept: */*\nAccept-Encoding: deflate, gzip\nContent-Type: application/json\nContent-Length: 232\n\n{\"function\":\"get_ts_traces\",\"version\":\"2\",\"params\":{\"site_list\":\"233217\",\"start_time\":\"20200101000000\",\"varfrom\":\"100\",\"varto\":\"140\",\"interval\":\"day\",\"datasource\":\"A\",\"end_time\":\"20200115000000\",\"data_type\":\"mean\",\"multiplier\":\"1\"}}\n\nrespbft <- req %>% \n  req_body_json(bparamsft) %>% \n  req_perform()\n\nrbodybft <- respbft %>% resp_body_json(check_type = FALSE)\n\nstr(rbodybft)\n\nList of 2\n $ error_num: int 0\n $ return   :List of 1\n  ..$ traces:List of 1\n  .. ..$ :List of 8\n  .. .. ..$ error_num      : int 0\n  .. .. ..$ compressed     : chr \"0\"\n  .. .. ..$ site_details   :List of 6\n  .. .. .. ..$ timezone  : chr \"10.0\"\n  .. .. .. ..$ short_name: chr \"BARWON @ GEELONG\"\n  .. .. .. ..$ longitude : chr \"144.346892190\"\n  .. .. .. ..$ name      : chr \"BARWON RIVER @ GEELONG\"\n  .. .. .. ..$ latitude  : chr \"-38.163605590\"\n  .. .. .. ..$ org_name  : chr \"Dept. Sustainability and Environment\"\n  .. .. ..$ quality_codes  :List of 1\n  .. .. .. ..$ 150: chr \"Rating extrapolated above 1.5x maximum flow gauged.\"\n  .. .. ..$ trace          :List of 15\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.18443\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 150\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.16332\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 150\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.12997\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 150\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.10202\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 150\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.08706\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 150\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.07811\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 150\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.07044\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 150\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.04782\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 150\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.02872\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 150\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.07961\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 150\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.14628\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 150\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.11425\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 150\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.09740\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 150\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.07464\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 150\n  .. .. .. ..$ :List of 3\n  .. .. .. .. ..$ v: chr \"0.11269\"\n  .. .. .. .. ..$ t: num 2.02e+13\n  .. .. .. .. ..$ q: int 150\n  .. .. ..$ varfrom_details:List of 6\n  .. .. .. ..$ short_name: chr \"Water Level (m)\"\n  .. .. .. ..$ precision : chr \"0.001000\"\n  .. .. .. ..$ subdesc   : chr \"Available for release\"\n  .. .. .. ..$ variable  : chr \"100.00\"\n  .. .. .. ..$ units     : chr \"metres\"\n  .. .. .. ..$ name      : chr \"Stream Water Level (m)\"\n  .. .. ..$ site           : chr \"233217\"\n  .. .. ..$ varto_details  :List of 6\n  .. .. .. ..$ short_name: chr \"Discharge (m3/sec)\"\n  .. .. .. ..$ precision : chr \"0.000010\"\n  .. .. .. ..$ subdesc   : chr \"Available for release\"\n  .. .. .. ..$ variable  : chr \"140.00\"\n  .. .. .. ..$ units     : chr \"cubic metres/second\"\n  .. .. .. ..$ name      : chr \"Stream Discharge (m3/s)\"\n\n\nThat looks like it might have only given us varto.\nWhat happens if we ask for a varto/from for a site that doesn’t have it? Earlier we saw that the varlist just skips, but does this?\n\nbparamse <- list(\"function\" = 'get_ts_traces',\n               \"version\" = \"2\",\n               \"params\" = list(\"site_list\" = golf,\n                               \"start_time\" = \"20200101000000\",\n                               \"var_list\" = \"100,210\",\n                               \"interval\" = \"day\",\n                               \"datasource\" = \"A\", \n                               \"end_time\" = \"20200115000000\",\n                               \"data_type\" = \"mean\",\n                               \"multiplier\" = \"1\"))\n\nreq <- request(vicurl)\n\nreq %>% \n  req_body_json(bparamse) %>% \n  req_dry_run()\n\nPOST /cgi/webservice.exe? HTTP/1.1\nHost: data.water.vic.gov.au\nUser-Agent: httr2/0.2.2 r-curl/4.3.3 libcurl/7.64.1\nAccept: */*\nAccept-Encoding: deflate, gzip\nContent-Type: application/json\nContent-Length: 223\n\n{\"function\":\"get_ts_traces\",\"version\":\"2\",\"params\":{\"site_list\":\"405837\",\"start_time\":\"20200101000000\",\"var_list\":\"100,210\",\"interval\":\"day\",\"datasource\":\"A\",\"end_time\":\"20200115000000\",\"data_type\":\"mean\",\"multiplier\":\"1\"}}\n\nrespbe <- req %>% \n  req_body_json(bparamse) %>% \n  req_perform()\n\nrbodybe <- respbe %>% resp_body_json(check_type = FALSE)\n\nstr(rbodybe)\n\nList of 2\n $ error_num: int 125\n $ error_msg: chr \"No data for specified variable in file\"\n\n\nOk, that errors. So I’ll need to capture and skip errors.\n\nunpack different formats\n(varlist with multiple, varfrom/to, etc). b1params (one param, one site), b2params (two params, varlist), b22params (two params, two sites- only one param at one site) bparamsft (varfrom/varto), bparamse (error),\nstart simple- grab errors. Should have been doing this all along.\n\ner1 <- rbodyb1[1]\nere <- rbodybe[1]\ner1\n\n$error_num\n[1] 0\n\nere\n\n$error_num\n[1] 125\n\n\nUnpack the single. Yeesh\nI’m ignoring quality codes for the moment. They’re a definition list, and so maybe should be unpacked separately, matched to varto (I think not varfrom), and then joined? But I want to see how they work with more complex structures first.\n\ns <- as_tibble(rbodyb1[2]) %>% # the [2] drops the error column\n  unnest_longer(col = where(is.list)) %>% # a `return` list\n  unnest_wider(col = where(is.list)) %>% # complex set of lists\n  unnest_wider(col = site_details) %>% # columns of info about the site\n  rename(site_name = name, site_short_name = short_name) %>% \n  # there are name conflicts between site and varfrom and varto. Not sure we need both varfrom and varto?\n  unnest_wider(col = varfrom_details) %>% \n  rename_with(~(paste0('varfrom_', .)), \n              c(short_name, precision, subdesc, variable, units, name)) %>% \n  unnest_wider(col = varto_details) %>% \n  rename_with(~(paste0('varto_', .)), \n              c(short_name, precision, subdesc, variable, units, name)) %>% \n  unnest_longer(col = trace) %>% \n  unnest_wider(col = trace)\n\nTry two variables. still works. still not sure why I need both varfrom and varto when they match.\n\ns <- as_tibble(rbodyb2[2]) %>% # the [2] drops the error column\n  unnest_longer(col = where(is.list)) %>% # a `return` list\n  unnest_wider(col = where(is.list)) %>% # complex set of lists\n  unnest_wider(col = site_details) %>% # columns of info about the site\n  rename(site_name = name, site_short_name = short_name) %>% \n  # there are name conflicts between site and varfrom and varto. Not sure we need both varfrom and varto?\n  unnest_wider(col = varfrom_details) %>% \n  rename_with(~(paste0('varfrom_', .)), \n              c(short_name, precision, subdesc, variable, units, name)) %>% \n  unnest_wider(col = varto_details) %>% \n  rename_with(~(paste0('varto_', .)), \n              c(short_name, precision, subdesc, variable, units, name)) %>% \n  unnest_longer(col = trace) %>% \n  unnest_wider(col = trace)\n\nTwo variables, two sites\n\ns <- as_tibble(rbodyb22[2]) %>% # the [2] drops the error column\n  unnest_longer(col = where(is.list)) %>% # a `return` list\n  unnest_wider(col = where(is.list)) %>% # complex set of lists\n  unnest_wider(col = site_details) %>% # columns of info about the site\n  rename(site_name = name, site_short_name = short_name) %>% \n  # there are name conflicts between site and varfrom and varto. Not sure we need both varfrom and varto?\n  unnest_wider(col = varfrom_details) %>% \n  rename_with(~(paste0('varfrom_', .)), \n              c(short_name, precision, subdesc, variable, units, name)) %>% \n  unnest_wider(col = varto_details) %>% \n  rename_with(~(paste0('varto_', .)), \n              c(short_name, precision, subdesc, variable, units, name)) %>% \n  unnest_longer(col = trace) %>% \n  unnest_wider(col = trace)\n\nAnd finally, the one where we do have a varto\n\ns <- as_tibble(rbodybft[2]) %>% # the [2] drops the error column\n  unnest_longer(col = where(is.list)) %>% # a `return` list\n  unnest_wider(col = where(is.list)) %>% # complex set of lists\n  unnest_wider(col = site_details) %>% # columns of info about the site\n  rename(site_name = name, site_short_name = short_name) %>% \n  # there are name conflicts between site and varfrom and varto. Not sure we need both varfrom and varto?\n  unnest_wider(col = varfrom_details) %>% \n  rename_with(~(paste0('varfrom_', .)), \n              c(short_name, precision, subdesc, variable, units, name)) %>% \n  unnest_wider(col = varto_details) %>% \n  rename_with(~(paste0('varto_', .)), \n              c(short_name, precision, subdesc, variable, units, name)) %>% \n  unnest_longer(col = trace) %>% \n  unnest_wider(col = trace)\n\nFinally, some new q values. and pretty clear we don’t need the varfroms.\nNeed to change the time column to dates\nDo we want to split up or return stacked or return wide? Make an option.\nDo we want to return NA days as NA or skip them?\n\n\nCleaning that up\nsafest is code x site x varto. though I think don’t need site, we’ll have expanded there by the time we get varto.\n\ns <- as_tibble(rbodyb22[2]) %>% # the [2] drops the error column\n  unnest_longer(col = where(is.list)) %>% # a `return` list\n  unnest_wider(col = where(is.list)) %>% # complex set of lists\n  unnest_wider(col = site_details) %>% # columns of info about the site\n  rename(site_name = name, site_short_name = short_name) %>% \n  # there are name conflicts between site and varfrom and varto. \n  # and we can drop varfrom\n  select(-varfrom_details) %>% \n  unnest_wider(col = varto_details) %>% \n  rename_with(~(paste0('variable_', .)), \n              c(short_name, name)) \n\n# break in here to get the quality codes to match\nqc <- s %>% \n  select(quality_codes, site, variable) %>% \n  unnest_longer(col = quality_codes) %>% \n  mutate(quality_codes_id = as.integer(quality_codes_id))\n\n# finish unpacking\ns <- s %>%\n  select(-quality_codes) %>% \n  unnest_longer(col = trace) %>% \n  unnest_wider(col = trace)\n\n# clean up\ns <- s %>% \n  rename(value = v, time = t, quality_codes_id = q) %>% \n  mutate(time = lubridate::ymd_hms(time)) %>% \n  left_join(qc, by = c('quality_codes_id', 'site', 'variable')) %>% \n  mutate(across(c(longitude, latitude, value), as.numeric)) # leaving some others because they either are names (gauges, variable) or display better (precision)\n\nCan I make that wide? Works without using id_cols but messy because too many info cols. Would end up being better to cut and join the info back on. But then I lose the quality codes, because they apply to each variable differently. Just return like this for now with a warning.\n\nsw <- s %>% pivot_wider(names_from = variable, values_from = value, id_cols = c(time, site))\n\nWhat I could do though is break it up into a list, potentially by sites and/or variables.\n\nslist <- split(s, s$site)\nvlist <- split(s, s$variable)\nsvlist <- split(s, interaction(s$site, s$variable))\n\n\n\nTest package version\n\ndevtools::load_all('C:/Users/Galen/Documents/vicwater')\n\nℹ Loading vicwater\n\n\nOne site, one variable\n\nbs <- get_ts_traces(site_list = barwon, datasource = 'A', var_list = '100', start_time = '20200101', end_time = '20200105', interval = 'day', data_type = 'mean', multiplier = 1, returnformat = 'df')\n\nWarning: executing %dopar% sequentially: no parallel backend registered\n\n\nCan I pass decimals? it’s how they come out of get_variable_list\n\nbsdec <- get_ts_traces(site_list = barwon, datasource = 'A', var_list = '100.00', start_time = '20200101', end_time = '20200105', interval = 'day', data_type = 'mean', multiplier = 1, returnformat = 'df')\n\nOne site, derived variables\n\nbsd <- get_ts_traces(site_list = barwon, datasource = 'A', var_list = c('100', '140'), start_time = '20200101', end_time = '20200105', interval = 'day', data_type = 'mean', multiplier = 1, returnformat = 'df')\n\nOnly derived\n\nbsod <- get_ts_traces(site_list = barwon, datasource = 'A', var_list = '140', start_time = '20200101', end_time = '20200105', interval = 'day', data_type = 'mean', multiplier = 1, returnformat = 'df')\n\nSome more variables, derived and not\n\nbsdv <- get_ts_traces(site_list = barwon, datasource = 'A', var_list = c('100', '140', '210', '450'), start_time = '20200101', end_time = '20200105', interval = 'day', data_type = 'mean', multiplier = 1, returnformat = 'df')\n\nAnd multi-sites too- does it correctly collapse the vector?\n\nbsdvs <- get_ts_traces(site_list = c(barwon, steavenson), \n                       datasource = 'A', \n                       var_list = c('100', '140', '210', '450'), \n                       start_time = '20200101', end_time = '20200105', \n                       interval = 'day', data_type = 'mean', \n                       multiplier = 1, returnformat = 'df')\n\nAnd finally everything including rain at golf. Careful though- does mean make sense for that? Probably better as a sum? Tried that and threw an error but told me the options:\nMean/Max/Min/Start/End/First/Last/Tot/MaxMin/Point/Cum\nDefinitely need two calls if need two different values at least for now- total temp is nonsense.\n\nbsdvs <- get_ts_traces(site_list = allsites, \n                       datasource = 'A', \n                       var_list = c('10', '100', '140', '210', '450'), \n                       start_time = '20200101', end_time = '20200105', \n                       interval = 'day', data_type = 'mean', \n                       multiplier = 1, returnformat = 'df')\n\nand return a list\n\nbsdvsl <- get_ts_traces(site_list = allsites, \n                       datasource = 'A', \n                       var_list = c('10', '100', '140', '210', '450'), \n                       start_time = '20200101', end_time = '20200105', \n                       interval = 'day', data_type = 'mean', \n                       multiplier = 1, returnformat = 'sxvlist')"
  },
  {
    "objectID": "vicwater/vicwater_testing.html#a-variable-and-time-aware-version",
    "href": "vicwater/vicwater_testing.html#a-variable-and-time-aware-version",
    "title": "Testing VicWater API",
    "section": "A variable and time-aware version",
    "text": "A variable and time-aware version\n\npossibles <- get_variable_list(site_list = allsites, datasource = 'A') %>% \n  dplyr::select(site, datasource, variable, period_start, period_end)\n\n\nposs140 <- possibles[possibles$variable == '100.00', ] \n\nposs141 <- poss140\nposs140$variable <- '140.00'\nposs141$variable <- '141.00'\n\npossibles <- bind_rows(possibles, poss140, poss141)\n\nall the tests above should run\n\nTest package version\n\ndevtools::load_all('C:/Users/Galen/Documents/vicwater')\n\nℹ Loading vicwater\n\n\nOne site, one variable\n\nbs <- get_ts_traces2(site_list = barwon, datasource = 'A', var_list = '100', start_time = '20200101', end_time = '20200105', interval = 'day', data_type = 'mean', multiplier = 1, returnformat = 'df')\n\nCan I pass decimals? it’s how they come out of get_variable_list\n\nbsdec <- get_ts_traces2(site_list = barwon, datasource = 'A', var_list = '100.00', start_time = '20200101', end_time = '20200105', interval = 'day', data_type = 'mean', multiplier = 1, returnformat = 'df')\n\nOne site, derived variables\n\nbsd <- get_ts_traces2(site_list = barwon, datasource = 'A', var_list = c('100', '140', '141'), start_time = '20200101', end_time = '20200105', interval = 'day', data_type = 'mean', multiplier = 1, returnformat = 'df')\n\nOnly derived\n\nbsod <- get_ts_traces2(site_list = barwon, datasource = 'A', var_list = '140', start_time = '20200101', end_time = '20200105', interval = 'day', data_type = 'mean', multiplier = 1, returnformat = 'df')\n\nSome more variables, derived and not\n\nbsdv <- get_ts_traces2(site_list = barwon, datasource = 'A', var_list = c('100', '140', '210', '450'), start_time = '20200101', end_time = '20200105', interval = 'day', data_type = 'mean', multiplier = 1, returnformat = 'df')\n\nAnd multi-sites too- does it correctly collapse the vector?\n\nbsdvs <- get_ts_traces2(site_list = c(barwon, steavenson), \n                       datasource = 'A', \n                       var_list = c('100', '140', '210', '450'), \n                       start_time = '20200101', end_time = '20200105', \n                       interval = 'day', data_type = 'mean', \n                       multiplier = 1, returnformat = 'df')\n\nDo the ‘all’ settings work? Let’s bump to year so I don’t have so much data\n\nbsdvs <- get_ts_traces2(site_list = c(barwon, steavenson), \n                       datasource = 'A', \n                       var_list = \"all\", \n                       start_time = \"all\", \n                       end_time = \"all\", \n                       interval = 'year', data_type = 'mean', \n                       multiplier = 1, returnformat = 'df')\n\nWarning: `var_list = 'all'` is *very* dangerous, since it applies the same\n`data_type` to all variables, which is rarely appropriate. Check the variables\navailable for your sites and make sure you want to do this.\n\n\nCan I throw something wrong to interval to see if it tells me what it can do? Kisters says\nyear, month, day, hour, minute, second,\nperiod,\ndefault\n\nbiw <- get_ts_traces2(site_list = barwon, \n                       datasource = 'A', \n                       var_list = \"100\", \n                       start_time = \"20200101\", \n                       end_time = \"20211231\", \n                       interval = 'eon', data_type = 'mean', \n                       multiplier = 1, returnformat = 'df')\n\nerror is Invalid interval, must be YEAR, MONTH, DAY, HOUR, MINUTE or SECOND"
  },
  {
    "objectID": "vicwater/vicwater_testing.html#benchmark",
    "href": "vicwater/vicwater_testing.html#benchmark",
    "title": "Testing VicWater API",
    "section": "Benchmark",
    "text": "Benchmark\nThis likely varies a lot depending on what I’m asking for. Should be done more systematically, and use microbenchmark.\nThey should be roughly the same for a single?\n\nsystem.time(b1 <- get_ts_traces(site_list = barwon, \n                       datasource = 'A', \n                       var_list = '100', \n                       start_time = '20200101', end_time = '20200105', \n                       interval = 'day', data_type = 'mean', \n                       multiplier = 1, returnformat = 'df'))\n\n   user  system elapsed \n   0.10    0.00    0.86 \n\nsystem.time(b2 <- get_ts_traces2(site_list = barwon, \n                       datasource = 'A', \n                       var_list = '100', \n                       start_time = '20200101', end_time = '20200105', \n                       interval = 'day', data_type = 'mean', \n                       multiplier = 1, returnformat = 'df'))\n\n   user  system elapsed \n   0.17    0.01    1.50 \n\n\ninteresting. so the second is faster locally, but higher network, I think.\n\nsystem.time(bsdvs1 <- get_ts_traces(site_list = c(barwon, steavenson), \n                       datasource = 'A', \n                       var_list = c('100', '140', '210', '450'), \n                       start_time = '20200101', end_time = '20200105', \n                       interval = 'day', data_type = 'mean', \n                       multiplier = 1, returnformat = 'df'))\n\n   user  system elapsed \n   0.16    0.02    1.71 \n\nsystem.time(bsdvs2 <- get_ts_traces2(site_list = c(barwon, steavenson), \n                       datasource = 'A', \n                       var_list = c('100', '140', '210', '450'), \n                       start_time = '20200101', end_time = '20200105', \n                       interval = 'day', data_type = 'mean', \n                       multiplier = 1, returnformat = 'df'))\n\n   user  system elapsed \n   0.25    0.01    5.69 \n\n\nOof. That’s pretty bad. Can I speed it up? probably.\nHow about parallel?\n\nlibrary(doFuture)\n\nLoading required package: foreach\n\n\nWarning: package 'foreach' was built under R version 4.2.2\n\n\nLoading required package: future\n\n\nWarning: package 'future' was built under R version 4.2.2\n\nregisterDoFuture()\nplan(multisession)\n\nsystem.time(bsdvs1p <- get_ts_traces(site_list = c(barwon, steavenson), \n                       datasource = 'A', \n                       var_list = c('100', '140', '210', '450'), \n                       start_time = '20200101', end_time = '20200105', \n                       interval = 'day', data_type = 'mean', \n                       multiplier = 1, returnformat = 'df'))\n\n   user  system elapsed \n   0.04    0.00    2.81 \n\nsystem.time(bsdvs2p <- get_ts_traces2(site_list = c(barwon, steavenson), \n                       datasource = 'A', \n                       var_list = c('100', '140', '210', '450'), \n                       start_time = '20200101', end_time = '20200105', \n                       interval = 'day', data_type = 'mean', \n                       multiplier = 1, returnformat = 'df'))\n\n   user  system elapsed \n   0.06    0.00    3.67"
  }
]